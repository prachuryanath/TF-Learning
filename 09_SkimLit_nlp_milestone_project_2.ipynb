{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_SkimLit_nlp_milestone_project_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQnhNIqLbzeSCvM6HMpExr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prachuryanath/TF-Learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc96wwcKO-El"
      },
      "source": [
        "# Milestone Project 2 : SkimLit \n",
        "\n",
        "In this project, we're going to be putting what we've learned into practice.\n",
        "\n",
        "More specificially, we're going to be replicating the deep learning model behind the 2017 paper `PubMed 200k RCT: a Dataset for Sequenctial Sentence Classification in Medical Abstracts`.\n",
        "\n",
        "When it was released, the paper presented a new dataset called `PubMed 200k RCT which consists of ~200,000 labelled Randomized Controlled Trial (RCT) abstracts`.\n",
        "\n",
        "The goal of the dataset was to explore the ability for NLP models to classify sentences which appear in sequential order.\n",
        "\n",
        "### **Problem in a sentence**\n",
        "*The number of RCT papers released is continuing to increase, those without structured abstracts can be hard to read and in turn slow down researchers moving through the literature.*\n",
        "\n",
        "### **Solution in a sentence**\n",
        "*Create an NLP model to classify abstract sentences into the role they play (e.g. objective, methods, results, etc) to enable researchers to skim through the literature (hence SkimLit ðŸ¤“ðŸ”¥) and dive deeper when necessary.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49iOYPcIPeRI"
      },
      "source": [
        "## What we're going to cover\n",
        "Time to take what we've learned in the NLP fundmentals notebook and build our biggest NLP model yet:\n",
        "\n",
        "* Downloading a text dataset (PubMed RCT200k from GitHub)\n",
        "* Writing a preprocessing function to prepare our data for modelling\n",
        "* Setting up a series of modelling experiments\n",
        "  * Making a baseline (TF-IDF classifier)\n",
        "  * Deep models with different combinations of: token embeddings, character embeddings, pretrained embeddings, positional embeddings\n",
        "* Building our first multimodal model (taking multiple types of data inputs)\n",
        "  * Replicating the model architecture from https://arxiv.org/pdf/1612.05251.pdf\n",
        "* Find the most wrong predictions\n",
        "* Making predictions on PubMed abstracts from the wild"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbHryq10QGlA",
        "outputId": "305a8c45-378f-4050-dca1-5fcc68de6e29"
      },
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 23 17:26:28 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXj_Ou67QU0U"
      },
      "source": [
        "## Get data\n",
        "\n",
        "Before we can start building a model, we've got to download the PubMed 200k RCT dataset.\n",
        "\n",
        "In a phenomenal act of kindness, the authors of the paper have made the data they used for their research availably publically and for free in the form of .txt files on GitHub.\n",
        "\n",
        "We can copy them to our local directory using git clone `https://github.com/Franck-Dernoncourt/pubmed-rct.`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ5b5_lMQuJV",
        "outputId": "e8ffdfcc-8581-43ac-b6bd-2fae0227a04e"
      },
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSrJNVHRQ0aQ"
      },
      "source": [
        "Looking at the README file from the GitHub page, we get the following information:\n",
        "\n",
        "* `PubMed 20k` is a subset of `PubMed 200k`. I.e., any abstract present in `PubMed 20k` is also present in `PubMed 200k`.\n",
        "* `PubMed_200k_RCT` is the same as `PubMed_200k_RCT_numbers_replaced_with_at_sign`, except that in the latter all numbers had been replaced by @. (same for `PubMed_20k_RCT` vs. `PubMed_20k_RCT_numbers_replaced_with_at_sign`).\n",
        "* Since Github file size limit is 100 MiB, we had to compress `PubMed_200k_RCT\\train.7z` and `PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip`. To uncompress train.7z, you may use 7-Zip on Windows, Keka on Mac OS X, or p7zip on Linux.\n",
        "\n",
        "To begin with, the dataset we're going to be focused on is `PubMed_20k_RCT_numbers_replaced_with_at_sign`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1liAnC0R5Zc",
        "outputId": "98d0671a-6a26-4f20-fef0-55dbed44c1f4"
      },
      "source": [
        "# Check what files are in the PubMed_20K dataset \n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9v0_aP8SJWc"
      },
      "source": [
        "Beautiful, looks like we've got three separate text files:\n",
        "\n",
        "* **train.txt** - *training samples.*\n",
        "* **dev.txt** - *dev is short for development set, which is another name for validation set (in our case, we'll be using and referring to this file as our validation set).*\n",
        "* **test.txt** - *test samples.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z72jYlzJSATJ"
      },
      "source": [
        "# Start by using the 20k dataset\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXbC3PBRSDHX",
        "outputId": "43a9917e-87bc-4127-f218-a31f4184bd98"
      },
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc8I6W8nSE75"
      },
      "source": [
        "## Preprocess data\n",
        "\n",
        "To get familiar and understand how we have to prepare our data for our deep learning models, we've got to visualize it.\n",
        "\n",
        "Because our data is in the form of text files, let's write some code to read each of the lines in a target file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXXE_zSsShAx"
      },
      "source": [
        "# Create function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Reads filename (a text file) and returns the lines of text as a list\n",
        "\n",
        "  Args:\n",
        "    filename : a string containing the target filepath to read.\n",
        "\n",
        "  Returns:\n",
        "    A list of strings with one string per line from the target filename.\n",
        "    For example:\n",
        "    [\"this is the first line of filename\",\n",
        "    \"this is the second line of filename\",\n",
        "    ...]\n",
        "  \"\"\"\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLH534ogTwad",
        "outputId": "d2b317df-c4e8-47c2-ec55-855b9afb2bd0"
      },
      "source": [
        "train_lines = get_lines(data_dir+\"train.txt\")\n",
        "train_lines[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwXHgushT7pY"
      },
      "source": [
        "Let's write a function to perform the following steps:\n",
        "\n",
        "* Take a target file of abstract samples.\n",
        "* Read the lines in the target file.\n",
        "* For each line in the target file:\n",
        "  * If the line begins with ### mark it as an abstract ID and the beginning of a new abstract.\n",
        "    * Keep count of the number of lines in a sample.\n",
        "  * If the line begins with \\n mark it as the end of an abstract sample.\n",
        "    * Keep count of the total lines in a sample.\n",
        "  * Record the text before the \\t as the label of the line.\n",
        "  * Record the text after the \\t as the text of the line.\n",
        "* Return all of the lines in the target text file as a list of dictionaries containing the key/value pairs:\n",
        "  * \"line_number\" - the position of the line in the abstract (e.g. 3).\n",
        "  * \"target\" - the role of the line in the abstract (e.g. OBJECTIVE).\n",
        "  * \"text\" - the text of the line in the abstract.\n",
        "  * \"total_lines\" - the total lines in an abstract sample (e.g. 14).\n",
        "* Abstract ID's and newlines should be omitted from the returned preprocessed data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1deHBAEUhMe"
      },
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"\n",
        "  Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads its contents and sorts through each line,\n",
        "  extracting things like the target label, the text of the sentence,\n",
        "  how many sentences are in the current abstract and what sentence\n",
        "  number the target line is.\n",
        "\n",
        "  Args:\n",
        "    filename : a string of the target text file to read and extract line data from.\n",
        "  \n",
        "  Returns:\n",
        "     A list of dictionaries each containing a line from an abstract,\n",
        "     the lines label, the lines position in the abstract and the total\n",
        "     number of lines in the abstract where the line is from. For example:\n",
        "\n",
        "     [{\"target\":'Conclusion',\n",
        "     \"text\": \"The study couldn't have gone better\",\n",
        "     \"line_number\":8,\n",
        "     \"total_lines\":9}]\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename)     # get all lines from filename\n",
        "  abstract_lines = \"\"                   # create an empty abstract\n",
        "  abstract_samples = []                 # create an empty list of abstracts\n",
        "\n",
        "  # Loop through each line in target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith('###'):          # check to see if line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset abstract string\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create empty dict to store data from line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "    \n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "  \n",
        "  return abstract_samples"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOZpSqPEaC0K",
        "outputId": "8f42b126-ec82-405f-c051-d9cd6ea5faad"
      },
      "source": [
        "# Get data from file and preprocess it\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # dev is another name for validation set\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 436 ms, sys: 99.3 ms, total: 535 ms\n",
            "Wall time: 532 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgZfGCaiaHR0",
        "outputId": "6a365d71-3f10-4153-b814-b0e1293f70a7"
      },
      "source": [
        "# Check the first abstract of our training data\n",
        "train_samples[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 0,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 1,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 2,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 3,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 4,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 5,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 6,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 7,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 8,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 9,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'total_lines': 11}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "v0sJK23Wam7F",
        "outputId": "fa26d610-27b9-4bc6-dc7c-8f409f316ae4"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         target  ... total_lines\n",
              "0     OBJECTIVE  ...          11\n",
              "1       METHODS  ...          11\n",
              "2       METHODS  ...          11\n",
              "3       METHODS  ...          11\n",
              "4       METHODS  ...          11\n",
              "5       METHODS  ...          11\n",
              "6       RESULTS  ...          11\n",
              "7       RESULTS  ...          11\n",
              "8       RESULTS  ...          11\n",
              "9       RESULTS  ...          11\n",
              "10      RESULTS  ...          11\n",
              "11  CONCLUSIONS  ...          11\n",
              "12   BACKGROUND  ...          10\n",
              "13   BACKGROUND  ...          10\n",
              "\n",
              "[14 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4A6lpD1a61i",
        "outputId": "6204bfa3-9a17-40eb-db3f-012ef247fb9e"
      },
      "source": [
        "# Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "5mqVEHKpbH3o",
        "outputId": "6a643554-5468-4660-8a97-40b137e5a60d"
      },
      "source": [
        "train_df.total_lines.plot.hist();"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-cjhPuebNeF"
      },
      "source": [
        "### Get lists of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7olPj8Exb1ly",
        "outputId": "4ded948e-df7a-4efb-e53c-37597d59148b"
      },
      "source": [
        "# Convert abstract text lines into lists \n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSU4YdF0b4U_",
        "outputId": "bac23a9c-f7da-4264-fdd8-fa1ada106b6d"
      },
      "source": [
        "# View first 10 lines of training sentences\n",
        "train_sentences[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WmxmMebb7AV"
      },
      "source": [
        "## Make numeric labels \n",
        "\n",
        "We're going to create one hot and label encoded labels.\n",
        "\n",
        "We could get away with just making label encoded labels, however, TensorFlow's CategoricalCrossentropy loss function likes to have one hot encoded labels (this will enable us to use label smoothing later on).\n",
        "\n",
        "To numerically encode labels we'll use Scikit-Learn's OneHotEncoder and LabelEncoder classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hqVk3rAcgbJ",
        "outputId": "ba052c8d-d2b6-4a1b-c5ec-649c68283758"
      },
      "source": [
        "# One hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_one_hot"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqZ4a-UCckXH"
      },
      "source": [
        "### Label encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_3fhlWVcnVX",
        "outputId": "3cb63651-ed9c-47f0-f86c-dbbf4e034448"
      },
      "source": [
        "# Extract labels (\"target\" columns) and encode them into integers \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPHnRKKScpwV",
        "outputId": "412efffd-8399-44e8-c132-aa183afc23b6"
      },
      "source": [
        "# Get class names and number of classes from LabelEncoder instance \n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XK9k-DHcwpE"
      },
      "source": [
        "# Creating a series of model experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4v7aRdvFInv"
      },
      "source": [
        "## Model 0 : Getting a baseline\n",
        "\n",
        "Our first model we'll be a TF-IDF Multinomial Naive Bayes as recommended by Scikit-Learn's machine learning map.\n",
        "\n",
        "To build it, we'll create a Scikit-Learn Pipeline which uses the TfidfVectorizer class to convert our abstract sentences to numbers using the TF-IDF (term frequency-inverse document frequecy) algorithm and then learns to classify our sentences using the MultinomialNB aglorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2a4ozzxFPKc"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tf-idf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X=train_sentences,\n",
        "            y = train_labels_encoded);"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgkr8gYaF5Pv",
        "outputId": "4f729664-c291-44ae-8892-be6fe82b2c2e"
      },
      "source": [
        "# Evaluate baseline on validation dataset\n",
        "model_0.score(X = val_sentences,\n",
        "              y = val_labels_encoded)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rHdfS3bGENE",
        "outputId": "0e15c213-60cb-4775-c521-559071600b5b"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxVpyW4xGNZA"
      },
      "source": [
        "### Download helper functions script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dO5dSbPGU-K",
        "outputId": "ad3e2d43-03a4-4d51-9590-0cbf832579f4"
      },
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/prachuryanath/TF-Learning/main/extras/helper_functions.py"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-23 17:26:50--  https://raw.githubusercontent.com/prachuryanath/TF-Learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10235 (10.0K) [text/plain]\n",
            "Saving to: â€˜helper_functions.pyâ€™\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-23 17:26:50 (114 MB/s) - â€˜helper_functions.pyâ€™ saved [10235/10235]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeJolLFJGaFG",
        "outputId": "38afc2f6-2b1e-4307-fbf5-50348b24ea1c"
      },
      "source": [
        "# Import calculate_results helper function\n",
        "from helper_functions import calculate_results\n",
        "\n",
        "# Calculate baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'f1': 0.6989250353450294,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWE3W4EYGfEy"
      },
      "source": [
        "## Preparing our data for deep sequence models\n",
        "\n",
        "Excellent! We've got a working baseline to try and improve upon.\n",
        "\n",
        "But before we start building deeper models, we've got to create vectorization and embedding layers.\n",
        "\n",
        "The vectorization layer will convert our text to numbers and the embedding layer will capture the relationships between those numbers.\n",
        "\n",
        "To start creating our vectorization and embedding layers, we'll need to import the appropriate libraries (namely TensorFlow and NumPy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SUIHdX1GrOm"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx7tIeidIbX6",
        "outputId": "32e54928-1542-4f7a-f86f-722b313978a4"
      },
      "source": [
        "# How long is each sentence on average ?\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_lens = np.mean(sent_lens)\n",
        "avg_sent_lens"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IEbJrjoIIrfy",
        "outputId": "d75c5d47-c5d0-4562-fef3-cd9d7fe14ddc"
      },
      "source": [
        "# What's the distribution look like ?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=15)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([7.3163e+04, 8.1733e+04, 1.8772e+04, 4.5680e+03, 1.2400e+03,\n",
              "        3.5400e+02, 1.1600e+02, 4.5000e+01, 1.7000e+01, 1.2000e+01,\n",
              "        1.2000e+01, 3.0000e+00, 3.0000e+00, 1.0000e+00, 1.0000e+00]),\n",
              " array([  1.        ,  20.66666667,  40.33333333,  60.        ,\n",
              "         79.66666667,  99.33333333, 119.        , 138.66666667,\n",
              "        158.33333333, 178.        , 197.66666667, 217.33333333,\n",
              "        237.        , 256.66666667, 276.33333333, 296.        ]),\n",
              " <a list of 15 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je8OphXJI_4T",
        "outputId": "aaaabe41-9709-4904-e954-ac2176fa741a"
      },
      "source": [
        "# How long of a sentence covers 95% of the lengths?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAg6f0oJPeA"
      },
      "source": [
        "Wonderful! It looks like 95% of the sentences in our training set have a length of 55 tokens or less.\n",
        "\n",
        "When we create our tokenization layer, we'll use this value to turn all of our sentences into the same length. Meaning sentences with a length below 55 get padded with zeros and sentences with a length above 55 get truncated (words after 55 get cut off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE5cD-M-JYaM",
        "outputId": "24e13be0-f6aa-41d2-d057-b72daeb2f8b7"
      },
      "source": [
        "# Maximum sentence length in the training set\n",
        "max(sent_lens)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnUNv660JaSG"
      },
      "source": [
        "### Create text vectorizer\n",
        "\n",
        "Now we've got a little more information about our texts, let's create a way to turn it into numbers.\n",
        "\n",
        "To do so, we'll use the TextVectorization layer from TensorFlow.\n",
        "\n",
        "We'll keep all the parameters default except for max_tokens (the number of unique words in our dataset) and output_sequence_length (our desired output length for each vectorized sentence).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuMMxPTIJori"
      },
      "source": [
        "# How many words are in our vocabulary? (taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n",
        "max_tokens = 68000"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX-T69OpJqts"
      },
      "source": [
        "# Create text vectorizer\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, # number of words in vocabulary\n",
        "                                    output_sequence_length=55) # desired output length of vectorized sequences"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS_MU-0KJz9i"
      },
      "source": [
        "Great! Looks like our text_vectorizer is ready, let's adapt it to the training data (let it read the training data and figure out what number should represent what word) and then test it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmIQcCE1JvO7"
      },
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbymR2tRJyLZ",
        "outputId": "4dde2beb-fd73-4267-baa5-e2ece2cd6ae2"
      },
      "source": [
        "# Test out text vectorizer\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:\n",
            "nine subjects with incomplete cervical or thoracic sci received @ days of daily sessions of real or sham rtms applied over the contralateral m@ .\n",
            "\n",
            "Length of text: 25\n",
            "\n",
            "Vectorized text:\n",
            "[[1243  104    7 3444  883   16 2090 3676   80   84    4  161  416    4\n",
            "  2834   16  786 1997  551  145    2 3386  358    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAqJhJOJJ32h",
        "outputId": "4455d4d3-eeb3-465b-c54b-e50485d88153"
      },
      "source": [
        "# How many words in our training vocabulary?\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\"), \n",
        "print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocabulary: 64841\n",
            "Most common words in the vocabulary: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words in the vocabulary: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESWjEHYMKD5t",
        "outputId": "a1aef5f1-5269-455c-f735-0df491adfe2f"
      },
      "source": [
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dtype': 'string',\n",
              " 'max_tokens': 68000,\n",
              " 'name': 'text_vectorization',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True,\n",
              " 'vocabulary_size': 64841}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikIQmf_fKKNI"
      },
      "source": [
        "### Create custom text embedding\n",
        "\n",
        "Our token_vectorization layer maps the words in our text directly to numbers. However, this doesn't necessarily capture the relationships between those numbers.\n",
        "\n",
        "To create a richer numerical representation of our text, we can use an **embedding**.\n",
        "\n",
        "As our model learns (*by going through many different examples of abstract sentences and their labels*), it'll update its embedding to better represent the relationships between tokens in our corpus.\n",
        "\n",
        "We can create a trainable embedding layer using TensorFlow's `Embedding layer`.\n",
        "\n",
        "Once again, the main parameters we're concerned with here are the inputs and outputs of our `Embedding layer`.\n",
        "\n",
        "The input_dim parameter defines the size of our vocabulary. And the output_dim parameter defines the dimension of the embedding output.\n",
        "\n",
        "Once created, our embedding layer will take the integer outputs of our `text_vectorization` layer as inputs and convert them to feature vectors of size `output_dim`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq32taDUMUHl",
        "outputId": "f8dc5a20-d77f-4938-c209-6e0e55958dd1"
      },
      "source": [
        "# Create token embedding layer\n",
        "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab), # length of vocabulary\n",
        "                               output_dim=128, # Note: different embedding sizes result in drastically different numbers of parameters to train\n",
        "                               # Use masking to handle variable sequence lengths (save space)\n",
        "                               mask_zero=True,\n",
        "                               name=\"token_embedding\") \n",
        "\n",
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence before vectorization:\n",
            "nine subjects with incomplete cervical or thoracic sci received @ days of daily sessions of real or sham rtms applied over the contralateral m@ .\n",
            "\n",
            "Sentence after vectorization (before embedding):\n",
            "[[1243  104    7 3444  883   16 2090 3676   80   84    4  161  416    4\n",
            "  2834   16  786 1997  551  145    2 3386  358    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "\n",
            "Sentence after embedding:\n",
            "[[[ 0.01348465  0.02929083  0.00392659 ... -0.01400733  0.04088379\n",
            "    0.00228102]\n",
            "  [ 0.01219877 -0.03625812  0.02067217 ... -0.03294801  0.01889458\n",
            "   -0.0343359 ]\n",
            "  [ 0.02504835 -0.03175694 -0.03599029 ...  0.02461581 -0.00531886\n",
            "   -0.00933461]\n",
            "  ...\n",
            "  [ 0.04955104 -0.01590795 -0.02530006 ... -0.0122577   0.01604012\n",
            "   -0.0338878 ]\n",
            "  [ 0.04955104 -0.01590795 -0.02530006 ... -0.0122577   0.01604012\n",
            "   -0.0338878 ]\n",
            "  [ 0.04955104 -0.01590795 -0.02530006 ... -0.0122577   0.01604012\n",
            "   -0.0338878 ]]]\n",
            "\n",
            "Embedded sentence shape: (1, 55, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBbbVDpKMwbH"
      },
      "source": [
        "### Create datasets \n",
        "Namely, the tf.data API provides methods which enable faster data loading.\n",
        "\n",
        "The main steps we'll want to use with our data is to turn it into a `PrefetchDataset` of batches.\n",
        "\n",
        "Doing so we'll ensure TensorFlow loads our data onto the GPU as fast as possible, in turn leading to faster training time.\n",
        "\n",
        "To create a batched PrefetchDataset we can use the methods `batch()` and `prefetch()`, the parameter `tf.data.AUTOTUNE` will also allow TensorFlow to determine the optimal amount of compute to use to prepare datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZXBLJ62NBZ2",
        "outputId": "bfb150cd-5461-4313-c6fa-eff966fefa29"
      },
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rrX-anYNPe7",
        "outputId": "0538fccd-0904-4c6d-dd67-345fde84e018"
      },
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dn9x-rwNRgQ"
      },
      "source": [
        "## Model 1 : Conv1D with token embeddings\n",
        "\n",
        "All of our deep models will follow a similar structure:\n",
        "\n",
        "`Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)`\n",
        "\n",
        "The main component we'll be changing throughout is the Layers component. Because any modern deep NLP model requires text to be converted into an embedding before meaningful patterns can be discovered within.\n",
        "\n",
        "The first model we're going to build is a 1-dimensional Convolutional Neural Network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StCVFrLwNg4j"
      },
      "source": [
        "# Create 1D convolutional model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = text_vectorizer(inputs) # vectorize text inputs\n",
        "token_embeddings = token_embed(text_vectors) # create embedding\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile\n",
        "model_1.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPA6RZ65N5dk",
        "outputId": "0c9e78fd-38bd-4062-c40f-af2c1ae4df59"
      },
      "source": [
        "# Get summary of Conv1D model\n",
        "model_1.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 55)                0         \n",
            "_________________________________________________________________\n",
            "token_embedding (Embedding)  (None, 55, 128)           8299648   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 55, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz3ZVL8NN-E8"
      },
      "source": [
        "Since our training data contains nearly 200,000 sentences, fitting a deep model may take a while even with a GPU. So to keep our experiments swift, we're going to run them on a subset of the training dataset.\n",
        "\n",
        "More specifically, we'll only use the first 10% of batches (about 18,000 samples) of the training set to train on and the first 10% of batches from the validation set to validate on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7GdhSyXOQEG",
        "outputId": "cf69fbac-44a3-401d-b4e0-6d3aac0777fb"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)), # only fit on 10% of batches for faster training time\n",
        "                              epochs=3,\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1 * len(valid_dataset))) # only validate on 10% of batches"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 76s 80ms/step - loss: 0.9154 - accuracy: 0.6405 - val_loss: 0.6837 - val_accuracy: 0.7387\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 44s 79ms/step - loss: 0.6557 - accuracy: 0.7570 - val_loss: 0.6350 - val_accuracy: 0.7709\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 44s 79ms/step - loss: 0.6165 - accuracy: 0.7732 - val_loss: 0.5982 - val_accuracy: 0.7846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwM9iMbNOVkM",
        "outputId": "789a915b-3dad-48a8-dd94-db792dc48656"
      },
      "source": [
        "# Evaluate on whole validation dataset (we only validated on 10% of batches during training)\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 3s 3ms/step - loss: 0.5968 - accuracy: 0.7868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5967712998390198, 0.786806583404541]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m_AXUlQP_Fa",
        "outputId": "05e52858-fa0c-4cf4-b14a-a80ebed4ab5c"
      },
      "source": [
        "# Make predictions (our model outputs prediction probabilities for each class)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.4125023e-01, 1.5433425e-01, 5.0111357e-02, 3.2728365e-01,\n",
              "        2.7020553e-02],\n",
              "       [4.4626617e-01, 2.7208057e-01, 1.3776123e-02, 2.5868285e-01,\n",
              "        9.1943108e-03],\n",
              "       [2.0313431e-01, 5.6108679e-03, 2.3817108e-03, 7.8883314e-01,\n",
              "        3.9881525e-05],\n",
              "       ...,\n",
              "       [8.5454176e-06, 6.8426423e-04, 8.0649718e-04, 7.1723130e-06,\n",
              "        9.9849355e-01],\n",
              "       [5.5163093e-02, 4.8991960e-01, 8.5530467e-02, 5.8981486e-02,\n",
              "        3.1040534e-01],\n",
              "       [1.3629866e-01, 7.3072863e-01, 5.4836471e-02, 4.4155389e-02,\n",
              "        3.3980932e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on46vMnoQCjy",
        "outputId": "a38df7c1-427f-48b6-cba6-7788d15bdfcc"
      },
      "source": [
        "# Convert pred probs to classes\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "model_1_preds"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joubzlk9TfHY",
        "outputId": "c2fdf695-2e82-432d-c2b1-fa13c7e0c88f"
      },
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.68065669270489,\n",
              " 'f1': 0.784263455656665,\n",
              " 'precision': 0.7834684910112292,\n",
              " 'recall': 0.7868065669270489}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioEtyCWVThue"
      },
      "source": [
        "## Model 2 : Feature extraction with pretrained token embeddings\n",
        "\n",
        "The model structure will look like:\n",
        "\n",
        "`Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)`\n",
        "\n",
        "You'll notice the lack of tokenization layer we've used in a previous model. This is because the `Universal Sentence Encoder (USE)` takes care of tokenization for us.\n",
        "\n",
        "This type of model is called transfer learning, or more specifically, **feature extraction transfer learning**. In other words, taking the patterns a model has learned elsewhere and applying it to our own problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S5Yh76iT76y"
      },
      "source": [
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnTm9-ArUPWI",
        "outputId": "518b298c-047c-4448-eaed-734b953dd907"
      },
      "source": [
        "# Test out the embedding on a random sentence\n",
        "random_training_sentence = random.choice(train_sentences)\n",
        "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
        "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
        "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random training sentence:\n",
            "symptoms of reflux esophagitis was reported in @ ( @ % ) patients in the jejunal interposition group , @ ( @ % ) in esophageal with the posterial of residual-stomach group , and @ ( @ % ) in the roux-en-y esophagojejunostomy group ( p = @ ) .\n",
            "\n",
            "Sentence after embedding:\n",
            "[ 2.08063219e-02  4.68869843e-02  6.22762716e-04 -6.77089840e-02\n",
            " -1.16463834e-02  4.63287421e-02  5.24353795e-03 -3.39668617e-02\n",
            "  1.33028235e-02  5.55481203e-03  8.10434967e-02  5.89486361e-02\n",
            "  6.13912083e-02  3.81273367e-02 -1.16226096e-02 -5.31675527e-03\n",
            " -8.07069540e-02 -5.62218986e-02 -3.19995044e-04  7.81297684e-02\n",
            " -5.01513932e-05  5.58082350e-02  2.80014910e-02 -5.87897412e-02\n",
            " -4.32992280e-02  3.93515937e-02 -2.97608990e-02  2.98595373e-02\n",
            " -1.74950324e-02 -2.37226393e-03] (truncated output)...\n",
            "\n",
            "Length of sentence embedding:\n",
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BrYwbV7Ui9W"
      },
      "source": [
        "### Building and fitting an NLP feature extraction model from TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3PJYUHkUry3"
      },
      "source": [
        "# Define feature extractor model using TF Hub layer\n",
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
        "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
        "# Note: you could add more layers here if you wanted to\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n",
        "model_2 = tf.keras.Model(inputs=inputs,\n",
        "                        outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWzn7queUvJn",
        "outputId": "819c2160-b2f6-4d0e-e830-2b4c9a9dbb91"
      },
      "source": [
        "# Get a summary of the model\n",
        "model_2.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None,)]                 0         \n",
            "_________________________________________________________________\n",
            "universal_sentence_encoder ( (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFlxT8IjUxGv",
        "outputId": "f248d68c-7f76-4263-f48a-8a3bd27b343c"
      },
      "source": [
        "# Fit feature extractor model for 3 epochs\n",
        "model_2.fit(train_dataset,\n",
        "            steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "            epochs=3,\n",
        "            validation_data=valid_dataset,\n",
        "            validation_steps=int(0.1 * len(valid_dataset)))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 9s 12ms/step - loss: 0.9185 - accuracy: 0.6498 - val_loss: 0.7991 - val_accuracy: 0.6888\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 6s 11ms/step - loss: 0.7694 - accuracy: 0.7016 - val_loss: 0.7561 - val_accuracy: 0.7051\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 6s 11ms/step - loss: 0.7515 - accuracy: 0.7128 - val_loss: 0.7367 - val_accuracy: 0.7181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f09a4021910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYO8oGtZU1o9",
        "outputId": "0688bd0a-85db-4993-bee9-a3fe3140477c"
      },
      "source": [
        "# Evaluate on whole validation dataset\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 9s 10ms/step - loss: 0.7400 - accuracy: 0.7147\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7399705052375793, 0.714682936668396]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUxpOCHyVEhI",
        "outputId": "d2f823fc-1a36-4f53-b481-fa79b43feb2d"
      },
      "source": [
        "# Make predictions with feature extraction model\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.8542169e-01, 4.0848091e-01, 2.2965374e-03, 1.9636366e-01,\n",
              "        7.4371528e-03],\n",
              "       [3.3588755e-01, 4.9569061e-01, 4.5665223e-03, 1.6121574e-01,\n",
              "        2.6395512e-03],\n",
              "       [2.3647679e-01, 1.4214988e-01, 2.0852327e-02, 5.5981970e-01,\n",
              "        4.0701341e-02],\n",
              "       ...,\n",
              "       [1.8414613e-03, 6.2013445e-03, 4.9788900e-02, 8.2827598e-04,\n",
              "        9.4133997e-01],\n",
              "       [3.6170736e-03, 5.6223754e-02, 2.0157084e-01, 1.2353832e-03,\n",
              "        7.3735297e-01],\n",
              "       [1.9249250e-01, 2.6765841e-01, 4.7904262e-01, 6.2980703e-03,\n",
              "        5.4508403e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY2TbJqLVGLd",
        "outputId": "f554ea08-b7c7-4e3c-f4ea-9b3b832a84a2"
      },
      "source": [
        "# Convert the predictions with feature extraction model to classes\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([1, 1, 3, ..., 4, 4, 2])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Env6Ch23VINu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28d743d-d265-4bf3-992c-bf4bfe7f9e61"
      },
      "source": [
        "# Calculate results from TF Hub pretrained embeddings results on validation set\n",
        "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 71.46829074539917,\n",
              " 'f1': 0.7117274109480947,\n",
              " 'precision': 0.7153492788064629,\n",
              " 'recall': 0.7146829074539918}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJiGRfXgVKT0"
      },
      "source": [
        "## Model 3: Conv1D with character embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC2BUk8p5n_4"
      },
      "source": [
        "### Creating a character-level tokenizer\n",
        "\n",
        "We've built models with a custom token embedding and a pretrained token embedding, how about we build one using a character embedding?\n",
        "\n",
        "The difference between a character and token embedding is that the character embedding is created using sequences split into characters *(e.g. hello -> [h, e, l, l, o])* where as a token embedding is created on sequences split into tokens.\n",
        "\n",
        "We can create a character-level embedding by first vectorizing our sequences (after they've been split into characters) using the `TextVectorization` class and then passing those vectorized sequences through an `Embedding` layer.\n",
        "\n",
        "Before we can vectorize our sequences on a character-level we'll need to split them into characters. Let's write a function to do so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "lkAYI4dl5yg9",
        "outputId": "4d616e80-2c68-427d-bf20-af1ca09d27c3"
      },
      "source": [
        "# Make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Test splitting non-character-level sequence into characters\n",
        "split_chars(random_training_sentence)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'s y m p t o m s   o f   r e f l u x   e s o p h a g i t i s   w a s   r e p o r t e d   i n   @   (   @   %   )   p a t i e n t s   i n   t h e   j e j u n a l   i n t e r p o s i t i o n   g r o u p   ,   @   (   @   %   )   i n   e s o p h a g e a l   w i t h   t h e   p o s t e r i a l   o f   r e s i d u a l - s t o m a c h   g r o u p   ,   a n d   @   (   @   %   )   i n   t h e   r o u x - e n - y   e s o p h a g o j e j u n o s t o m y   g r o u p   (   p   =   @   )   .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ltr7Aa_6D18",
        "outputId": "6d5a047e-9b67-45b9-ecc0-0b4108eb8055"
      },
      "source": [
        "# Split sequence-level data splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "print(train_chars[0])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu5fg7Gq6PTL",
        "outputId": "ad997a8a-ecb7-4ec0-88b5-c0411eb76341"
      },
      "source": [
        "# What's the average character length?\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.3662574983337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8wXXI0Ol6Sk0",
        "outputId": "934fcf0b-3a8c-41bb-86ad-e5a0bdd1ef2c"
      },
      "source": [
        "# Check the distribution of our sequences at character-level\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens, bins=7);"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWqUlEQVR4nO3df6zddZ3n8edr2wF/zEqLdBimbbZ1bNxUsrNigzVuJsY6paCxbIKmxCzVYW12xV1n1kSLJkNWJYGdyTCSKA4jHYthQZZxlkZhu13EmE0W5CLKT5EroLQBe6UIu2P8Uee9f5zPhWO9/ZTec3vuFZ6P5OR+v+/P53vO+3xz73n1++PepqqQJOlw/sl8NyBJWtgMCklSl0EhSeoyKCRJXQaFJKlr8Xw3MNdOOumkWrVq1Xy3IUm/Ue68884fVdWymcZecEGxatUqJiYm5rsNSfqNkuT7hxvz1JMkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeo6YlAk2ZFkf5J7Zxj7UJJKclJbT5LLk0wmuTvJaUNztyZ5qD22DtVfn+Sets3lSdLqJybZ0+bvSbJ0bt6yJOloPJ8jis8Dmw4tJlkJbAR+MFQ+E1jTHtuAK9rcE4GLgDcApwMXDX3wXwG8b2i76dfaDtxSVWuAW9q6JGnMjvib2VX19SSrZhi6DPgwcONQbTNwdQ3+N6TbkixJcgrwZmBPVR0ASLIH2JTka8Arquq2Vr8aOBu4uT3Xm9vz7gS+BnzkqN7dUVq1/SvH8unn3KOXvG2+W5D0IjCraxRJNgP7qurbhwwtBx4bWt/bar363hnqACdX1eNt+Qng5E4/25JMJJmYmpo62rcjSeo46qBI8jLgo8CfzX07M2tHKIf9P1ur6sqqWldV65Ytm/FvWkmSZmk2RxS/D6wGvp3kUWAF8M0kvwvsA1YOzV3Rar36ihnqAD9sp61oX/fPoldJ0oiOOiiq6p6q+p2qWlVVqxicLjqtqp4AdgHntbuf1gNPt9NHu4GNSZa2i9gbgd1t7Jkk69vdTufx3DWPXcD03VFb+dVrIZKkMXk+t8deC/wf4DVJ9iY5vzP9JuBhYBL4G+D9AO0i9ieAO9rj49MXttucz7VtvsfgQjbAJcAfJXkIeGtblySN2fO56+ncI4yvGlou4ILDzNsB7JihPgGcOkP9SWDDkfqTJB1b/ma2JKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkrqOGBRJdiTZn+TeodqfJ/lOkruT/H2SJUNjFyaZTPJgkjOG6ptabTLJ9qH66iS3t/oXkxzX6se39ck2vmqu3rQk6fl7PkcUnwc2HVLbA5xaVf8C+C5wIUCStcAW4LVtm88kWZRkEfBp4ExgLXBumwtwKXBZVb0aeAo4v9XPB55q9cvaPEnSmB0xKKrq68CBQ2r/s6oOttXbgBVteTNwXVX9rKoeASaB09tjsqoerqqfA9cBm5MEeAtwQ9t+J3D20HPtbMs3ABvafEnSGM3FNYo/Bm5uy8uBx4bG9rba4eqvBH48FDrT9V95rjb+dJv/a5JsSzKRZGJqamrkNyRJes5IQZHkY8BB4Jq5aWd2qurKqlpXVeuWLVs2n61I0gvO4tlumOQ9wNuBDVVVrbwPWDk0bUWrcZj6k8CSJIvbUcPw/Onn2ptkMXBCmy9JGqNZHVEk2QR8GHhHVf1kaGgXsKXdsbQaWAN8A7gDWNPucDqOwQXvXS1gbgXOadtvBW4ceq6tbfkc4KtDgSRJGpMjHlEkuRZ4M3BSkr3ARQzucjoe2NOuL99WVf+uqu5Lcj1wP4NTUhdU1S/b83wA2A0sAnZU1X3tJT4CXJfkk8BdwFWtfhXwhSSTDC6mb5mD9ytJOkpHDIqqOneG8lUz1KbnXwxcPEP9JuCmGeoPM7gr6tD6T4F3Hqk/SdKx5W9mS5K6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXUcMiiQ7kuxPcu9Q7cQke5I81L4ubfUkuTzJZJK7k5w2tM3WNv+hJFuH6q9Pck/b5vIk6b2GJGm8ns8RxeeBTYfUtgO3VNUa4Ja2DnAmsKY9tgFXwOBDH7gIeANwOnDR0Af/FcD7hrbbdITXkCSN0RGDoqq+Dhw4pLwZ2NmWdwJnD9WvroHbgCVJTgHOAPZU1YGqegrYA2xqY6+oqtuqqoCrD3mumV5DkjRGs71GcXJVPd6WnwBObsvLgceG5u1ttV597wz13mv8miTbkkwkmZiamprF25EkHc7IF7PbkUDNQS+zfo2qurKq1lXVumXLlh3LViTpRWe2QfHDdtqI9nV/q+8DVg7NW9FqvfqKGeq915AkjdFsg2IXMH3n0lbgxqH6ee3up/XA0+300W5gY5Kl7SL2RmB3G3smyfp2t9N5hzzXTK8hSRqjxUeakORa4M3ASUn2Mrh76RLg+iTnA98H3tWm3wScBUwCPwHeC1BVB5J8Arijzft4VU1fIH8/gzurXgrc3B50XkOSNEZHDIqqOvcwQxtmmFvABYd5nh3AjhnqE8CpM9SfnOk1JEnj5W9mS5K6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXSMFRZI/TXJfknuTXJvkJUlWJ7k9yWSSLyY5rs09vq1PtvFVQ89zYas/mOSMofqmVptMsn2UXiVJszProEiyHPiPwLqqOhVYBGwBLgUuq6pXA08B57dNzgeeavXL2jySrG3bvRbYBHwmyaIki4BPA2cCa4Fz21xJ0hiNeuppMfDSJIuBlwGPA28BbmjjO4Gz2/Lmtk4b35AkrX5dVf2sqh4BJoHT22Oyqh6uqp8D17W5kqQxmnVQVNU+4C+AHzAIiKeBO4EfV9XBNm0vsLwtLwcea9sebPNfOVw/ZJvD1X9Nkm1JJpJMTE1NzfYtSZJmMMqpp6UM/oW/Gvg94OUMTh2NXVVdWVXrqmrdsmXL5qMFSXrBGuXU01uBR6pqqqp+AXwJeBOwpJ2KAlgB7GvL+4CVAG38BODJ4foh2xyuLkkao1GC4gfA+iQva9caNgD3A7cC57Q5W4Eb2/Kutk4b/2pVVatvaXdFrQbWAN8A7gDWtLuojmNwwXvXCP1KkmZh8ZGnzKyqbk9yA/BN4CBwF3Al8BXguiSfbLWr2iZXAV9IMgkcYPDBT1Xdl+R6BiFzELigqn4JkOQDwG4Gd1TtqKr7ZtuvJGl2Zh0UAFV1EXDRIeWHGdyxdOjcnwLvPMzzXAxcPEP9JuCmUXqUJI3G38yWJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUtdIQZFkSZIbknwnyQNJ3pjkxCR7kjzUvi5tc5Pk8iSTSe5OctrQ82xt8x9KsnWo/vok97RtLk+SUfqVJB29UY8oPgX8j6r658AfAA8A24FbqmoNcEtbBzgTWNMe24ArAJKcCFwEvAE4HbhoOlzanPcNbbdpxH4lSUdp1kGR5ATgD4GrAKrq51X1Y2AzsLNN2wmc3ZY3A1fXwG3AkiSnAGcAe6rqQFU9BewBNrWxV1TVbVVVwNVDzyVJGpNRjihWA1PA3ya5K8nnkrwcOLmqHm9zngBObsvLgceGtt/bar363hnqvybJtiQTSSampqZGeEuSpEONEhSLgdOAK6rqdcA/8NxpJgDakUCN8BrPS1VdWVXrqmrdsmXLjvXLSdKLyihBsRfYW1W3t/UbGATHD9tpI9rX/W18H7ByaPsVrdarr5ihLkkao1kHRVU9ATyW5DWttAG4H9gFTN+5tBW4sS3vAs5rdz+tB55up6h2AxuTLG0XsTcCu9vYM0nWt7udzht6LknSmCwecfv/AFyT5DjgYeC9DMLn+iTnA98H3tXm3gScBUwCP2lzqaoDST4B3NHmfbyqDrTl9wOfB14K3NwekqQxGikoqupbwLoZhjbMMLeACw7zPDuAHTPUJ4BTR+lRkjQafzNbktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqGjkokixKcleSL7f11UluTzKZ5ItJjmv149v6ZBtfNfQcF7b6g0nOGKpvarXJJNtH7VWSdPTm4ojig8ADQ+uXApdV1auBp4DzW/184KlWv6zNI8laYAvwWmAT8JkWPouATwNnAmuBc9tcSdIYjRQUSVYAbwM+19YDvAW4oU3ZCZzdlje3ddr4hjZ/M3BdVf2sqh4BJoHT22Oyqh6uqp8D17W5kqQxGvWI4q+ADwP/2NZfCfy4qg629b3A8ra8HHgMoI0/3eY/Wz9km8PVf02SbUkmkkxMTU2N+JYkScNmHRRJ3g7sr6o757CfWamqK6tqXVWtW7Zs2Xy3I0kvKItH2PZNwDuSnAW8BHgF8ClgSZLF7ahhBbCvzd8HrAT2JlkMnAA8OVSfNrzN4eqSpDGZ9RFFVV1YVSuqahWDi9Ffrap3A7cC57RpW4Eb2/Kutk4b/2pVVatvaXdFrQbWAN8A7gDWtLuojmuvsWu2/UqSZmeUI4rD+QhwXZJPAncBV7X6VcAXkkwCBxh88FNV9yW5HrgfOAhcUFW/BEjyAWA3sAjYUVX3HYN+f2Ot2v6V+W7heXv0krfNdwuSZmlOgqKqvgZ8rS0/zOCOpUPn/BR452G2vxi4eIb6TcBNc9GjJGl2/M1sSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpa9ZBkWRlkluT3J/kviQfbPUTk+xJ8lD7urTVk+TyJJNJ7k5y2tBzbW3zH0qydaj++iT3tG0uT5JR3qwk6eiNckRxEPhQVa0F1gMXJFkLbAduqao1wC1tHeBMYE17bAOugEGwABcBbwBOBy6aDpc2531D220aoV9J0izMOiiq6vGq+mZb/r/AA8ByYDOws03bCZzdljcDV9fAbcCSJKcAZwB7qupAVT0F7AE2tbFXVNVtVVXA1UPPJUkakzm5RpFkFfA64Hbg5Kp6vA09AZzclpcDjw1ttrfVevW9M9Rnev1tSSaSTExNTY30XiRJv2rkoEjy28DfAX9SVc8Mj7UjgRr1NY6kqq6sqnVVtW7ZsmXH+uUk6UVlpKBI8lsMQuKaqvpSK/+wnTaifd3f6vuAlUObr2i1Xn3FDHVJ0hiNctdTgKuAB6rqL4eGdgHTdy5tBW4cqp/X7n5aDzzdTlHtBjYmWdouYm8EdrexZ5Ksb6913tBzSZLGZPEI274J+DfAPUm+1WofBS4Brk9yPvB94F1t7CbgLGAS+AnwXoCqOpDkE8Adbd7Hq+pAW34/8HngpcDN7SFJGqNZB0VV/W/gcL/XsGGG+QVccJjn2gHsmKE+AZw62x4lSaPzN7MlSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1LV4vhs4kiSbgE8Bi4DPVdUl89ySZmHV9q/MdwtH5dFL3jbfLUgLxoI+okiyCPg0cCawFjg3ydr57UqSXlwWdFAApwOTVfVwVf0cuA7YPM89SdKLykI/9bQceGxofS/whkMnJdkGbGur/y/Jg7N8vZOAH81y2/lgv8dILgV+g/pt7PfYeqH3+88ON7DQg+J5qaorgStHfZ4kE1W1bg5aGgv7Pbbs99iy32NrLvtd6Kee9gErh9ZXtJokaUwWelDcAaxJsjrJccAWYNc89yRJLyoL+tRTVR1M8gFgN4PbY3dU1X3H8CVHPn01ZvZ7bNnvsWW/x9ac9ZuqmqvnkiS9AC30U0+SpHlmUEiSugwKBn8mJMmDSSaTbJ/vfgCSrExya5L7k9yX5IOtfmKSPUkeal+XtnqSXN7ew91JTpunvhcluSvJl9v66iS3t76+2G5KIMnxbX2yja+ah16XJLkhyXeSPJDkjQt5/yb50/a9cG+Sa5O8ZCHt3yQ7kuxPcu9Q7aj3Z5Ktbf5DSbaOud8/b98Pdyf5+yRLhsYubP0+mOSMofpYPj9m6ndo7ENJKslJbX1u929VvagfDC6Sfw94FXAc8G1g7QLo6xTgtLb8T4HvMvgzJv8F2N7q24FL2/JZwM1AgPXA7fPU938C/ivw5bZ+PbClLX8W+Pdt+f3AZ9vyFuCL89DrTuDftuXjgCULdf8y+OXTR4CXDu3X9yyk/Qv8IXAacO9Q7aj2J3Ai8HD7urQtLx1jvxuBxW350qF+17bPhuOB1e0zY9E4Pz9m6rfVVzK44ef7wEnHYv+O9QdzIT6ANwK7h9YvBC6c775m6PNG4I+AB4FTWu0U4MG2/NfAuUPzn503xh5XALcAbwG+3L5JfzT0g/fsvm7f2G9sy4vbvIyx1xPaB28OqS/I/ctzf6XgxLa/vgycsdD2L7DqkA/eo9qfwLnAXw/Vf2Xese73kLF/DVzTln/lc2F6/47782OmfoEbgD8AHuW5oJjT/eupp5n/TMjyeeplRu20weuA24GTq+rxNvQEcHJbXgjv46+ADwP/2NZfCfy4qg7O0NOz/bbxp9v8cVkNTAF/206VfS7Jy1mg+7eq9gF/AfwAeJzB/rqThbt/px3t/lwI38fT/pjBv8phgfabZDOwr6q+fcjQnPZrUCxwSX4b+DvgT6rqmeGxGvyTYEHc35zk7cD+qrpzvnt5nhYzOIy/oqpeB/wDg1Mjz1pg+3cpgz+IuRr4PeDlwKZ5beooLaT9eSRJPgYcBK6Z714OJ8nLgI8Cf3asX8ugWMB/JiTJbzEIiWuq6kut/MMkp7TxU4D9rT7f7+NNwDuSPMrgr/y+hcH/I7IkyfQvdg739Gy/bfwE4Mkx9rsX2FtVt7f1GxgEx0Ldv28FHqmqqar6BfAlBvt8oe7faUe7P+d7P5PkPcDbgXe3cKPT13z2+/sM/uHw7fZztwL4ZpLf7fQ1q34NigX6Z0KSBLgKeKCq/nJoaBcwfafCVgbXLqbr57W7HdYDTw8d8h9zVXVhVa2oqlUM9uFXq+rdwK3AOYfpd/p9nNPmj+1fm1X1BPBYkte00gbgfhbo/mVwyml9kpe1743pfhfk/h1ytPtzN7AxydJ2FLWx1cYig/8o7cPAO6rqJ0NDu4At7W6y1cAa4BvM4+dHVd1TVb9TVavaz91eBjfAPMFc799jddHlN+nB4A6B7zK4e+Fj891P6+lfMThMvxv4VnucxeA88y3AQ8D/Ak5s88PgP3n6HnAPsG4ee38zz9319CoGP1CTwH8Djm/1l7T1yTb+qnno818CE20f/3cGd4Es2P0L/GfgO8C9wBcY3IGzYPYvcC2D6ye/aB9a589mfzK4NjDZHu8dc7+TDM7hT//MfXZo/sdavw8CZw7Vx/L5MVO/h4w/ynMXs+d0//onPCRJXZ56kiR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXf8fWfBom7qekSwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ifuLnxi6WWN",
        "outputId": "bd38a9a0-1e26-418b-dea6-cfec2d87eab6"
      },
      "source": [
        "# Find what character length covers 95% of seuences\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_-KpsgC6cup"
      },
      "source": [
        "We'll set max_tokens (the total number of different characters in our sequences) to 28, in other words, 26 letters of the alphabet + space + OOV (out of vocabulary or unknown) tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5AH0YKoX6k_D",
        "outputId": "088827e4-2b3d-4259-bf0d-a52f5049c6fd"
      },
      "source": [
        "# Get all keyboard characters for char-level embedding\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkfcUvwY6m8S"
      },
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 # num characters in alphabet + space + OOV token\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,  \n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    name=\"char_vectorizer\")\n",
        "\n",
        "# Adapt character vectorizer to training characters\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rb3poVE6pif",
        "outputId": "59783485-0c3b-47a7-ff92-e2769d1216d0"
      },
      "source": [
        "# Check character vocabulary characteristics\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
        "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
        "print(f\"5 least common characters: {char_vocab[-5:]}\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of different characters in character vocab: 28\n",
            "5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n",
            "5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIK0hHQE6tUX",
        "outputId": "c6d2aba8-fb25-4860-e4a0-c590b720de54"
      },
      "source": [
        "# Test out character vectorizer\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n{random_train_chars}\")\n",
        "print(f\"\\nLength of chars: {len(random_train_chars.split())}\")\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorized chars:\\n{vectorized_chars}\")\n",
        "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Charified text:\n",
            "a   s e c o n d   c o u r s e   o f   a t d   t h e r a p y   c a n   b r i n g   a b o u t   a   s a t i s f y i n g   l o n g - t e r m   r e m i s s i o n   o n   r e c u r r e n t   g d   .\n",
            "\n",
            "Length of chars: 81\n",
            "\n",
            "Vectorized chars:\n",
            "[[ 5  9  2 11  7  6 10 11  7 16  8  9  2  7 17  5  3 10  3 13  2  8  5 14\n",
            "  19 11  5  6 22  8  4  6 18  5 22  7 16  3  5  9  5  3  4  9 17 19  4  6\n",
            "  18 12  7  6 18  3  2  8 15  8  2 15  4  9  9  4  7  6  7  6  8  2 11 16\n",
            "   8  8  2  6  3 18 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n",
            "\n",
            "Length of vectorized chars: 290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xCvrv496vtE"
      },
      "source": [
        "You'll notice sequences with a length shorter than 290 (`output_seq_char_length`) get padded with zeros on the end, this ensures all sequences passed to our model are the same length.\n",
        "\n",
        "Also, due to the standardize parameter of `TextVectorization` being \"`lower_and_strip_punctuation`\" and the split parameter being \"`whitespace`\" by default, symbols (such as @) and spaces are removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL3O6RWI7yGH"
      },
      "source": [
        "### Creating a character-level embedding\n",
        "\n",
        "We've got a way to vectorize our character-level sequences, now's time to create a character-level embedding.\n",
        "\n",
        "Just like our custom token embedding, we can do so using the `tensorflow.keras.layers.Embedding` class.\n",
        "\n",
        "Our character-level embedding layer requires an input dimension and output dimension.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_llxFGT8CWD",
        "outputId": "efa66755-3eb5-4d72-9f5d-2558b38a056b"
      },
      "source": [
        "# Create char embedding layer\n",
        "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, # number of different characters\n",
        "                              output_dim=25, # embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)\n",
        "                              mask_zero=True,\n",
        "                              name=\"char_embed\")\n",
        "\n",
        "# Test out character embedding layer\n",
        "print(f\"Charified text (before vectorization and embedding):\\n{random_train_chars}\\n\")\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f\"Embedded chars (after vectorization and embedding):\\n{char_embed_example}\\n\")\n",
        "print(f\"Character embedding shape: {char_embed_example.shape}\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Charified text (before vectorization and embedding):\n",
            "a   s e c o n d   c o u r s e   o f   a t d   t h e r a p y   c a n   b r i n g   a b o u t   a   s a t i s f y i n g   l o n g - t e r m   r e m i s s i o n   o n   r e c u r r e n t   g d   .\n",
            "\n",
            "Embedded chars (after vectorization and embedding):\n",
            "[[[-0.01527715 -0.03468176  0.00368496 ... -0.03219478  0.00254216\n",
            "    0.04092336]\n",
            "  [-0.02755555 -0.02175934 -0.04397463 ... -0.0350431  -0.01678824\n",
            "   -0.02483918]\n",
            "  [ 0.03034412  0.04768774  0.0142568  ... -0.0270498   0.02661158\n",
            "   -0.03379227]\n",
            "  ...\n",
            "  [-0.03391    -0.02729326  0.0367342  ...  0.03198892 -0.00696387\n",
            "   -0.03662505]\n",
            "  [-0.03391    -0.02729326  0.0367342  ...  0.03198892 -0.00696387\n",
            "   -0.03662505]\n",
            "  [-0.03391    -0.02729326  0.0367342  ...  0.03198892 -0.00696387\n",
            "   -0.03662505]]]\n",
            "\n",
            "Character embedding shape: (1, 290, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvJnKmS_644R"
      },
      "source": [
        "### Building a Conv1D model to fit on character embeddings\n",
        "\n",
        "Now we've got a way to turn our character-level sequences into numbers (`char_vectorizer`) as well as numerically represent them as an embedding (`char_embed`) let's test how effective they are at encoding the information in our sequences by creating a character-level sequence model.\n",
        "\n",
        "The model will have the same structure as our custom token embedding model (`model_1`) except it'll take character-level sequences as input instead of token-level sequences.\n",
        "\n",
        "`Input (character-level text) -> Tokenize -> Embedding -> Layers (Conv1D, GlobalMaxPool1D) -> Output (label probability)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN0SlIG57ORy"
      },
      "source": [
        "# Make Conv1D on chars only\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_3 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=\"model_3_conv1D_char_embedding\")\n",
        "\n",
        "# Compile model\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ofjKXir7cQF",
        "outputId": "687e12c3-f6c8-4489-9b9e-2c8445ef752d"
      },
      "source": [
        "# Check the summary of conv1d_char_model\n",
        "model_3.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3_conv1D_char_embedding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "char_vectorizer (TextVectori (None, 290)               0         \n",
            "_________________________________________________________________\n",
            "char_embed (Embedding)       (None, 290, 25)           1750      \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 290, 64)           8064      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 10,139\n",
            "Trainable params: 10,139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9kZizVf7eHQ",
        "outputId": "69677887-dcdd-46f2-f92f-a89aaea3be88"
      },
      "source": [
        "# Create char datasets\n",
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_char_dataset"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDJ8Jvct7gY1",
        "outputId": "41f8811a-a365-4dfd-c390-892594e6da99"
      },
      "source": [
        "# Fit the model on chars only\n",
        "model_3_history = model_3.fit(train_char_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_dataset)))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 4s 6ms/step - loss: 1.2653 - accuracy: 0.4968 - val_loss: 1.0505 - val_accuracy: 0.5971\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 3s 6ms/step - loss: 1.0089 - accuracy: 0.5982 - val_loss: 0.9373 - val_accuracy: 0.6330\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 3s 6ms/step - loss: 0.9232 - accuracy: 0.6394 - val_loss: 0.8584 - val_accuracy: 0.6745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs03Xb7K7kKt"
      },
      "source": [
        "## Model 4: Combining pretrained token embeddings + character embeddings (hybrid embedding layer)\n",
        "\n",
        "To start replicating (or getting close to replicating) the model in Figure 1, we're going to go through the following steps:\n",
        "\n",
        "1. Create a token-level model (similar to `model_1`)\n",
        "2. Create a character-level model (similar to `model_3` with a slight modification to reflect the paper)\n",
        "3. Combine (using `layers.Concatenate`) the outputs of 1 and 2\n",
        "4. Build a series of output layers on top of 3\n",
        "5. Construct a model which takes token and character-level sequences as input and produces sequence label probabilities as output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgTvcwOt8_mZ"
      },
      "source": [
        "# 1. Setup token inputs/model\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_output)\n",
        "\n",
        "# 2. Setup char inputs/model\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # bi-LSTM shown in Figure 1 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Concatenate token and char inputs (create hybrid token embedding)\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output, \n",
        "                                                                  char_model.output])\n",
        "\n",
        "# 4. Create output layers - addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout) # slightly different to Figure 1 due to different shapes of token/char embedding layers\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
        "\n",
        "# 5. Construct model with char and token inputs\n",
        "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name=\"model_4_token_and_char_embeddings\")"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk9S9v1B9QUz",
        "outputId": "bcb89a0d-1a38-4ccd-a5b0-a6057c8b04b7"
      },
      "source": [
        "# Get summary of token and character model\n",
        "model_4.summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4_token_and_char_embeddings\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_input (InputLayer)         [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "token_input (InputLayer)        [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_vectorizer (TextVectorizat (None, 290)          0           char_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "universal_sentence_encoder (Ker (None, 512)          256797824   token_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "char_embed (Embedding)          (None, 290, 25)      1750        char_vectorizer[2][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 128)          65664       universal_sentence_encoder[1][0] \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 50)           10200       char_embed[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "token_char_hybrid (Concatenate) (None, 178)          0           dense_4[0][0]                    \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 178)          0           token_char_hybrid[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 200)          35800       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 5)            1005        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 256,912,243\n",
            "Trainable params: 114,419\n",
            "Non-trainable params: 256,797,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "ayc8_xZk9rJU",
        "outputId": "51c04647-c979-4fb3-f8eb-8bf9bdfa53ea"
      },
      "source": [
        "# Plot hybrid token and character model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_4)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG9W0kEP9ve_"
      },
      "source": [
        "# Compile token char model\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(), # section 4.2 of https://arxiv.org/pdf/1612.05251.pdf mentions using SGD but we'll stick with Adam\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Q9rK8I96lF"
      },
      "source": [
        "### Combining token and character data into a tf.data dataset\n",
        "\n",
        "To keep our experiments fast, we'll fit our token-character-hybrid model on 10% of training and validate on 10% of validation batches. However, the difference with this model is that it requires two inputs, token-level sequences and character-level sequences.\n",
        "\n",
        "We can do this by create a tf.data.Dataset with a tuple as it's first input, for example:\n",
        "\n",
        "* `((token_data, char_data), (label))`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lmlsJF5_KsT"
      },
      "source": [
        "# Combine chars and tokens into a dataset\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # make data\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # combine data and labels\n",
        "\n",
        "# Prefetch and batch train data\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) \n",
        "\n",
        "# Repeat same steps validation data\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7u_Zwgf_NON",
        "outputId": "c9207271-3b8c-45d9-bc70-5e29905aafd2"
      },
      "source": [
        "# Check out training char and token embedding dataset\n",
        "train_char_token_dataset, val_char_token_dataset"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>,\n",
              " <PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83dkpfH5_PMa"
      },
      "source": [
        "### Fitting a model on token and character-level sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8omi3OT_eUe",
        "outputId": "8056a28d-b631-4407-a963-0a3538e0cbd0"
      },
      "source": [
        "# Fit the model on tokens and chars\n",
        "model_4_history = model_4.fit(train_char_token_dataset, # train on dataset of token and characters\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_token_dataset)))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 35s 48ms/step - loss: 0.9660 - accuracy: 0.6162 - val_loss: 0.7762 - val_accuracy: 0.7038\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 25s 45ms/step - loss: 0.7905 - accuracy: 0.6942 - val_loss: 0.7141 - val_accuracy: 0.7257\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 23s 40ms/step - loss: 0.7684 - accuracy: 0.7065 - val_loss: 0.6911 - val_accuracy: 0.7360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtKW5j6O_gEg",
        "outputId": "0100368b-9081-44cb-a685-a78f693144a4"
      },
      "source": [
        "# Evaluate on the whole validation dataset\n",
        "model_4.evaluate(val_char_token_dataset)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 20s 21ms/step - loss: 0.6955 - accuracy: 0.7345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6955002546310425, 0.7345094680786133]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWbtU3IA_hpz",
        "outputId": "5f1bb09e-714e-472f-c922-7298a3742bd9"
      },
      "source": [
        "# Make predictions using the token-character model hybrid\n",
        "model_4_pred_probs = model_4.predict(val_char_token_dataset)\n",
        "model_4_pred_probs"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.0942553e-01, 3.5972768e-01, 4.7814948e-03, 2.1791780e-01,\n",
              "        8.1475452e-03],\n",
              "       [3.3812651e-01, 4.1246369e-01, 3.8940003e-03, 2.4322543e-01,\n",
              "        2.2904486e-03],\n",
              "       [2.8525928e-01, 8.8772811e-02, 5.9874892e-02, 5.3525203e-01,\n",
              "        3.0841004e-02],\n",
              "       ...,\n",
              "       [4.6707597e-04, 8.4131351e-03, 6.5805033e-02, 3.0486795e-04,\n",
              "        9.2500991e-01],\n",
              "       [1.0519034e-02, 7.0276901e-02, 2.0390257e-01, 5.9772511e-03,\n",
              "        7.0932424e-01],\n",
              "       [3.6633334e-01, 3.9268538e-01, 1.7613292e-01, 3.4696881e-02,\n",
              "        3.0151470e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iskz6lBN_jnU",
        "outputId": "c1c76bd4-de3a-4f5f-a207-d30b68a9998e"
      },
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model_4_preds = tf.argmax(model_4_pred_probs, axis=1)\n",
        "model_4_preds"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPlHumgd_lfU",
        "outputId": "b8de3c55-1a0e-48b8-96bc-8e08d0fc0acc"
      },
      "source": [
        "# Get results of token-char-hybrid model\n",
        "model_4_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 73.45094664371773,\n",
              " 'f1': 0.7323752567890249,\n",
              " 'precision': 0.733973832616795,\n",
              " 'recall': 0.7345094664371773}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    }
  ]
}