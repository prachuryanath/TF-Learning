{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_SkimLit_nlp_milestone_project_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOVa3jRQdY1U5KQuCMmFcwB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prachuryanath/TF-Learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc96wwcKO-El"
      },
      "source": [
        "# Milestone Project 2 : SkimLit \n",
        "\n",
        "In this project, we're going to be putting what we've learned into practice.\n",
        "\n",
        "More specificially, we're going to be replicating the deep learning model behind the 2017 paper `PubMed 200k RCT: a Dataset for Sequenctial Sentence Classification in Medical Abstracts`.\n",
        "\n",
        "When it was released, the paper presented a new dataset called `PubMed 200k RCT which consists of ~200,000 labelled Randomized Controlled Trial (RCT) abstracts`.\n",
        "\n",
        "The goal of the dataset was to explore the ability for NLP models to classify sentences which appear in sequential order.\n",
        "\n",
        "### **Problem in a sentence**\n",
        "*The number of RCT papers released is continuing to increase, those without structured abstracts can be hard to read and in turn slow down researchers moving through the literature.*\n",
        "\n",
        "### **Solution in a sentence**\n",
        "*Create an NLP model to classify abstract sentences into the role they play (e.g. objective, methods, results, etc) to enable researchers to skim through the literature (hence SkimLit ðŸ¤“ðŸ”¥) and dive deeper when necessary.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49iOYPcIPeRI"
      },
      "source": [
        "## What we're going to cover\n",
        "Time to take what we've learned in the NLP fundmentals notebook and build our biggest NLP model yet:\n",
        "\n",
        "* Downloading a text dataset (PubMed RCT200k from GitHub)\n",
        "* Writing a preprocessing function to prepare our data for modelling\n",
        "* Setting up a series of modelling experiments\n",
        "  * Making a baseline (TF-IDF classifier)\n",
        "  * Deep models with different combinations of: token embeddings, character embeddings, pretrained embeddings, positional embeddings\n",
        "* Building our first multimodal model (taking multiple types of data inputs)\n",
        "  * Replicating the model architecture from https://arxiv.org/pdf/1612.05251.pdf\n",
        "* Find the most wrong predictions\n",
        "* Making predictions on PubMed abstracts from the wild"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbHryq10QGlA",
        "outputId": "09d5ab3f-839a-4c6f-b3d5-e957d5416c1c"
      },
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun 15 14:30:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXj_Ou67QU0U"
      },
      "source": [
        "## Get data\n",
        "\n",
        "Before we can start building a model, we've got to download the PubMed 200k RCT dataset.\n",
        "\n",
        "In a phenomenal act of kindness, the authors of the paper have made the data they used for their research availably publically and for free in the form of .txt files on GitHub.\n",
        "\n",
        "We can copy them to our local directory using git clone `https://github.com/Franck-Dernoncourt/pubmed-rct.`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ5b5_lMQuJV",
        "outputId": "d7925778-5f8f-4308-8c6b-f52376c61489"
      },
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Total 30 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (30/30), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSrJNVHRQ0aQ"
      },
      "source": [
        "Looking at the README file from the GitHub page, we get the following information:\n",
        "\n",
        "* `PubMed 20k` is a subset of `PubMed 200k`. I.e., any abstract present in `PubMed 20k` is also present in `PubMed 200k`.\n",
        "* `PubMed_200k_RCT` is the same as `PubMed_200k_RCT_numbers_replaced_with_at_sign`, except that in the latter all numbers had been replaced by @. (same for `PubMed_20k_RCT` vs. `PubMed_20k_RCT_numbers_replaced_with_at_sign`).\n",
        "* Since Github file size limit is 100 MiB, we had to compress `PubMed_200k_RCT\\train.7z` and `PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip`. To uncompress train.7z, you may use 7-Zip on Windows, Keka on Mac OS X, or p7zip on Linux.\n",
        "\n",
        "To begin with, the dataset we're going to be focused on is `PubMed_20k_RCT_numbers_replaced_with_at_sign`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1liAnC0R5Zc",
        "outputId": "8b4920f7-33a1-4e60-a4c9-558008efee8d"
      },
      "source": [
        "# Check what files are in the PubMed_20K dataset \n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9v0_aP8SJWc"
      },
      "source": [
        "Beautiful, looks like we've got three separate text files:\n",
        "\n",
        "* **train.txt** - *training samples.*\n",
        "* **dev.txt** - *dev is short for development set, which is another name for validation set (in our case, we'll be using and referring to this file as our validation set).*\n",
        "* **test.txt** - *test samples.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z72jYlzJSATJ"
      },
      "source": [
        "# Start by using the 20k dataset\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXbC3PBRSDHX",
        "outputId": "85d96c23-108a-4267-ac7a-60e06c44e3ae"
      },
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc8I6W8nSE75"
      },
      "source": [
        "## Preprocess data\n",
        "\n",
        "To get familiar and understand how we have to prepare our data for our deep learning models, we've got to visualize it.\n",
        "\n",
        "Because our data is in the form of text files, let's write some code to read each of the lines in a target file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXXE_zSsShAx"
      },
      "source": [
        "# Create function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Reads filename (a text file) and returns the lines of text as a list\n",
        "\n",
        "  Args:\n",
        "    filename : a string containing the target filepath to read.\n",
        "\n",
        "  Returns:\n",
        "    A list of strings with one string per line from the target filename.\n",
        "    For example:\n",
        "    [\"this is the first line of filename\",\n",
        "    \"this is the second line of filename\",\n",
        "    ...]\n",
        "  \"\"\"\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLH534ogTwad",
        "outputId": "3a1c9f7e-0bcd-4e6b-cad4-01b516447473"
      },
      "source": [
        "train_lines = get_lines(data_dir+\"train.txt\")\n",
        "train_lines[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwXHgushT7pY"
      },
      "source": [
        "Let's write a function to perform the following steps:\n",
        "\n",
        "* Take a target file of abstract samples.\n",
        "* Read the lines in the target file.\n",
        "* For each line in the target file:\n",
        "  * If the line begins with ### mark it as an abstract ID and the beginning of a new abstract.\n",
        "    * Keep count of the number of lines in a sample.\n",
        "  * If the line begins with \\n mark it as the end of an abstract sample.\n",
        "    * Keep count of the total lines in a sample.\n",
        "  * Record the text before the \\t as the label of the line.\n",
        "  * Record the text after the \\t as the text of the line.\n",
        "* Return all of the lines in the target text file as a list of dictionaries containing the key/value pairs:\n",
        "  * \"line_number\" - the position of the line in the abstract (e.g. 3).\n",
        "  * \"target\" - the role of the line in the abstract (e.g. OBJECTIVE).\n",
        "  * \"text\" - the text of the line in the abstract.\n",
        "  * \"total_lines\" - the total lines in an abstract sample (e.g. 14).\n",
        "* Abstract ID's and newlines should be omitted from the returned preprocessed data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1deHBAEUhMe"
      },
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"\n",
        "  Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads its contents and sorts through each line,\n",
        "  extracting things like the target label, the text of the sentence,\n",
        "  how many sentences are in the current abstract and what sentence\n",
        "  number the target line is.\n",
        "\n",
        "  Args:\n",
        "    filename : a string of the target text file to read and extract line data from.\n",
        "  \n",
        "  Returns:\n",
        "     A list of dictionaries each containing a line from an abstract,\n",
        "     the lines label, the lines position in the abstract and the total\n",
        "     number of lines in the abstract where the line is from. For example:\n",
        "\n",
        "     [{\"target\":'Conclusion',\n",
        "     \"text\": \"The study couldn't have gone better\",\n",
        "     \"line_number\":8,\n",
        "     \"total_lines\":9}]\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename)     # get all lines from filename\n",
        "  abstract_lines = \"\"                   # create an empty abstract\n",
        "  abstract_samples = []                 # create an empty list of abstracts\n",
        "\n",
        "  # Loop through each line in target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith('###'):          # check to see if line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset abstract string\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create empty dict to store data from line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "    \n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "  \n",
        "  return abstract_samples"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOZpSqPEaC0K",
        "outputId": "c61b4f05-26ba-4bc9-f46c-a73521a49fdb"
      },
      "source": [
        "# Get data from file and preprocess it\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # dev is another name for validation set\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 449 ms, sys: 75.7 ms, total: 524 ms\n",
            "Wall time: 521 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgZfGCaiaHR0",
        "outputId": "eb6a21ee-fac4-4d96-ae30-dffdd0c72fe3"
      },
      "source": [
        "# Check the first abstract of our training data\n",
        "train_samples[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 0,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 1,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 2,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 3,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 4,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 5,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 6,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 7,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 8,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 9,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'total_lines': 11}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "v0sJK23Wam7F",
        "outputId": "ffaeba5f-0171-49af-e183-8a4122acc66c"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         target  ... total_lines\n",
              "0     OBJECTIVE  ...          11\n",
              "1       METHODS  ...          11\n",
              "2       METHODS  ...          11\n",
              "3       METHODS  ...          11\n",
              "4       METHODS  ...          11\n",
              "5       METHODS  ...          11\n",
              "6       RESULTS  ...          11\n",
              "7       RESULTS  ...          11\n",
              "8       RESULTS  ...          11\n",
              "9       RESULTS  ...          11\n",
              "10      RESULTS  ...          11\n",
              "11  CONCLUSIONS  ...          11\n",
              "12   BACKGROUND  ...          10\n",
              "13   BACKGROUND  ...          10\n",
              "\n",
              "[14 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4A6lpD1a61i",
        "outputId": "47554f48-1c80-41fd-d422-db3aec3ccc3e"
      },
      "source": [
        "# Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "5mqVEHKpbH3o",
        "outputId": "773c3689-7610-47f2-d398-9098a7a06375"
      },
      "source": [
        "train_df.total_lines.plot.hist();"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-cjhPuebNeF"
      },
      "source": [
        "### Get lists of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7olPj8Exb1ly",
        "outputId": "374def39-9463-4eff-ad70-2e7366e9c5b1"
      },
      "source": [
        "# Convert abstract text lines into lists \n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSU4YdF0b4U_",
        "outputId": "233adadc-20e8-4f7e-b2a1-5c7658a05093"
      },
      "source": [
        "# View first 10 lines of training sentences\n",
        "train_sentences[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WmxmMebb7AV"
      },
      "source": [
        "## Make numeric labels \n",
        "\n",
        "We're going to create one hot and label encoded labels.\n",
        "\n",
        "We could get away with just making label encoded labels, however, TensorFlow's CategoricalCrossentropy loss function likes to have one hot encoded labels (this will enable us to use label smoothing later on).\n",
        "\n",
        "To numerically encode labels we'll use Scikit-Learn's OneHotEncoder and LabelEncoder classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hqVk3rAcgbJ",
        "outputId": "1fc1bfbf-aa2c-4925-a704-31ce152f90c0"
      },
      "source": [
        "# One hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_one_hot"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqZ4a-UCckXH"
      },
      "source": [
        "### Label encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_3fhlWVcnVX",
        "outputId": "940585fc-42e1-4920-8d95-6166effcebc4"
      },
      "source": [
        "# Extract labels (\"target\" columns) and encode them into integers \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPHnRKKScpwV",
        "outputId": "b123679b-a730-4837-f6d6-dec56750e7c3"
      },
      "source": [
        "# Get class names and number of classes from LabelEncoder instance \n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XK9k-DHcwpE"
      },
      "source": [
        "# Creating a series of model experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4v7aRdvFInv"
      },
      "source": [
        "## Model 0 : Getting a baseline\n",
        "\n",
        "Our first model we'll be a TF-IDF Multinomial Naive Bayes as recommended by Scikit-Learn's machine learning map.\n",
        "\n",
        "To build it, we'll create a Scikit-Learn Pipeline which uses the TfidfVectorizer class to convert our abstract sentences to numbers using the TF-IDF (term frequency-inverse document frequecy) algorithm and then learns to classify our sentences using the MultinomialNB aglorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2a4ozzxFPKc"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tf-idf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X=train_sentences,\n",
        "            y = train_labels_encoded);"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgkr8gYaF5Pv",
        "outputId": "b83e4fb0-d96b-423b-dd6d-a7cfe421dce4"
      },
      "source": [
        "# Evaluate baseline on validation dataset\n",
        "model_0.score(X = val_sentences,\n",
        "              y = val_labels_encoded)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rHdfS3bGENE",
        "outputId": "8597e54b-713f-4d7b-cb46-71e759b18cfe"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxVpyW4xGNZA"
      },
      "source": [
        "### Download helper functions script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dO5dSbPGU-K",
        "outputId": "3f5e2c65-e88f-41d7-efd9-aee5b6cc2cae"
      },
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/prachuryanath/TF-Learning/main/extras/helper_functions.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-15 14:35:54--  https://raw.githubusercontent.com/prachuryanath/TF-Learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10235 (10.0K) [text/plain]\n",
            "Saving to: â€˜helper_functions.pyâ€™\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-15 14:35:54 (92.4 MB/s) - â€˜helper_functions.pyâ€™ saved [10235/10235]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeJolLFJGaFG",
        "outputId": "87dc9ce5-9675-4171-d661-563a6b3436d1"
      },
      "source": [
        "# Import calculate_results helper function\n",
        "from helper_functions import calculate_results\n",
        "\n",
        "# Calculate baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'f1': 0.6989250353450294,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWE3W4EYGfEy"
      },
      "source": [
        "## Preparing our data for deep sequence models\n",
        "\n",
        "Excellent! We've got a working baseline to try and improve upon.\n",
        "\n",
        "But before we start building deeper models, we've got to create vectorization and embedding layers.\n",
        "\n",
        "The vectorization layer will convert our text to numbers and the embedding layer will capture the relationships between those numbers.\n",
        "\n",
        "To start creating our vectorization and embedding layers, we'll need to import the appropriate libraries (namely TensorFlow and NumPy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SUIHdX1GrOm"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx7tIeidIbX6",
        "outputId": "eddbabac-8b51-4c00-f035-87bb20dc874f"
      },
      "source": [
        "# How long is each sentence on average ?\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_lens = np.mean(sent_lens)\n",
        "avg_sent_lens"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "IEbJrjoIIrfy",
        "outputId": "fb4a3d7d-06c0-44f6-a718-d74fb5896829"
      },
      "source": [
        "# What's the distribution look like ?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=15)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([7.3163e+04, 8.1733e+04, 1.8772e+04, 4.5680e+03, 1.2400e+03,\n",
              "        3.5400e+02, 1.1600e+02, 4.5000e+01, 1.7000e+01, 1.2000e+01,\n",
              "        1.2000e+01, 3.0000e+00, 3.0000e+00, 1.0000e+00, 1.0000e+00]),\n",
              " array([  1.        ,  20.66666667,  40.33333333,  60.        ,\n",
              "         79.66666667,  99.33333333, 119.        , 138.66666667,\n",
              "        158.33333333, 178.        , 197.66666667, 217.33333333,\n",
              "        237.        , 256.66666667, 276.33333333, 296.        ]),\n",
              " <a list of 15 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWt0lEQVR4nO3df6zd9X3f8eerNr9KAjZwZzHbmp3FauSghcAVOEoUbXgxNplqKhEEqoaFLDwN2JJp02ZWaW4hTDBtZWEiVG7wsKMshtJEWI2p6xmqan8YuAQCGEp9w49iy+BbbKApCtT0vT/Ox8np5f44Ntf3+trPh3R0Pt/39/P9ns8nX4fX/X7P95yTqkKSdHL7lakegCRp6hkGkiTDQJJkGEiSMAwkScDMqR7A0TrvvPNqwYIFUz0MSZo2nnrqqb+qqr6R1k3bMFiwYAEDAwNTPQxJmjaSvDbaOi8TSZIMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJafwJ5OPJgrU/mtD9vXrHVyd0f5I0np7ODJL8uyS7kjyf5PtJTk+yMMnjSQaTPJDk1Nb3tLY82NYv6NrPLa3+UpLLu+rLW20wydqJnqQkaWzjhkGSucC/Bfqr6gJgBnANcCdwV1V9GjgIrG6brAYOtvpdrR9JFrftPgssB76dZEaSGcA9wApgMXBt6ytJmiS9vmcwEzgjyUzgV4F9wGXAQ239RuDK1l7ZlmnrlyZJq2+uqver6hVgELikPQar6uWq+gDY3PpKkibJuGFQVXuB/w78JZ0QeAd4Cni7qg61bnuAua09F3i9bXuo9T+3uz5sm9HqH5FkTZKBJANDQ0O9zE+S1INeLhPNpvOX+kLgHwJn0rnMM+mqan1V9VdVf1/fiF/JLUk6Cr1cJvrnwCtVNVRVfwv8APgiMKtdNgKYB+xt7b3AfIC2/mzgre76sG1Gq0uSJkkvYfCXwJIkv9qu/S8FXgAeA65qfVYBD7f2lrZMW/9oVVWrX9PuNloILAKeAJ4EFrW7k06l8ybzlo8/NUlSr8b9nEFVPZ7kIeDHwCHgaWA98CNgc5Jvttp9bZP7gO8mGQQO0PmPO1W1K8mDdILkEHBTVX0IkORmYBudO5U2VNWuiZuiJGk8PX3orKrWAeuGlV+mcyfQ8L4/B742yn5uB24fob4V2NrLWCRJE8+vo5AkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJJEj99NdKKZ6B+wl6TpzjMDSZJhIEkyDCRJGAaSJHoIgyS/luSZrse7Sb6R5Jwk25Psbs+zW/8kuTvJYJJnk1zUta9Vrf/uJKu66hcnea5tc3f7eU1J0iQZNwyq6qWqurCqLgQuBt4DfgisBXZU1SJgR1sGWEHn940XAWuAewGSnEPn19IupfMLaesOB0jrc0PXdssnZHaSpJ4c6WWipcBPq+o1YCWwsdU3Ale29kpgU3XsBGYlOR+4HNheVQeq6iCwHVje1p1VVTurqoBNXfuSJE2CIw2Da4Dvt/acqtrX2m8Ac1p7LvB61zZ7Wm2s+p4R6h+RZE2SgSQDQ0NDRzh0SdJoeg6DJKcCvw78wfB17S/6msBxjaiq1ldVf1X19/X1HeuXk6STxpGcGawAflxVb7blN9slHtrz/lbfC8zv2m5eq41VnzdCXZI0SY4kDK7ll5eIALYAh+8IWgU83FW/rt1VtAR4p11O2gYsSzK7vXG8DNjW1r2bZEm7i+i6rn1JkiZBT99NlORM4CvAv+oq3wE8mGQ18BpwdatvBa4ABunceXQ9QFUdSHIb8GTrd2tVHWjtG4H7gTOAR9pDkjRJegqDqvob4Nxhtbfo3F00vG8BN42ynw3AhhHqA8AFvYxFkjTx/ASyJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiS6DEMksxK8lCSP0/yYpIvJDknyfYku9vz7NY3Se5OMpjk2SQXde1nVeu/O8mqrvrFSZ5r29zdfgtZkjRJej0z+Bbwx1X1GeBzwIvAWmBHVS0CdrRlgBXAovZYA9wLkOQcYB1wKXAJsO5wgLQ+N3Rtt/zjTUuSdCTGDYMkZwNfBu4DqKoPquptYCWwsXXbCFzZ2iuBTdWxE5iV5HzgcmB7VR2oqoPAdmB5W3dWVe1sv5+8qWtfkqRJ0MuZwUJgCPjfSZ5O8p0kZwJzqmpf6/MGMKe15wKvd22/p9XGqu8Zof4RSdYkGUgyMDQ01MPQJUm96CUMZgIXAfdW1eeBv+GXl4QAaH/R18QP7++rqvVV1V9V/X19fcf65STppNFLGOwB9lTV4235ITrh8Ga7xEN73t/W7wXmd20/r9XGqs8boS5JmiTjhkFVvQG8nuTXWmkp8AKwBTh8R9Aq4OHW3gJc1+4qWgK80y4nbQOWJZnd3jheBmxr695NsqTdRXRd174kSZNgZo/9/g3wvSSnAi8D19MJkgeTrAZeA65ufbcCVwCDwHutL1V1IMltwJOt361VdaC1bwTuB84AHmkPSdIk6SkMquoZoH+EVUtH6FvATaPsZwOwYYT6AHBBL2ORJE08P4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEn0GAZJXk3yXJJnkgy02jlJtifZ3Z5nt3qS3J1kMMmzSS7q2s+q1n93klVd9Yvb/gfbtpnoiUqSRnckZwb/rKourKrDv3i2FthRVYuAHW0ZYAWwqD3WAPdCJzyAdcClwCXAusMB0vrc0LXd8qOekSTpiH2cy0QrgY2tvRG4squ+qTp2ArOSnA9cDmyvqgNVdRDYDixv686qqp3tJzM3de1LkjQJeg2DAv4kyVNJ1rTanKra19pvAHNaey7wete2e1ptrPqeEeofkWRNkoEkA0NDQz0OXZI0npk99vtSVe1N8g+A7Un+vHtlVVWSmvjh/X1VtR5YD9Df33/MX0+SThY9nRlU1d72vB/4IZ1r/m+2Szy05/2t+15gftfm81ptrPq8EeqSpEkybhgkOTPJJw+3gWXA88AW4PAdQauAh1t7C3Bdu6toCfBOu5y0DViWZHZ743gZsK2tezfJknYX0XVd+5IkTYJeLhPNAX7Y7vacCfyfqvrjJE8CDyZZDbwGXN36bwWuAAaB94DrAarqQJLbgCdbv1ur6kBr3wjcD5wBPNIekqRJMm4YVNXLwOdGqL8FLB2hXsBNo+xrA7BhhPoAcEEP45UkHQN+AlmSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjiCMEgyI8nTSf6oLS9M8niSwSQPJDm11U9ry4Nt/YKufdzS6i8lubyrvrzVBpOsnbjpSZJ6cSRnBl8HXuxavhO4q6o+DRwEVrf6auBgq9/V+pFkMXAN8FlgOfDtFjAzgHuAFcBi4NrWV5I0SXoKgyTzgK8C32nLAS4DHmpdNgJXtvbKtkxbv7T1Xwlsrqr3q+oVOr+RfEl7DFbVy1X1AbC59ZUkTZJezwz+J/Afgb9ry+cCb1fVoba8B5jb2nOB1wHa+nda/1/Uh20zWv0jkqxJMpBkYGhoqMehS5LGM24YJPkXwP6qemoSxjOmqlpfVf1V1d/X1zfVw5GkE8bMHvp8Efj1JFcApwNnAd8CZiWZ2f76nwfsbf33AvOBPUlmAmcDb3XVD+veZrS6JGkSjHtmUFW3VNW8qlpA5w3gR6vqN4HHgKtat1XAw629pS3T1j9aVdXq17S7jRYCi4AngCeBRe3upFPba2yZkNlJknrSy5nBaP4TsDnJN4Gngfta/T7gu0kGgQN0/uNOVe1K8iDwAnAIuKmqPgRIcjOwDZgBbKiqXR9jXJKkI3REYVBVfwr8aWu/TOdOoOF9fg58bZTtbwduH6G+Fdh6JGORJE0cP4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkegiDJKcneSLJT5LsSvI7rb4wyeNJBpM80H6/mPYbxw+0+uNJFnTt65ZWfynJ5V315a02mGTtxE9TkjSWXs4M3gcuq6rPARcCy5MsAe4E7qqqTwMHgdWt/2rgYKvf1fqRZDGd30P+LLAc+HaSGUlmAPcAK4DFwLWtryRpkowbBtXxs7Z4SnsUcBnwUKtvBK5s7ZVtmbZ+aZK0+uaqer+qXgEG6fyG8iXAYFW9XFUfAJtbX0nSJOnpPYP2F/wzwH5gO/BT4O2qOtS67AHmtvZc4HWAtv4d4Nzu+rBtRquPNI41SQaSDAwNDfUydElSD3oKg6r6sKouBObR+Uv+M8d0VKOPY31V9VdVf19f31QMQZJOSEd0N1FVvQ08BnwBmJVkZls1D9jb2nuB+QBt/dnAW931YduMVpckTZJe7ibqSzKrtc8AvgK8SCcUrmrdVgEPt/aWtkxb/2hVVatf0+42WggsAp4AngQWtbuTTqXzJvOWiZicJKk3M8fvwvnAxnbXz68AD1bVHyV5Adic5JvA08B9rf99wHeTDAIH6PzHnaraleRB4AXgEHBTVX0IkORmYBswA9hQVbsmbIaSpHGNGwZV9Szw+RHqL9N5/2B4/efA10bZ1+3A7SPUtwJbexivJOkY8BPIkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJJEbz97OT/JY0leSLIryddb/Zwk25Psbs+zWz1J7k4ymOTZJBd17WtV6787yaqu+sVJnmvb3J0kx2KykqSR9XJmcAj491W1GFgC3JRkMbAW2FFVi4AdbRlgBZ3fN14ErAHuhU54AOuAS+n8Qtq6wwHS+tzQtd3yjz81SVKvxg2DqtpXVT9u7b8GXgTmAiuBja3bRuDK1l4JbKqOncCsJOcDlwPbq+pAVR0EtgPL27qzqmpnVRWwqWtfkqRJcETvGSRZQOf3kB8H5lTVvrbqDWBOa88FXu/abE+rjVXfM0J9pNdfk2QgycDQ0NCRDF2SNIaewyDJJ4A/BL5RVe92r2t/0dcEj+0jqmp9VfVXVX9fX9+xfjlJOmn0FAZJTqETBN+rqh+08pvtEg/teX+r7wXmd20+r9XGqs8boS5JmiQzx+vQ7uy5D3ixqn63a9UWYBVwR3t+uKt+c5LNdN4sfqeq9iXZBvzXrjeNlwG3VNWBJO8mWULn8tN1wP+agLlNWwvW/mjC9/nqHV+d8H1KOnGMGwbAF4F/CTyX5JlW+890QuDBJKuB14Cr27qtwBXAIPAecD1A+4/+bcCTrd+tVXWgtW8E7gfOAB5pD0nSJBk3DKrq/wGj3fe/dIT+Bdw0yr42ABtGqA8AF4w3FknSseEnkCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkiR7CIMmGJPuTPN9VOyfJ9iS72/PsVk+Su5MMJnk2yUVd26xq/XcnWdVVvzjJc22bu9vPbEqSJlEvZwb3A8uH1dYCO6pqEbCjLQOsABa1xxrgXuiEB7COzm8iXwKs6/ot5HuBG7q2G/5akqRjbNwwqKo/Aw4MK68ENrb2RuDKrvqm6tgJzEpyPnA5sL2qDlTVQWA7sLytO6uqdrafy9zUtS9J0iQ52vcM5lTVvtZ+A5jT2nOB17v67Wm1sep7RqiPKMmaJANJBoaGho5y6JKk4T72G8jtL/qagLH08lrrq6q/qvr7+vom4yUl6aRwtGHwZrvEQ3ve3+p7gfld/ea12lj1eSPUJUmT6GjDYAtw+I6gVcDDXfXr2l1FS4B32uWkbcCyJLPbG8fLgG1t3btJlrS7iK7r2pckaZLMHK9Dku8D/xQ4L8keOncF3QE8mGQ18Bpwdeu+FbgCGATeA64HqKoDSW4Dnmz9bq2qw29K30jnjqUzgEfaQ5I0icYNg6q6dpRVS0foW8BNo+xnA7BhhPoAcMF445AkHTt+AlmSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiS6OFDZzoxLFj7ownd36t3fHVC9ydpanlmIEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkcRx86S7Ic+BYwA/hOVd0xxUPSGPwQm3RiOS7ODJLMAO4BVgCLgWuTLJ7aUUnSyeN4OTO4BBisqpcBkmwGVgIvTOmoNGkm+kwDPNuQjsTxEgZzgde7lvcAlw7vlGQNsKYt/izJS0fxWucBf3UU2x2PTqS5wATPJ3dO1J6O2ol0fE6kucCJNZ8jmcs/Gm3F8RIGPamq9cD6j7OPJANV1T9BQ5pSJ9JcwPkcz06kucCJNZ+Jmstx8Z4BsBeY37U8r9UkSZPgeAmDJ4FFSRYmORW4BtgyxWOSpJPGcXGZqKoOJbkZ2Ebn1tINVbXrGL3cx7rMdJw5keYCzud4diLNBU6s+UzIXFJVE7EfSdI0drxcJpIkTSHDQJJ08oRBkuVJXkoymGTtVI/naCR5NclzSZ5JMtBq5yTZnmR3e5491eMcTZINSfYneb6rNuL403F3O17PJrlo6kb+UaPM5beT7G3H55kkV3Stu6XN5aUkl0/NqEeWZH6Sx5K8kGRXkq+3+nQ9NqPNZ7oen9OTPJHkJ20+v9PqC5M83sb9QLv5hiSnteXBtn5BTy9UVSf8g86b0j8FPgWcCvwEWDzV4zqKebwKnDes9t+Ata29Frhzqsc5xvi/DFwEPD/e+IErgEeAAEuAx6d6/D3M5beB/zBC38Xt39xpwML2b3HGVM+ha3znAxe19ieBv2hjnq7HZrT5TNfjE+ATrX0K8Hj73/1B4JpW/z3gX7f2jcDvtfY1wAO9vM7Jcmbwi6+7qKoPgMNfd3EiWAlsbO2NwJVTOJYxVdWfAQeGlUcb/0pgU3XsBGYlOX9yRjq+UeYympXA5qp6v6peAQbp/Js8LlTVvqr6cWv/NfAinW8FmK7HZrT5jOZ4Pz5VVT9ri6e0RwGXAQ+1+vDjc/i4PQQsTZLxXudkCYORvu5irH8cx6sC/iTJU+2rOQDmVNW+1n4DmDM1Qztqo41/uh6zm9ulkw1dl+ymzVzaJYXP0/nrc9ofm2HzgWl6fJLMSPIMsB/YTufs5e2qOtS6dI/5F/Np698Bzh3vNU6WMDhRfKmqLqLz7a43Jfly98rqnBdO23uFp/v4gXuBfwxcCOwD/sfUDufIJPkE8IfAN6rq3e510/HYjDCfaXt8qurDqrqQzrczXAJ8ZqJf42QJgxPi6y6qam973g/8kM4/ijcPn6K35/1TN8KjMtr4p90xq6o32/9p/w74fX55qeG4n0uSU+j8h/N7VfWDVp62x2ak+Uzn43NYVb0NPAZ8gc7lucMfHO4e8y/m09afDbw13r5PljCY9l93keTMJJ883AaWAc/Tmceq1m0V8PDUjPCojTb+LcB17c6VJcA7XZcsjkvDrpv/Bp3jA525XNPu8lgILAKemOzxjaZdT74PeLGqfrdr1bQ8NqPNZxofn74ks1r7DOArdN4HeQy4qnUbfnwOH7ergEfbmd3Ypvqd8sl60LkD4i/oXGv7rakez1GM/1N07nj4CbDr8BzoXAvcAewG/i9wzlSPdYw5fJ/O6fnf0rnGuXq08dO5g+KedryeA/qnevw9zOW7bazPtv9Dnt/V/7faXF4CVkz1+IfN5Ut0LgE9CzzTHldM42Mz2nym6/H5J8DTbdzPA/+l1T9FJ7QGgT8ATmv109vyYFv/qV5ex6+jkCSdNJeJJEljMAwkSYaBJMkwkCRhGEiSMAwkSRgGkiTg/wMqybg/6oo3YAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je8OphXJI_4T",
        "outputId": "ba1173d3-8a5b-43d8-efa7-d5fe10665b21"
      },
      "source": [
        "# How long of a sentence covers 95% of the lengths?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAg6f0oJPeA"
      },
      "source": [
        "Wonderful! It looks like 95% of the sentences in our training set have a length of 55 tokens or less.\n",
        "\n",
        "When we create our tokenization layer, we'll use this value to turn all of our sentences into the same length. Meaning sentences with a length below 55 get padded with zeros and sentences with a length above 55 get truncated (words after 55 get cut off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE5cD-M-JYaM",
        "outputId": "da4a38a2-f93f-4fe8-df9f-30e402565f4e"
      },
      "source": [
        "# Maximum sentence length in the training set\n",
        "max(sent_lens)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnUNv660JaSG"
      },
      "source": [
        "### Create text vectorizer\n",
        "\n",
        "Now we've got a little more information about our texts, let's create a way to turn it into numbers.\n",
        "\n",
        "To do so, we'll use the TextVectorization layer from TensorFlow.\n",
        "\n",
        "We'll keep all the parameters default except for max_tokens (the number of unique words in our dataset) and output_sequence_length (our desired output length for each vectorized sentence).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuMMxPTIJori"
      },
      "source": [
        "# How many words are in our vocabulary? (taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n",
        "max_tokens = 68000"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX-T69OpJqts"
      },
      "source": [
        "# Create text vectorizer\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, # number of words in vocabulary\n",
        "                                    output_sequence_length=55) # desired output length of vectorized sequences"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS_MU-0KJz9i"
      },
      "source": [
        "Great! Looks like our text_vectorizer is ready, let's adapt it to the training data (let it read the training data and figure out what number should represent what word) and then test it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmIQcCE1JvO7"
      },
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbymR2tRJyLZ",
        "outputId": "ccce0e16-3011-4e94-c9d3-e247d270963a"
      },
      "source": [
        "# Test out text vectorizer\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:\n",
            "non-inferiority for shared strains and superiority for the alternate-lineage b strain unique to qiv was demonstrated for qiv versus tiv .\n",
            "\n",
            "Length of text: 21\n",
            "\n",
            "Vectorized text:\n",
            "[[  731    11  3462  3048     3  1622    11     2 32729   186  1679  1320\n",
            "      6  9078    10   371    11  9078   110  4293     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAqJhJOJJ32h",
        "outputId": "ad6f0660-98f9-4869-f135-2c6f9706aa11"
      },
      "source": [
        "# How many words in our training vocabulary?\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\"), \n",
        "print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocabulary: 64841\n",
            "Most common words in the vocabulary: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words in the vocabulary: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESWjEHYMKD5t",
        "outputId": "e9521f80-b3f7-4a67-a5e5-ba03b418a364"
      },
      "source": [
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dtype': 'string',\n",
              " 'max_tokens': 68000,\n",
              " 'name': 'text_vectorization',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True,\n",
              " 'vocabulary_size': 64841}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikIQmf_fKKNI"
      },
      "source": [
        "### Create custom text embedding\n",
        "\n",
        "Our token_vectorization layer maps the words in our text directly to numbers. However, this doesn't necessarily capture the relationships between those numbers.\n",
        "\n",
        "To create a richer numerical representation of our text, we can use an **embedding**.\n",
        "\n",
        "As our model learns (*by going through many different examples of abstract sentences and their labels*), it'll update its embedding to better represent the relationships between tokens in our corpus.\n",
        "\n",
        "We can create a trainable embedding layer using TensorFlow's `Embedding layer`.\n",
        "\n",
        "Once again, the main parameters we're concerned with here are the inputs and outputs of our `Embedding layer`.\n",
        "\n",
        "The input_dim parameter defines the size of our vocabulary. And the output_dim parameter defines the dimension of the embedding output.\n",
        "\n",
        "Once created, our embedding layer will take the integer outputs of our `text_vectorization` layer as inputs and convert them to feature vectors of size `output_dim`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq32taDUMUHl",
        "outputId": "da7a5da3-ab1e-448a-f52f-f98048e082e8"
      },
      "source": [
        "# Create token embedding layer\n",
        "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab), # length of vocabulary\n",
        "                               output_dim=128, # Note: different embedding sizes result in drastically different numbers of parameters to train\n",
        "                               # Use masking to handle variable sequence lengths (save space)\n",
        "                               mask_zero=True,\n",
        "                               name=\"token_embedding\") \n",
        "\n",
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence before vectorization:\n",
            "non-inferiority for shared strains and superiority for the alternate-lineage b strain unique to qiv was demonstrated for qiv versus tiv .\n",
            "\n",
            "Sentence after vectorization (before embedding):\n",
            "[[  731    11  3462  3048     3  1622    11     2 32729   186  1679  1320\n",
            "      6  9078    10   371    11  9078   110  4293     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n",
            "\n",
            "Sentence after embedding:\n",
            "[[[ 0.0318012  -0.0373584  -0.01014536 ...  0.00094408 -0.03992225\n",
            "   -0.01078955]\n",
            "  [-0.02126801  0.0459605  -0.02651554 ...  0.00162262 -0.03452737\n",
            "   -0.04052386]\n",
            "  [-0.00401509 -0.02775712 -0.03382535 ... -0.00633721 -0.039207\n",
            "   -0.04495046]\n",
            "  ...\n",
            "  [ 0.02103119  0.02808634  0.01165854 ...  0.03445664 -0.04550666\n",
            "    0.02748168]\n",
            "  [ 0.02103119  0.02808634  0.01165854 ...  0.03445664 -0.04550666\n",
            "    0.02748168]\n",
            "  [ 0.02103119  0.02808634  0.01165854 ...  0.03445664 -0.04550666\n",
            "    0.02748168]]]\n",
            "\n",
            "Embedded sentence shape: (1, 55, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBbbVDpKMwbH"
      },
      "source": [
        "### Create datasets \n",
        "Namely, the tf.data API provides methods which enable faster data loading.\n",
        "\n",
        "The main steps we'll want to use with our data is to turn it into a `PrefetchDataset` of batches.\n",
        "\n",
        "Doing so we'll ensure TensorFlow loads our data onto the GPU as fast as possible, in turn leading to faster training time.\n",
        "\n",
        "To create a batched PrefetchDataset we can use the methods `batch()` and `prefetch()`, the parameter `tf.data.AUTOTUNE` will also allow TensorFlow to determine the optimal amount of compute to use to prepare datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZXBLJ62NBZ2",
        "outputId": "a3126f93-a4fe-4311-ffab-724c7f6691d9"
      },
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rrX-anYNPe7",
        "outputId": "2df34210-df0b-40a2-db78-b63b7a29f370"
      },
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dn9x-rwNRgQ"
      },
      "source": [
        "## Model 1 : Conv1D with token embeddings\n",
        "\n",
        "All of our deep models will follow a similar structure:\n",
        "\n",
        "`Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)`\n",
        "\n",
        "The main component we'll be changing throughout is the Layers component. Because any modern deep NLP model requires text to be converted into an embedding before meaningful patterns can be discovered within.\n",
        "\n",
        "The first model we're going to build is a 1-dimensional Convolutional Neural Network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StCVFrLwNg4j"
      },
      "source": [
        "# Create 1D convolutional model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = text_vectorizer(inputs) # vectorize text inputs\n",
        "token_embeddings = token_embed(text_vectors) # create embedding\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile\n",
        "model_1.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPA6RZ65N5dk",
        "outputId": "131d3bf7-681f-404d-9e39-b66783c37487"
      },
      "source": [
        "# Get summary of Conv1D model\n",
        "model_1.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 55)                0         \n",
            "_________________________________________________________________\n",
            "token_embedding (Embedding)  (None, 55, 128)           8299648   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 55, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz3ZVL8NN-E8"
      },
      "source": [
        "Since our training data contains nearly 200,000 sentences, fitting a deep model may take a while even with a GPU. So to keep our experiments swift, we're going to run them on a subset of the training dataset.\n",
        "\n",
        "More specifically, we'll only use the first 10% of batches (about 18,000 samples) of the training set to train on and the first 10% of batches from the validation set to validate on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7GdhSyXOQEG",
        "outputId": "79b29017-02b5-4abd-e8dc-3eb4970d0caf"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)), # only fit on 10% of batches for faster training time\n",
        "                              epochs=3,\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1 * len(valid_dataset))) # only validate on 10% of batches"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 76s 79ms/step - loss: 0.9119 - accuracy: 0.6393 - val_loss: 0.6833 - val_accuracy: 0.7424\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 43s 77ms/step - loss: 0.6546 - accuracy: 0.7588 - val_loss: 0.6290 - val_accuracy: 0.7716\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 43s 77ms/step - loss: 0.6164 - accuracy: 0.7753 - val_loss: 0.5956 - val_accuracy: 0.7869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwM9iMbNOVkM",
        "outputId": "4c0c54c3-c0f4-404f-9d3d-c7ac08f04952"
      },
      "source": [
        "# Evaluate on whole validation dataset (we only validated on 10% of batches during training)\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 3s 3ms/step - loss: 0.5967 - accuracy: 0.7872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5966708064079285, 0.7871706485748291]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m_AXUlQP_Fa",
        "outputId": "87d37666-600b-4d5c-9201-f3e3b51eb909"
      },
      "source": [
        "# Make predictions (our model outputs prediction probabilities for each class)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.5082515e-01, 1.5135884e-01, 7.6123647e-02, 2.9937693e-01,\n",
              "        2.2315383e-02],\n",
              "       [4.7565222e-01, 2.4212237e-01, 1.6916417e-02, 2.5668603e-01,\n",
              "        8.6230570e-03],\n",
              "       [1.3601859e-01, 8.0019953e-03, 1.2665332e-03, 8.5467887e-01,\n",
              "        3.4075354e-05],\n",
              "       ...,\n",
              "       [3.7103837e-06, 5.9053855e-04, 4.3977957e-04, 3.7711472e-06,\n",
              "        9.9896216e-01],\n",
              "       [6.2072244e-02, 4.7143814e-01, 1.0958694e-01, 7.8320682e-02,\n",
              "        2.7858195e-01],\n",
              "       [1.9307315e-01, 6.6721207e-01, 3.6838394e-02, 4.3273766e-02,\n",
              "        5.9602693e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on46vMnoQCjy",
        "outputId": "f0531d1f-428e-44a1-c422-16827feb61cd"
      },
      "source": [
        "# Convert pred probs to classes\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "model_1_preds"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joubzlk9TfHY",
        "outputId": "d4971d16-0f13-437a-ed05-bbdf82a947b2"
      },
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.71706606646366,\n",
              " 'f1': 0.7847213324818353,\n",
              " 'precision': 0.7840437196875146,\n",
              " 'recall': 0.7871706606646366}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioEtyCWVThue"
      },
      "source": [
        "## Model 2 : Feature extraction with pretrained token embeddings\n",
        "\n",
        "The model structure will look like:\n",
        "\n",
        "`Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)`\n",
        "\n",
        "You'll notice the lack of tokenization layer we've used in a previous model. This is because the `Universal Sentence Encoder (USE)` takes care of tokenization for us.\n",
        "\n",
        "This type of model is called transfer learning, or more specifically, **feature extraction transfer learning**. In other words, taking the patterns a model has learned elsewhere and applying it to our own problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S5Yh76iT76y"
      },
      "source": [
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnTm9-ArUPWI",
        "outputId": "bbffc125-cc44-4285-db6f-57c381f7a9e2"
      },
      "source": [
        "# Test out the embedding on a random sentence\n",
        "random_training_sentence = random.choice(train_sentences)\n",
        "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
        "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
        "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random training sentence:\n",
            "we genotyped a functional npy variant rs@ among @ participants in the preventing overweight using novel dietary strategies trial .\n",
            "\n",
            "Sentence after embedding:\n",
            "[-0.05518287 -0.00825012 -0.02050118 -0.05578801 -0.03241367  0.00054056\n",
            " -0.00273321 -0.00483429 -0.01467546  0.01473663  0.06976774 -0.02043296\n",
            "  0.04627545  0.04922597 -0.08822115 -0.03502212  0.04210846  0.05037799\n",
            " -0.05480552 -0.03656818 -0.01744021 -0.00681542 -0.07347436 -0.05725589\n",
            "  0.03962769  0.0337556   0.02015668  0.02703178 -0.00118242 -0.06963792] (truncated output)...\n",
            "\n",
            "Length of sentence embedding:\n",
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BrYwbV7Ui9W"
      },
      "source": [
        "### Building and fitting an NLP feature extraction model from TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3PJYUHkUry3"
      },
      "source": [
        "# Define feature extractor model using TF Hub layer\n",
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
        "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
        "# Note: you could add more layers here if you wanted to\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n",
        "model_2 = tf.keras.Model(inputs=inputs,\n",
        "                        outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWzn7queUvJn",
        "outputId": "ced5ccfd-983e-4f69-d1fd-e8a3b89c389b"
      },
      "source": [
        "# Get a summary of the model\n",
        "model_2.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None,)]                 0         \n",
            "_________________________________________________________________\n",
            "universal_sentence_encoder ( (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFlxT8IjUxGv",
        "outputId": "974c0e8e-94e5-4fa9-d424-ec8fb5e500ae"
      },
      "source": [
        "# Fit feature extractor model for 3 epochs\n",
        "model_2.fit(train_dataset,\n",
        "            steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "            epochs=3,\n",
        "            validation_data=valid_dataset,\n",
        "            validation_steps=int(0.1 * len(valid_dataset)))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 8s 11ms/step - loss: 0.9202 - accuracy: 0.6497 - val_loss: 0.7977 - val_accuracy: 0.6912\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 6s 11ms/step - loss: 0.7679 - accuracy: 0.7014 - val_loss: 0.7545 - val_accuracy: 0.7068\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 6s 11ms/step - loss: 0.7506 - accuracy: 0.7129 - val_loss: 0.7366 - val_accuracy: 0.7154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feb6c34ec50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYO8oGtZU1o9",
        "outputId": "8cc781dc-7d0e-40e0-90ef-f6be0be1c618"
      },
      "source": [
        "# Evaluate on whole validation dataset\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "945/945 [==============================] - 9s 9ms/step - loss: 0.7391 - accuracy: 0.7135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7390727400779724, 0.7135244011878967]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUxpOCHyVEhI",
        "outputId": "90b98fd4-2d92-406c-e75d-886d5a4ca9ed"
      },
      "source": [
        "# Make predictions with feature extraction model\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.3545204e-01, 3.7734786e-01, 2.3506223e-03, 1.7532632e-01,\n",
              "        9.5231989e-03],\n",
              "       [3.3610135e-01, 4.9236277e-01, 3.9582876e-03, 1.6397451e-01,\n",
              "        3.6029876e-03],\n",
              "       [2.4439669e-01, 1.3326187e-01, 1.8326290e-02, 5.6707835e-01,\n",
              "        3.6936790e-02],\n",
              "       ...,\n",
              "       [1.7160536e-03, 5.8018509e-03, 4.9736131e-02, 8.8421471e-04,\n",
              "        9.4186175e-01],\n",
              "       [3.9561801e-03, 4.7132079e-02, 1.8193603e-01, 1.7137539e-03,\n",
              "        7.6526195e-01],\n",
              "       [1.4743917e-01, 2.0400587e-01, 5.7333243e-01, 8.4196804e-03,\n",
              "        6.6802882e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY2TbJqLVGLd",
        "outputId": "520dd351-869c-4283-85b4-3824df5d437e"
      },
      "source": [
        "# Convert the predictions with feature extraction model to classes\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Env6Ch23VINu",
        "outputId": "1107a51a-fbf0-4d98-d2ab-f9af71266615"
      },
      "source": [
        "# Calculate results from TF Hub pretrained embeddings results on validation set\n",
        "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 71.35244273798492,\n",
              " 'f1': 0.710589604605243,\n",
              " 'precision': 0.7136628457526302,\n",
              " 'recall': 0.7135244273798491}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJiGRfXgVKT0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}