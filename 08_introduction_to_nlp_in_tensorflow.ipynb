{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdKfLG7pm32Q3BggQWm7KW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prachuryanath/TF-Learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CknZhbEJGuB"
      },
      "source": [
        "# Natural Language Processing Basics in Tensorflow\n",
        "To get hands-on with NLP in TensorFlow, we're going to practice the steps we've used previously but this time with text data:\n",
        "\n",
        "`Text -> turn into numbers -> build a model -> train the model to find patterns -> use patterns (make predictions)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3MFV9vpI6Y2"
      },
      "source": [
        "## What we're going to cover\n",
        "Let's get specific hey?\n",
        "\n",
        "* Downloading a text dataset\n",
        "* Visualizing text data\n",
        "* Converting text into numbers using tokenization\n",
        "* Turning our tokenized text into an embedding\n",
        "* Modelling a text dataset\n",
        "  * Starting with a baseline (TF-IDF)\n",
        "  * Building several deep learning text models\n",
        "    * Dense, LSTM, GRU, Conv1D, Transfer learning\n",
        "* Comparing the performance of each our models\n",
        "* Combining our models into an ensemble\n",
        "* Saving and loading a trained model\n",
        "* Find the most wrong predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xicB1xTPJ6qv",
        "outputId": "1a0b8396-adb2-45ee-d9c9-7ce25e88fdf9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun  5 06:56:06 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kowzun2KOwE"
      },
      "source": [
        "## Get helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBc1YPIXKCfn",
        "outputId": "8cca9727-2ef3-435d-b676-7923e800ba8f"
      },
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/prachuryanath/TF-Learning/main/extras/helper_functions.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-05 06:56:06--  https://raw.githubusercontent.com/prachuryanath/TF-Learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10235 (10.0K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-05 06:56:06 (97.5 MB/s) - ‘helper_functions.py’ saved [10235/10235]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIl7a27uKNc0"
      },
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_NBhWlrKU4_"
      },
      "source": [
        "## Download a text dataset\n",
        "\n",
        "Let's start by download a text dataset. We'll be using the Real or Not? datset from Kaggle which contains text-based Tweets about natural disasters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJnMQA8PLPaX",
        "outputId": "abe25cff-e8fd-48c1-b882-70beda9f0be4"
      },
      "source": [
        "# Download data (same as from Kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-05 06:56:08--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.202.128, 74.125.20.128, 74.125.197.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.202.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-06-05 06:56:09 (112 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl0GDFLPLdJA"
      },
      "source": [
        "Unzipping `nlp_getting_started`.zip gives the following 3 .csv files:\n",
        "\n",
        "* `sample_submission.csv` - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n",
        "* `train.csv` - training samples of real and not real diaster Tweets.\n",
        "* `test.csv` - testing samples of real and not real diaster Tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "oN_hOEW8LWxw",
        "outputId": "b32da551-0403-4a05-b1c1-27224b0dc405"
      },
      "source": [
        "# Turn .csv files into pandas DataFrame's\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "iJYhYZtSLoj3",
        "outputId": "1f62f528-aa8f-4e05-f49e-e447c4bd0f0b"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "39j33t3MLuSK",
        "outputId": "e7bdfe15-bb5c-493d-ec2d-facb99072650"
      },
      "source": [
        "# The test data doesn't have a target (that's what we'd try to predict)\n",
        "test_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt_zM9_EL4k1",
        "outputId": "be28ae09-94d6-4e5a-e8dc-f7aeede80bf0"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwbPLd7pM3u6"
      },
      "source": [
        "Since we have two target values, we're dealing with a binary classification problem.\n",
        "\n",
        "It's fairly balanced too, about 60% negative class (target = 0) and 40% positive class (target = 1).\n",
        "Where,\n",
        "* 1 = a real disaster Tweet\n",
        "* 0 = not a real disaster Tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9IiB8kXNLNF",
        "outputId": "769068ab-ce79-49fa-e712-495aa1651366"
      },
      "source": [
        "# How many samples total?\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training samples: 7613\n",
            "Total test samples: 3263\n",
            "Total samples: 10876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_57mk3MNOA0",
        "outputId": "1a5e5bc3-a24d-45af-888f-b04c14406de6"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Morgan Silver Dollar 1880 S Gem BU DMPL Cameo Rev Blazing MS+++++ High grade! - Full read Û_ http://t.co/IU9baFDXeY http://t.co/AphqU5SvET\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Abe government said the missiles were not 'weapon' so JSDF could provide them to the ally when collective self defense right was exercised.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@MechaMacGyver Wow bet you got blamed for that too huh?\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "GOP debate drinking game. For anyone looking for a bit of fun while watching this train wreck. http://t.co/W3Rga0nkOm http://t.co/0TZsQe8ESD\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@PixelJanosz @Angelheartnight I remember now.  There was a British man who survived both also.  Can't remember his name though.\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rymAQljTNh-l"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SjIC4fzOkKj"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size =0.1,   # dedicate 10% of samples to validation set\n",
        "                                                                            random_state = 42)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9trA82mBPZOp",
        "outputId": "c5560a31-ce22-4d5a-9195-db3abe496246"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwXa8JNRPpCz",
        "outputId": "41b245cc-5b66-4ddb-c4bb-7ece2a2234a1"
      },
      "source": [
        "# View the first 10 training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXoZcNd6P2Cq"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "**Text vectorization (tokenization)**\n",
        "\n",
        "We'll practice tokenzation (mapping our words to numbers) first.\n",
        "\n",
        "To tokenize our words, we'll use the helpful preprocessing layer `tf.keras.layers.experimental.preprocessing.TextVectorization`.\n",
        "\n",
        "The TextVectorization layer takes the following parameters:\n",
        "\n",
        "* `max_tokens` - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens.\n",
        "* `standardize` - Method for standardizing text. Default is \"`lower_and_strip_punctuation`\" which lowers text and removes all punctuation marks.\n",
        "* `split` - How to split text, default is \"`whitespace`\" which splits on spaces.\n",
        "* `ngrams` - How many words to contain per token split, for example, `ngrams=2` splits tokens into continuous sequences of 2.\n",
        "* `output_mode` - How to output tokens, can be \"`int`\" (integer mapping), \"`binary`\" (one-hot encoding), \"`count`\" or \"`tf-idf`\". See documentation for more.\n",
        "* `output_sequence_length` - Length of tokenized sequence to output. For example, if `output_sequence_length=150`, all tokenized sequences will be 150 tokens long.\n",
        "* `pad_to_max_tokens` - If `True` (default), the output feature axis will be padded to max_tokens even if the number of unique tokens in the vocabulary is less than max_tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGGn0u5ZP_Ed"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None, # how long should the output sequence of tokens be?\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBL4s9OU0MG"
      },
      "source": [
        "We've initialized a `TextVectorization` object with the default settings but let's customize it a little bit for our own use case.\n",
        "\n",
        "In particular, let's set values for `max_tokens` and `output_sequence_length`.\n",
        "\n",
        "For max_tokens (the number of words in the vocabulary), multiples of `10,000 (10,000, 20,000, 30,000)` or the exact number of unique words in your text `(e.g. 32,179)` are common values.\n",
        "\n",
        "For our use case, we'll use `10,000`.\n",
        "\n",
        "And for the `output_sequence_length` we'll use the average number of tokens per Tweet in the training set. But first, we'll need to find it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saRZfbgGWyJj",
        "outputId": "822b6f69-7508-495b-9034-c63ee9b2fe83"
      },
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6fEOx3LXELq"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWMCi878XIMf"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPMfAAwoXLfm",
        "outputId": "2532693e-5c73-47b3-c470-8be1822ab79f"
      },
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my road!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 366,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO5vIIJGXalY"
      },
      "source": [
        "Wonderful, it seems we've got a way to turn our text into numbers (in this case, word-level tokenization). Notice the 0's at the end of the returned tensor, this is because we set `output_sequence_length=15`, meaning no matter the size of the sequence we pass to `text_vectorizer`, it always returns a sequence with a length of 15."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7UY_2W6XPgk",
        "outputId": "3000fe91-82b4-4981-9b65-d38f830148a5"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            "A Marshall Plan for the United States by Dambisa Moyo via @ProSyn #oped http://t.co/GnPStnvi5G via @po_st      \n",
            "\n",
            "Vectorized version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   3, 5160,  241,   10,    2,  800, 1253,   18, 5867, 5086,   49,\n",
              "        4847, 4992,    1,   49]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpxinbFXXY9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f19d2da-c501-400c-f435-67db57fdd6a1"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgblym0e0RIT"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "The main parameters we're concerned about here are:\n",
        "\n",
        "* `input_dim` - The size of the vocabulary (e.g. len(text_vectorizer.get_vocabulary()).\n",
        "* `output_dim` - The size of the output embedding vector, for example, a value of 100 outputs a feature vector of size 100 for each word.\n",
        "* `embeddings_initializer` - How to initialize the embeddings matrix, default is \"uniform\" which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "* `input_length` - Length of sequences being passed to embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMpftg8E0cQm",
        "outputId": "41fd2503-3328-494b-f4fb-425709998ad0"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length) # how long is each input\n",
        "embedding"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f47d160f810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA-ZvVn20wLl",
        "outputId": "11b7fef3-0230-4f65-ae41-5f7303652fc8"
      },
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            "@YoungHeroesID LAVA BLAST dan POWER RED #PantherAttack @Mirmanda11 @evaaaSR      \n",
            "\n",
            "Embedded version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.03190076, -0.00242253, -0.01273875, ..., -0.0396785 ,\n",
              "         -0.0291288 ,  0.01420231],\n",
              "        [-0.04265922,  0.04408724,  0.04563365, ..., -0.03252497,\n",
              "         -0.01081617, -0.0185733 ],\n",
              "        [-0.00458907,  0.03227844,  0.00691449, ...,  0.02078613,\n",
              "         -0.04588251, -0.04110479],\n",
              "        ...,\n",
              "        [ 0.03200486, -0.04079875, -0.0386943 , ..., -0.04738299,\n",
              "         -0.00887217,  0.00320014],\n",
              "        [ 0.03200486, -0.04079875, -0.0386943 , ..., -0.04738299,\n",
              "         -0.00887217,  0.00320014],\n",
              "        [ 0.03200486, -0.04079875, -0.0386943 , ..., -0.04738299,\n",
              "         -0.00887217,  0.00320014]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDxFsbTj02nd"
      },
      "source": [
        "Each token in the sentence gets turned into a length 128 feature vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYAOuf1W1CuG",
        "outputId": "53e7b801-7acc-487b-fc20-af55f076f6e4"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([-3.19007635e-02, -2.42253393e-03, -1.27387531e-02,  9.77473333e-03,\n",
              "       -2.41258033e-02,  3.52895260e-03,  3.07852514e-02,  4.89945896e-02,\n",
              "       -4.30011265e-02, -3.77954729e-02,  4.21947129e-02,  9.81404632e-03,\n",
              "        4.76770736e-02, -4.30630520e-03, -2.13906169e-02,  2.05234177e-02,\n",
              "        4.18723710e-02,  7.24102184e-03,  4.26395275e-02,  1.35215409e-02,\n",
              "       -2.39822753e-02, -2.91573536e-02,  1.09200105e-02,  2.30619349e-02,\n",
              "       -1.05881579e-02,  1.78122260e-02, -3.26630101e-02, -4.85124104e-02,\n",
              "        1.00157857e-02,  2.16158070e-02,  3.35370377e-03,  3.19241323e-02,\n",
              "       -4.25206088e-02,  4.87149879e-03,  4.74084504e-02,  3.96238826e-02,\n",
              "       -1.89575311e-02, -1.51623115e-02, -4.83855270e-02,  1.05676055e-02,\n",
              "        3.03056948e-02,  5.47470897e-03, -3.57606038e-02,  2.42167152e-02,\n",
              "       -3.00684702e-02, -4.57648300e-02, -1.88264381e-02, -4.04831879e-02,\n",
              "        3.24849226e-02,  4.73359562e-02, -3.17935944e-02,  2.44444050e-02,\n",
              "       -6.51400164e-03,  2.71933787e-02, -4.63437103e-02, -2.69668829e-02,\n",
              "       -7.20766932e-03,  6.79913908e-03,  4.62226383e-02,  2.60504521e-02,\n",
              "       -4.54571024e-02, -4.87663522e-02,  3.15819867e-02, -4.92720678e-03,\n",
              "       -1.35101676e-02,  1.52980201e-02,  2.26378441e-03, -3.03749572e-02,\n",
              "        2.78015397e-02,  1.39578693e-02,  3.20549943e-02,  3.86932380e-02,\n",
              "        3.11459564e-02, -4.87685204e-03,  4.48539145e-02,  1.33648179e-02,\n",
              "       -2.85824426e-02, -4.31322828e-02,  1.41816027e-02,  1.66112669e-02,\n",
              "        4.25197817e-02,  1.94861740e-03, -6.18734211e-03, -1.48628727e-02,\n",
              "       -3.84002924e-02,  1.63287260e-02,  3.15901078e-02,  4.35269214e-02,\n",
              "       -2.93611418e-02, -2.53102910e-02, -3.71610634e-02, -7.63791800e-03,\n",
              "       -2.54146215e-02,  3.31505798e-02,  2.53825299e-02,  1.13288760e-02,\n",
              "        3.63402106e-02, -2.17980146e-02,  4.63479199e-02, -3.37743983e-02,\n",
              "        2.30698697e-02,  4.26241867e-02,  3.65972035e-02,  2.18712129e-02,\n",
              "       -3.03509124e-02,  3.09586264e-02,  2.96589173e-02,  2.96345092e-02,\n",
              "        2.93532275e-02, -1.91210397e-02,  3.55691426e-02,  4.42929752e-02,\n",
              "        1.03829391e-02, -6.16200268e-05,  8.36286694e-03, -1.87453032e-02,\n",
              "        1.36763938e-02,  1.17676258e-02, -4.16004062e-02, -1.01246610e-02,\n",
              "        3.97802107e-02, -2.29320172e-02,  1.43612735e-02, -4.49011326e-02,\n",
              "       -6.37838989e-03, -3.96785028e-02, -2.91288029e-02,  1.42023079e-02],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-rkCUyE1Eqr"
      },
      "source": [
        "# Modelling a text dataset\n",
        "\n",
        "* Model 0: Naive Bayes (baseline)\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model\n",
        "* Model 3: GRU model\n",
        "* Model 4: Bidirectional-LSTM model\n",
        "* Model 5: 1D Convolutional Neural Network\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "Each experiment will go through the following steps:\n",
        "\n",
        "1. Construct the model\n",
        "2. Train the model\n",
        "3. Make predictions with the model\n",
        "4. Track prediction evaluation metrics for later comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZGcs6H61Ri1"
      },
      "source": [
        "## Model 0 : Getting a baseline\n",
        "\n",
        "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the Multinomial Naive Bayes algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnzvYAHD17Nx",
        "outputId": "13fa7afd-56e6-4e2b-9432-3cb05f713677"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([(\"tfidf\", TfidfVectorizer()),   # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB())        # model the text\n",
        "])\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf1yT0id236g",
        "outputId": "ca2daac6-00c7-4d17-83cc-c17522185e5e"
      },
      "source": [
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_w6zAIJ27iW",
        "outputId": "a2e3c469-ed32-4e3e-895a-04e035945157"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_u_wv_U2_MZ"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwan_vPI3M2m"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a\n",
        "  binary classification model.\n",
        "  Args :\n",
        "  ----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\" : model_accuracy,\n",
        "                   \"precision\" : model_precision,\n",
        "                   \"recall\" : model_recall,\n",
        "                   \"f1\" : model_f1}\n",
        "  return model_results"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIdxzmO14xha",
        "outputId": "cd96db53-a441-41ca-ad39-0b6bd8627093"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmzjLJ7L5EMn"
      },
      "source": [
        "## Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1dmi4L26o7c"
      },
      "source": [
        "# Create tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCOPryYusNkS"
      },
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GZZNbfnsREC"
      },
      "source": [
        "Looking good. Our model takes a 1-dimensional string as input (in our case, a Tweet), it then tokenizes the string using text_vectorizer and creates an embedding using embedding.\n",
        "\n",
        "We then (optionally) pool the outputs of the embedding layer to reduce the dimensionality of the tensor we pass to the output layer.\n",
        "\n",
        "Finally, we pass the output of the pooling layer to a dense layer with sigmoid activation (we use sigmoid since our problem is binary classification).\n",
        "\n",
        "Before we can fit our model to the data, we've got to compile it. Since we're working with binary classification, we'll use \"binary_crossentropy\" as our loss function and the Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8bKocJTsWof",
        "outputId": "c7289a9c-0f79-427f-dc02-c0276b17de4d"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "# Get a summary of the model\n",
        "model_1.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgDfdovfshxi"
      },
      "source": [
        "Most of the trainable parameters are contained within the embedding layer. Recall we created an embedding of size 128 (output_dim=128) for a vocabulary of size 10,000 (input_dim=10000), hence the 1,280,000 trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-FzE1Yfsl1g",
        "outputId": "d085be3f-2cd1-4bc8-a043-b6542b245bcf"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20210605-065617\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 17ms/step - loss: 0.6104 - accuracy: 0.6887 - val_loss: 0.5328 - val_accuracy: 0.7638\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.4406 - accuracy: 0.8216 - val_loss: 0.4692 - val_accuracy: 0.7822\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.3457 - accuracy: 0.8643 - val_loss: 0.4615 - val_accuracy: 0.7927\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.2837 - accuracy: 0.8921 - val_loss: 0.4646 - val_accuracy: 0.7927\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.2369 - accuracy: 0.9143 - val_loss: 0.4840 - val_accuracy: 0.7861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqooEmcZsmsO",
        "outputId": "8a644ad6-462e-47f2-bb77-b5dc032bd97f"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4840349853038788, 0.7860892415046692]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORsVe10VswQv",
        "outputId": "1683ed22-57c9-45bc-e891-8dde1874d4d9"
      },
      "source": [
        "# Make predictions (these come back in the form of probabilities)\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.31381956],\n",
              "       [0.71311873],\n",
              "       [0.99789065],\n",
              "       [0.10159325],\n",
              "       [0.10057276],\n",
              "       [0.93303365],\n",
              "       [0.90955526],\n",
              "       [0.9927729 ],\n",
              "       [0.9641858 ],\n",
              "       [0.24115662]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7p-bC6juQSS",
        "outputId": "d40a26c9-e7b8-4555-cb83-4b4bb1874c3b"
      },
      "source": [
        "# Turn prediction probabilities into single-dimension tensor of floats\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
        "model_1_preds[:20]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5Bqqto0uTgo",
        "outputId": "d23679c1-3fa3-40e2-f4da-a6f6252000d6"
      },
      "source": [
        "# Calculate model_1 metrics\n",
        "model_1_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.60892388451444,\n",
              " 'f1': 0.7822223876855834,\n",
              " 'precision': 0.7936252368304625,\n",
              " 'recall': 0.7860892388451444}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCP4mMGIuW1D",
        "outputId": "e429a662-4d34-44a2-c611-b588ca82a4d4"
      },
      "source": [
        "# Create a helper function to compare our baseline results to new model results\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
        "                                new_model_results=model_1_results)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 78.61, Difference: -0.66\n",
            "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
            "Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riI-tesyueHX"
      },
      "source": [
        "### Visualizing learned embeddings\n",
        "\n",
        "Our first model (`model_1`) contained an embedding layer (`embedding`) which learned a way of representing words as feature vectors by passing over the training data.\n",
        "\n",
        "Hearing this for the first few times may sound confusing.\n",
        "\n",
        "So to further help understand what a text embedding is, let's visualize the embedding our model learned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhgbORq-uuof",
        "outputId": "39e8191c-018f-4da2-f006-fb50e30dded7"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuk6W075u8-6",
        "outputId": "8210dc65-388b-404a-f70d-ad4782cd486e"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO5YA8zpvLM0",
        "outputId": "43576c5a-da6f-4ba9-e93d-90ce7c35dbb6"
      },
      "source": [
        "# Get the weight matrix of embedding layer \n",
        "# (these are the numerical patterns between the text in the training dataset the model has learned)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "print(embed_weights.shape) # same size as vocab size and embedding_dim (each word is a embedding_dim size vector)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM2Ch7K5vNTV"
      },
      "source": [
        "import io\n",
        "\n",
        "# Create output writers\n",
        "out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# Write embedding vectors and words to file\n",
        "for num, word in enumerate(words_in_vocab):\n",
        "  if num == 0: \n",
        "     continue # skip padding token\n",
        "  vec = embed_weights[num]\n",
        "  out_m.write(word + \"\\n\") # write words to file\n",
        "  out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "out_v.close()\n",
        "out_m.close()\n",
        "\n",
        "# Download files locally to upload to Embedding Projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(\"embedding_vectors.tsv\")\n",
        "  files.download(\"embedding_metadata.tsv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4Y00bHFvbo0"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "For our next series of modelling experiments we're going to be using a special kind of neural network called a **Recurrent Neural Network (RNN)**.\n",
        "\n",
        "The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (X) and compute an output (y) based on all previous inputs.\n",
        "\n",
        "This concept is especially helpful when dealing with sequences such as passages of natural language text (such as our Tweets).\n",
        "\n",
        "Recurrent neural networks can be used for a number of sequence-based problems:\n",
        "\n",
        "* **One to one:** one input, one output, such as image classification.\n",
        "* **One to many:** one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
        "* **Many to one:** many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
        "* **Many to many:** many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output).\n",
        "\n",
        "When you come across RNN's in the wild, you'll most likely come across variants of the following:\n",
        "\n",
        "* `Long short-term memory cells (LSTMs)`.\n",
        "* `Gated recurrent units (GRUs)`.\n",
        "* `Bidirectional RNN's` (passes forward and backward along a sequence, left to right and right to left).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NybRkOd6z5L-"
      },
      "source": [
        "### Model 2 : LSTM\n",
        "\n",
        "We're going to start with an LSTM-powered RNN.\n",
        "\n",
        "To harness the power of the LSTM cell (LSTM cell and LSTM layer are often used interchangably) in TensorFlow, we'll use `tensorflow.keras.layers.LSTM()`.\n",
        "\n",
        "Our model is going to take on a very similar structure to `model_1`:\n",
        "\n",
        "`Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv7_eMLn0maK",
        "outputId": "f8981269-fc57-4c86-a65c-4a1c84a0244f"
      },
      "source": [
        "# Create LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences =True)\n",
        "x = layers.LSTM(64)(x)    # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)    # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdDKQ0IB2WCy"
      },
      "source": [
        "# Compile model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T54TPUoB2lOs",
        "outputId": "a6d05a81-9781-409f-c575-38566bb73203"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTAMAGku2m4F",
        "outputId": "3560b5bd-33fc-4c9e-bf52-b30b640ae627"
      },
      "source": [
        "# Fit model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"LSTM\")])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20210605-065637\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 21ms/step - loss: 0.2238 - accuracy: 0.9181 - val_loss: 0.5158 - val_accuracy: 0.7861\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.1588 - accuracy: 0.9412 - val_loss: 0.6217 - val_accuracy: 0.7822\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.1266 - accuracy: 0.9530 - val_loss: 0.7802 - val_accuracy: 0.7769\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.1055 - accuracy: 0.9588 - val_loss: 0.8308 - val_accuracy: 0.7808\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0851 - accuracy: 0.9673 - val_loss: 0.9299 - val_accuracy: 0.7730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-I496P72qY9",
        "outputId": "5fc0cf5f-7113-4d2c-9e8b-c3daaea6a5e8"
      },
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[1.3029672e-02],\n",
              "        [8.8546664e-01],\n",
              "        [9.9976724e-01],\n",
              "        [2.2855008e-02],\n",
              "        [3.8762722e-04],\n",
              "        [9.9801648e-01],\n",
              "        [8.9397603e-01],\n",
              "        [9.9980873e-01],\n",
              "        [9.9967003e-01],\n",
              "        [3.3487469e-01]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG3vgSXZ22iw",
        "outputId": "b0dc85b1-ace0-450c-97b7-b4d5395a520c"
      },
      "source": [
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnloacRf26I8",
        "outputId": "b78a5aa4-c5f0-4cbe-897d-f7b0f25ec8d5"
      },
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.29658792650919,\n",
              " 'f1': 0.7709704727215051,\n",
              " 'precision': 0.7745161732477092,\n",
              " 'recall': 0.7729658792650919}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcYhr0u72-fl",
        "outputId": "9581e087-8dcc-4a9f-9453-8683b9a90615"
      },
      "source": [
        "# Compare model 2 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.30, Difference: -1.97\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LOA8-Ke3BAs"
      },
      "source": [
        "### Model 3 : GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters.\n",
        "\n",
        "To use the GRU cell in TensorFlow, we can call the `tensorflow.keras.layers.GRU()` class.\n",
        "\n",
        "The architecture of the GRU-powered model will follow the same structure we've been using:\n",
        "\n",
        "`Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVGa5Cdc4HLl"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x = layers.GRU(64)(x) \n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4Kdu0Sh4K8g"
      },
      "source": [
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shCmwESH4Mz-",
        "outputId": "705258b6-9087-434e-ba1d-bb659cc79398"
      },
      "source": [
        "# Get a summary of the GRU model\n",
        "model_3.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PFaN8tW4Pbs"
      },
      "source": [
        "Notice the difference in number of trainable parameters between `model_2` (LSTM) and `model_3` (GRU). The difference comes from the LSTM cell having more trainable parameters than the GRU cell.\n",
        "\n",
        "We'll fit our model just as we've been doing previously. We'll also track our models results using our `create_tensorboard_callback()` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJgSyisX4Y75",
        "outputId": "d6273d77-2a0e-4523-c782-6581503acf42"
      },
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20210605-065721\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 20ms/step - loss: 0.1628 - accuracy: 0.9364 - val_loss: 0.7004 - val_accuracy: 0.7664\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0858 - accuracy: 0.9673 - val_loss: 0.8205 - val_accuracy: 0.7756\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0722 - accuracy: 0.9711 - val_loss: 1.0441 - val_accuracy: 0.7717\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0579 - accuracy: 0.9750 - val_loss: 0.9668 - val_accuracy: 0.7743\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0517 - accuracy: 0.9771 - val_loss: 1.4435 - val_accuracy: 0.7677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIWW-sd84bHj",
        "outputId": "41666c21-0e37-4b4f-c274-461d0221faba"
      },
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[9.2827067e-05],\n",
              "        [7.5632554e-01],\n",
              "        [9.9988580e-01],\n",
              "        [5.6445368e-02],\n",
              "        [4.8615821e-05],\n",
              "        [9.9985492e-01],\n",
              "        [9.5732814e-01],\n",
              "        [9.9995625e-01],\n",
              "        [9.9991417e-01],\n",
              "        [9.9000156e-01]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQu1JfjE4d7t",
        "outputId": "85c754e7-736e-4288-8b5f-37d164d4b9c4"
      },
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Iqwa6K4gMQ",
        "outputId": "47a54edd-ddc4-4067-afd6-6b02000c135f"
      },
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.77165354330708,\n",
              " 'f1': 0.7649853724238768,\n",
              " 'precision': 0.7705418629507439,\n",
              " 'recall': 0.7677165354330708}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et6oL1rp4ilX",
        "outputId": "511f2795-4e73-4b97-dcaf-58a42d22b44a"
      },
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.77, Difference: -2.49\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.76, Difference: -0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmKI4_0u4k0a"
      },
      "source": [
        "### Model 4 : Bidirectional RNN Model\n",
        "\n",
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
        "\n",
        "Once again, TensorFlow helps us out by providing the `tensorflow.keras.layers.Bidirectional` class. We can use the Bidirectional class to wrap our existing RNNs, instantly making them bidirectional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOeL45nG6dDo"
      },
      "source": [
        "# Build a Bidirectional RNN in TensorFlow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtgPMDAk6hia"
      },
      "source": [
        "# Compile\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up43_S1A6lgJ",
        "outputId": "782d402a-8da9-4d8e-a74a-aecd70576e37"
      },
      "source": [
        "# Get a summary of our bidirectional model\n",
        "model_4.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDy7O9To6sTm"
      },
      "source": [
        "Notice the increased number of trainable parameters in model_4 (bidirectional LSTM) compared to model_2 (regular LSTM). This is due to the bidirectionality we added to our RNN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4uWywRY6uEU",
        "outputId": "81e9979d-0973-467b-85c5-c27df73d637d"
      },
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20210605-065741\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 23ms/step - loss: 0.1118 - accuracy: 0.9648 - val_loss: 1.0226 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0537 - accuracy: 0.9780 - val_loss: 1.1940 - val_accuracy: 0.7664\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0519 - accuracy: 0.9784 - val_loss: 1.1585 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0419 - accuracy: 0.9801 - val_loss: 1.2296 - val_accuracy: 0.7703\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0391 - accuracy: 0.9804 - val_loss: 1.5183 - val_accuracy: 0.7690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dn_WtsY6wZ6",
        "outputId": "e2cdbefc-0305-43ef-ee6e-a95815155eb5"
      },
      "source": [
        "# Make predictions with bidirectional RNN on the validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.3188689e-03],\n",
              "       [6.9924265e-01],\n",
              "       [9.9998748e-01],\n",
              "       [1.0427738e-01],\n",
              "       [9.1959791e-06],\n",
              "       [9.9937916e-01],\n",
              "       [6.5241265e-01],\n",
              "       [9.9998748e-01],\n",
              "       [9.9998426e-01],\n",
              "       [9.9553156e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5QDhOHq65zl",
        "outputId": "ba50c9ba-345a-4217-e28c-c5cec5c4bfe3"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvqmgtQE678n",
        "outputId": "0d6b95f6-6515-4f91-95b4-e1c9ea33cc64"
      },
      "source": [
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'f1': 0.7670626202962317,\n",
              " 'precision': 0.7703609632684677,\n",
              " 'recall': 0.7690288713910761}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOe5opPj6-ot",
        "outputId": "2a6e3e62-46b9-47f0-df3c-40ee03292c19"
      },
      "source": [
        "# Check to see how the bidirectional model performs against the baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.90, Difference: -2.36\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh23_Rfr7ChK"
      },
      "source": [
        "## Covolutional Neural Networks for Text\n",
        "\n",
        "The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n",
        "\n",
        "So to use CNNs with sequences, we use a 1-dimensional convolution instead of a 2-dimensional convolution.\n",
        "\n",
        "A typical CNN architecture for sequences will look like the following:\n",
        "\n",
        "`Inputs (text) -> Tokenization -> Embedding -> Layers -> Outputs (class probabilities)`\n",
        "\n",
        "The difference again is in the layers component. Instead of using an LSTM or GRU cell, we're going to use a `tensorflow.keras.layers.Conv1D()` layer followed by a `tensorflow.keras.layers.GlobablMaxPool1D()` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZQgXQEvyZFf"
      },
      "source": [
        "### Model 5 : Conv1D\n",
        "\n",
        "Before we build a full 1-dimensional CNN model, let's see a 1-dimensional convolutional layer (also called a temporal convolution) in action.\n",
        "\n",
        "We'll first create an embedding of a sample of text and experiment passing it through a `Conv1D()` layer and `GlobalMaxPool1D()` layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17ATOrZLyjfx",
        "outputId": "17122619-791e-4f83-d96a-c82d23c6e38e"
      },
      "source": [
        "# Test out the embedding, 1D convolutional and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve over target sequence 5 words at a time\n",
        "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
        "max_pool = layers.GlobalMaxPool1D() \n",
        "max_pool_output = max_pool(conv_1d_output) # get the most important features\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqoFNvRo0m85"
      },
      "source": [
        "The embedding has an output shape dimension of the parameters we set it to (`input_length=15` and `output_dim=128`).\n",
        "\n",
        "The 1-dimensional convolutional layer has an output which has been compressed inline with its parameters. And the same goes for the max pooling layer output.\n",
        "\n",
        "Our text starts out as a string but gets converted to a feature vector of length 64 through various transformation steps (from tokenization to embedding to 1-dimensional convolution to max pool)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X7iYs61z20x",
        "outputId": "31f2e04b-c07a-44df-d7c0-328e0d5cbcf9"
      },
      "source": [
        "# See the outputs of each layer\n",
        "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              " array([[[ 0.01374843,  0.02129278,  0.02984431, ..., -0.07407638,\n",
              "           0.0354228 ,  0.0142892 ],\n",
              "         [-0.01900367,  0.09623166,  0.00663293, ..., -0.04154462,\n",
              "           0.07931519, -0.04664357],\n",
              "         [-0.05866097, -0.01341076,  0.0341325 , ..., -0.01316493,\n",
              "           0.02184204, -0.00182547],\n",
              "         ...,\n",
              "         [-0.00577683, -0.01886478, -0.01328105, ..., -0.04913909,\n",
              "           0.00375702, -0.00399138],\n",
              "         [-0.00577683, -0.01886478, -0.01328105, ..., -0.04913909,\n",
              "           0.00375702, -0.00399138],\n",
              "         [-0.00577683, -0.01886478, -0.01328105, ..., -0.04913909,\n",
              "           0.00375702, -0.00399138]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              " array([[[0.08912495, 0.        , 0.04773278, 0.        , 0.        ,\n",
              "          0.04623758, 0.        , 0.09865971, 0.07878119, 0.        ,\n",
              "          0.        , 0.06558101, 0.00714454, 0.01820039, 0.02504179,\n",
              "          0.        , 0.        , 0.03159903, 0.        , 0.00761626,\n",
              "          0.04536571, 0.05004644, 0.00557673, 0.12001723, 0.        ,\n",
              "          0.01362148, 0.        , 0.00889037, 0.        , 0.        ,\n",
              "          0.08316293, 0.04086177],\n",
              "         [0.09485511, 0.        , 0.00132187, 0.        , 0.        ,\n",
              "          0.0061956 , 0.        , 0.        , 0.06749987, 0.03014896,\n",
              "          0.0615385 , 0.        , 0.        , 0.        , 0.01331794,\n",
              "          0.01341588, 0.04845958, 0.01672923, 0.        , 0.        ,\n",
              "          0.00670791, 0.        , 0.05380431, 0.00871072, 0.        ,\n",
              "          0.        , 0.        , 0.00930256, 0.        , 0.        ,\n",
              "          0.02358385, 0.        ],\n",
              "         [0.0479188 , 0.03846999, 0.        , 0.01437194, 0.0025095 ,\n",
              "          0.00202227, 0.01332944, 0.        , 0.04472027, 0.        ,\n",
              "          0.00020374, 0.00292884, 0.06616978, 0.        , 0.04558297,\n",
              "          0.03000198, 0.        , 0.        , 0.        , 0.04691436,\n",
              "          0.05515365, 0.04897699, 0.00239109, 0.        , 0.02445281,\n",
              "          0.00776025, 0.        , 0.        , 0.01642495, 0.02852213,\n",
              "          0.03576478, 0.01644791],\n",
              "         [0.03580688, 0.03844727, 0.03576411, 0.        , 0.023699  ,\n",
              "          0.05583078, 0.        , 0.        , 0.02738103, 0.00136114,\n",
              "          0.03325984, 0.        , 0.03008655, 0.        , 0.        ,\n",
              "          0.        , 0.        , 0.01619207, 0.00964863, 0.        ,\n",
              "          0.01305135, 0.        , 0.00323906, 0.        , 0.03380041,\n",
              "          0.04608539, 0.        , 0.        , 0.        , 0.02886245,\n",
              "          0.02776176, 0.02873435],\n",
              "         [0.        , 0.00865812, 0.02239072, 0.        , 0.02661895,\n",
              "          0.02934175, 0.        , 0.02772379, 0.        , 0.        ,\n",
              "          0.        , 0.        , 0.0557284 , 0.        , 0.0428319 ,\n",
              "          0.        , 0.02616863, 0.06860927, 0.03900579, 0.        ,\n",
              "          0.03917753, 0.01648356, 0.        , 0.        , 0.01736121,\n",
              "          0.03836705, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01087262, 0.00645511, 0.01555661, 0.        , 0.01248788,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.01910791, 0.        , 0.03864025, 0.        , 0.00798424,\n",
              "          0.        , 0.02991701, 0.02722055, 0.00581853, 0.00587285,\n",
              "          0.03305376, 0.0230267 , 0.01548645, 0.        , 0.03023105,\n",
              "          0.02871349, 0.00293097, 0.        , 0.        , 0.        ,\n",
              "          0.02524621, 0.        ],\n",
              "         [0.01087262, 0.00645511, 0.0155566 , 0.        , 0.01248788,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.01910791, 0.        , 0.03864025, 0.        , 0.00798424,\n",
              "          0.        , 0.02991702, 0.02722055, 0.00581853, 0.00587285,\n",
              "          0.03305377, 0.02302671, 0.01548644, 0.        , 0.03023105,\n",
              "          0.0287135 , 0.00293097, 0.        , 0.        , 0.        ,\n",
              "          0.02524621, 0.        ],\n",
              "         [0.01087261, 0.00645511, 0.0155566 , 0.        , 0.01248788,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.01910791, 0.        , 0.03864025, 0.        , 0.00798425,\n",
              "          0.        , 0.02991701, 0.02722055, 0.00581853, 0.00587284,\n",
              "          0.03305376, 0.02302671, 0.01548645, 0.        , 0.03023105,\n",
              "          0.0287135 , 0.00293097, 0.        , 0.        , 0.        ,\n",
              "          0.02524622, 0.        ],\n",
              "         [0.01087262, 0.00645511, 0.0155566 , 0.        , 0.01248787,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.01910791, 0.        , 0.03864024, 0.        , 0.00798424,\n",
              "          0.        , 0.02991702, 0.02722055, 0.00581853, 0.00587285,\n",
              "          0.03305378, 0.0230267 , 0.01548644, 0.        , 0.03023105,\n",
              "          0.0287135 , 0.00293097, 0.        , 0.        , 0.        ,\n",
              "          0.02524622, 0.        ],\n",
              "         [0.01087262, 0.00645511, 0.0155566 , 0.        , 0.01248787,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.0191079 , 0.        , 0.03864025, 0.        , 0.00798424,\n",
              "          0.        , 0.02991703, 0.02722055, 0.00581853, 0.00587285,\n",
              "          0.03305376, 0.0230267 , 0.01548644, 0.        , 0.03023105,\n",
              "          0.02871349, 0.00293096, 0.        , 0.        , 0.        ,\n",
              "          0.02524621, 0.        ],\n",
              "         [0.01087262, 0.00645512, 0.0155566 , 0.        , 0.01248788,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.0191079 , 0.        , 0.03864025, 0.        , 0.00798425,\n",
              "          0.        , 0.02991701, 0.02722056, 0.00581853, 0.00587285,\n",
              "          0.03305377, 0.02302671, 0.01548645, 0.        , 0.03023105,\n",
              "          0.0287135 , 0.00293098, 0.        , 0.        , 0.        ,\n",
              "          0.02524622, 0.        ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              " array([[0.09485511, 0.03846999, 0.04773278, 0.01437194, 0.02661895,\n",
              "         0.05583078, 0.01332944, 0.09865971, 0.07878119, 0.03014896,\n",
              "         0.0615385 , 0.06558101, 0.06616978, 0.01820039, 0.04558297,\n",
              "         0.03000198, 0.04845958, 0.06860927, 0.03900579, 0.04691436,\n",
              "         0.05515365, 0.05004644, 0.05380431, 0.12001723, 0.03380041,\n",
              "         0.04608539, 0.00293098, 0.00930256, 0.01642495, 0.02886245,\n",
              "         0.08316293, 0.04086177]], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VODCXmB1L1b",
        "outputId": "ee5d7172-f6a7-46be-e752-4ae048b10364"
      },
      "source": [
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of our 1D convolution model\n",
        "model_5.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 32)            20512     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxYFQMr51P_G",
        "outputId": "93333057-166d-4ba6-f8f9-c29aea4287c3"
      },
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"Conv1D\")])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20210605-065830\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 19ms/step - loss: 0.1311 - accuracy: 0.9585 - val_loss: 0.8628 - val_accuracy: 0.7677\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0761 - accuracy: 0.9749 - val_loss: 1.0096 - val_accuracy: 0.7677\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0628 - accuracy: 0.9752 - val_loss: 1.0823 - val_accuracy: 0.7598\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0542 - accuracy: 0.9791 - val_loss: 1.1472 - val_accuracy: 0.7598\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0498 - accuracy: 0.9794 - val_loss: 1.2126 - val_accuracy: 0.7598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C88htasE1TN4",
        "outputId": "54472b0a-83e4-435f-a20f-087754147a12"
      },
      "source": [
        "# Make predictions with model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.2933905e-01],\n",
              "       [7.4059081e-01],\n",
              "       [9.9996722e-01],\n",
              "       [7.2094992e-02],\n",
              "       [4.9123884e-08],\n",
              "       [9.9334782e-01],\n",
              "       [9.8978406e-01],\n",
              "       [9.9998820e-01],\n",
              "       [9.9999988e-01],\n",
              "       [8.8409293e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILIcRiXW1XBo",
        "outputId": "b6a84ed7-89ad-4510-b9e8-bb8b90b97f4c"
      },
      "source": [
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJHEQizw1Z4M",
        "outputId": "0981c628-f262-4c68-b05e-d642de9f94b9"
      },
      "source": [
        "# Calculate model_5 evaluation metrics \n",
        "model_5_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.98425196850394,\n",
              " 'f1': 0.758578322737536,\n",
              " 'precision': 0.7598710707718088,\n",
              " 'recall': 0.7598425196850394}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiVNc3bF1cOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c046a8-4bc8-42f9-c135-0fc1a36b304f"
      },
      "source": [
        "# Compare model_5 results to baseline \n",
        "compare_baseline_to_new_results(baseline_results, model_5_results)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 75.98, Difference: -3.28\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
            "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.76, Difference: -0.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HQ21KW6_2sQ"
      },
      "source": [
        "## Using Pretrained Embeddings (transfer learning for NLP )\n",
        "\n",
        "However, a common practice is to leverage pretrained embeddings through transfer learning. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned (often on a large amount of data) and adjust it for our own use case.\n",
        "\n",
        "More specifically, we're going to be using the Universal Sentence Encoder from TensorFlow Hub (a great resource containing a plethora of pretrained model resources for a variety of tasks)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOkx2QGA1emw"
      },
      "source": [
        "### Model 6 : TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "The main difference between the embedding layer we created and the **Universal Sentence Encoder** is that rather than create a word-level embedding, the **Universal Sentence Encoder**, as you might've guessed, creates a whole sentence-level embedding.\n",
        "\n",
        "*Our embedding layer also outputs an a 128 dimensional vector for each word, where as, the Universal Sentence Encoder outputs a 512 dimensional vector for each sentence.*\n",
        "\n",
        "We can load in a TensorFlow Hub module using the `hub.load()` method and passing it the target URL of the module we'd like to use, in our case, it's `\"https://tfhub.dev/google/universal-sentence-encoder/4\"`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "errBgBv5ATZO",
        "outputId": "1db0a355-8335-4773-e881-5ddb57222572"
      },
      "source": [
        "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
        "embed_samples = embed([sample_sentence,\n",
        "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[-0.00227923  0.02503782  0.05165793 -0.02049924  0.06524664  0.07871991\n",
            "  0.04292819  0.05375134  0.02137922 -0.01271617  0.01633732 -0.0236556\n",
            " -0.00251637  0.08856936  0.04738833 -0.03504737  0.01855711 -0.01724731\n",
            " -0.0171118  -0.02748966 -0.0463478   0.03816369  0.06219235  0.01337105\n",
            " -0.02875983 -0.05794404  0.03516345 -0.00216923 -0.04345246 -0.02009531\n",
            " -0.06199861  0.03515631 -0.0169575  -0.0254854  -0.02920206 -0.0685383\n",
            "  0.02810755  0.03589788  0.01183301 -0.07927105  0.030587   -0.02572455\n",
            " -0.03626588  0.04522885 -0.10527454 -0.00228848 -0.01724683  0.00489267\n",
            " -0.01167761  0.03022392], shape=(50,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKjWd9VDAV7D",
        "outputId": "908ac5f2-271f-4aa1-eda9-96a4402d2c24"
      },
      "source": [
        "# Each sentence has been encoded into a 512 dimension vector\n",
        "embed_samples[0].shape"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LFByRSCA17w"
      },
      "source": [
        "Passing our sentences to the Universal Sentence Encoder (USE) encodes them from strings to 512 dimensional vectors, which make no sense to us but hopefully make sense to our machine learning models.\n",
        "\n",
        "Speaking of models, let's build one with the USE as our embedding layer.\n",
        "\n",
        "We can convert the TensorFlow Hub USE module into a Keras layer using the hub.KerasLayer class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed9waZUIAuKH"
      },
      "source": [
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bE1b-QiA3rC",
        "outputId": "260e0ef0-8928-4629-9610-55bba26590f0"
      },
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lbAnPnMA7hL",
        "outputId": "738cd607-bcbc-4186-b721-6a5bbf497a1c"
      },
      "source": [
        "# Train a classifier on top of pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210605-071229\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 23ms/step - loss: 0.5029 - accuracy: 0.7844 - val_loss: 0.4496 - val_accuracy: 0.8018\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.4148 - accuracy: 0.8174 - val_loss: 0.4360 - val_accuracy: 0.8110\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.4011 - accuracy: 0.8228 - val_loss: 0.4374 - val_accuracy: 0.8071\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3937 - accuracy: 0.8266 - val_loss: 0.4301 - val_accuracy: 0.8123\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3869 - accuracy: 0.8289 - val_loss: 0.4265 - val_accuracy: 0.8150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZy1USL2BBye",
        "outputId": "50b52293-1cf5-4bf8-f5f9-1996a8129ec0"
      },
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19880572],\n",
              "       [0.78401333],\n",
              "       [0.9865013 ],\n",
              "       [0.22457188],\n",
              "       [0.7512788 ],\n",
              "       [0.7497252 ],\n",
              "       [0.98350656],\n",
              "       [0.9796083 ],\n",
              "       [0.94336957],\n",
              "       [0.09099196]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsaWziVZBL10",
        "outputId": "adf9d096-ff9f-43c8-c0b6-70e8569646e2"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcZnehcbBN7M",
        "outputId": "e1b3c869-beb3-4ad5-c33c-7c1fe89795b5"
      },
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.49606299212599,\n",
              " 'f1': 0.8138139523860313,\n",
              " 'precision': 0.8161852632862286,\n",
              " 'recall': 0.8149606299212598}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ezhhwoXBP53",
        "outputId": "ea25f83e-c62a-41c3-aab6-a9bcfbb3378a"
      },
      "source": [
        "# Compare TF Hub model to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_6_results)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 81.50, Difference: 2.23\n",
            "Baseline precision: 0.81, New precision: 0.82, Difference: 0.01\n",
            "Baseline recall: 0.79, New recall: 0.81, Difference: 0.02\n",
            "Baseline f1: 0.79, New f1: 0.81, Difference: 0.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpCwTlTwBSys"
      },
      "source": [
        "### Model 7 : Tensorflow Hub Pretrained Sentence Encoder 10% of the training data\n",
        "\n",
        "One of the benefits of using transfer learning methods, such as, the pretrained embeddings within the USE is the ability to get great results on a small amount of data (the USE paper even mentions this in the abstract).\n",
        "\n",
        "To put this to the test, we're going to make a small subset of the training data (10%), train a model and evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwt0L2TNBy30"
      },
      "source": [
        "### NOTE: Making splits like this will lead to data leakage ###\n",
        "### (some of the training examples in the validation set) ###\n",
        "\n",
        "### WRONG WAY TO MAKE SPLITS (train_df_shuffled has already been split) ### \n",
        "\n",
        "# # Create subsets of 10% of the training data\n",
        "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVJYHplAB5Gr",
        "outputId": "099c5055-7069-473f-cff8-a9f9e5131f4c"
      },
      "source": [
        "import numpy as np\n",
        "# One kind of correct way (there are more) to make data subset\n",
        "# (split the already split train_sentences/train_labels)\n",
        "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
        "                                                                                                                            train_labels,\n",
        "                                                                                                                            test_size=0.1,\n",
        "                                                                                                                            random_state=42)\n",
        "# Check length of 10 percent datasets\n",
        "print(f\"Total training examples: {len(train_sentences)}\")\n",
        "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training examples: 6851\n",
            "Length of 10% training examples: 686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h18yiQVSCCet",
        "outputId": "0b56b029-5196-4e21-f283-22222d6b418b"
      },
      "source": [
        "# Check the number of targets in our subset of data \n",
        "# (this should be close to the distribution of labels in the original train_labels)\n",
        "pd.Series(train_labels_10_percent).value_counts()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    415\n",
              "1    271\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUXdGAetCMP1",
        "outputId": "0bbc85e4-8dc3-4528-86b5-8eb10000d344"
      },
      "source": [
        "# Clone model_6 but reset weights\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary (will be same as model_6)\n",
        "model_7.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpcERbh1CRGN",
        "outputId": "bd515cf4-50c7-4118-ebaf-dd38c7b9d718"
      },
      "source": [
        "# Fit the model to 10% of the training data\n",
        "model_7_history = model_7.fit(x=train_sentences_10_percent,\n",
        "                              y=train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20210605-071804\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 113ms/step - loss: 0.6717 - accuracy: 0.6356 - val_loss: 0.6494 - val_accuracy: 0.7507\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6035 - accuracy: 0.7974 - val_loss: 0.5931 - val_accuracy: 0.7520\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.5299 - accuracy: 0.8265 - val_loss: 0.5407 - val_accuracy: 0.7769\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.4668 - accuracy: 0.8280 - val_loss: 0.5120 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.4203 - accuracy: 0.8309 - val_loss: 0.4891 - val_accuracy: 0.7717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyNInlPTCTnD",
        "outputId": "23455e39-48d3-49aa-9ecc-687b7814d074"
      },
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "\n",
        "# Convert prediction probabilities to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2amhpO4CcnQ",
        "outputId": "b5695796-427e-4e00-f277-b6dd07bca4b9"
      },
      "source": [
        "# Calculate model results\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.16535433070865,\n",
              " 'f1': 0.7691811868378113,\n",
              " 'precision': 0.7741380916586217,\n",
              " 'recall': 0.7716535433070866}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQyio9V5CfVg",
        "outputId": "6a845b5c-16c0-4cee-cc5a-266f49c93476"
      },
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_7_results)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.17, Difference: -2.10\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETlJ_z6gChUd"
      },
      "source": [
        "## Comaring the performance of each of our models\n",
        "\n",
        "The important thing to note is that for all of our modelling experiments we used the same training data (except for model_7 where we used 10% of the training data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "RJq01MFaC0yF",
        "outputId": "27f3396a-3f6f-425a-e007-39c206bc00d6"
      },
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"simple_dense\": model_1_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"bidirectional\": model_4_results,\n",
        "                                  \"conv1d\": model_5_results,\n",
        "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
        "                                  \"tf_hub_10_percent_data\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>78.608924</td>\n",
              "      <td>0.793625</td>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.782222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>77.296588</td>\n",
              "      <td>0.774516</td>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.770970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>76.771654</td>\n",
              "      <td>0.770542</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.764985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>76.902887</td>\n",
              "      <td>0.770361</td>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.767063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>75.984252</td>\n",
              "      <td>0.759871</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.758578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>81.496063</td>\n",
              "      <td>0.816185</td>\n",
              "      <td>0.814961</td>\n",
              "      <td>0.813814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>77.165354</td>\n",
              "      <td>0.774138</td>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.769181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "baseline                 79.265092   0.811139  0.792651  0.786219\n",
              "simple_dense             78.608924   0.793625  0.786089  0.782222\n",
              "lstm                     77.296588   0.774516  0.772966  0.770970\n",
              "gru                      76.771654   0.770542  0.767717  0.764985\n",
              "bidirectional            76.902887   0.770361  0.769029  0.767063\n",
              "conv1d                   75.984252   0.759871  0.759843  0.758578\n",
              "tf_hub_sentence_encoder  81.496063   0.816185  0.814961  0.813814\n",
              "tf_hub_10_percent_data   77.165354   0.774138  0.771654  0.769181"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "zKzRzRxkC9zG",
        "outputId": "cf8c687f-6551-4059-a997-62cf6ecebc9f"
      },
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "\n",
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqkAAAIRCAYAAABpvyTfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde5xWZb3///d7OIjIIcXxiAgip1FRFNHUslLbuks8pmCmuSt+ulPLaped1Oi0tbS9PXz3xrMWblO3KR7KrBTamSmgopwUlRA8oSKghDDy+f1xr9GbYWAGGea6hvV6Ph73g1nrXtzznvvBMO9Z67qu5YgQAAAAkJOa1AEAAACAxiipAAAAyA4lFQAAANmhpAIAACA7lFQAAABkp2OqT7z11ltH3759U316AACAFpsyZcprEVGbOkeZJCupffv21eTJk1N9egAAgBaz/ffUGcqGy/0AAADIDiUVAAAA2aGkAgAAIDvJxqQCAAC0Z1OmTNmmY8eOV0vaXZz4W1+rJD1VX1//xX322efVpg6gpAIAAHwAHTt2vHq77bYbUltbu6impiZS52lPVq1a5YULF9a9/PLLV0sa2dQxtH4AAIAPZvfa2tolFNT1V1NTE7W1tYtVOQvd9DFtmAcAAGBTUkNB/eCK926tXZSSCgAAgOwwJhUAAKAV9D33nn1a8/Xm/vunprTm67U3nEkFAADAOq1cubLNPyclFQAAoB079NBD+++2225Ddt11191+/vOfby1Jt912W4+6urohgwYNqvvwhz88UJIWL15cc/zxx/cdOHBg3cCBA+uuv/76D0lS165dhzW81nXXXbflcccd11eSjjvuuL4nnXRSn6FDhw4+44wzej/wwANd99prr8FDhgypGzZs2OAnnnhiM0mqr6/XmDFjeg8YMGC3gQMH1v34xz/eZsKECd0PPfTQ/g2v+5vf/KbHYYcd1l/rgcv9AAAA7dj48ePnbrvttu++9dZbHjZsWN2JJ5745plnntn3wQcfnDV48OAVr7zySgdJOvfcc7fv0aPHu08//fQMSVq4cGGH5l77pZde6jx16tRZHTt21BtvvFHz6KOPzurUqZPuuOOO7t/85jd733fffc9efPHFtfPmzes8Y8aM6Z06ddIrr7zSoba29t2vfOUrfV588cWOO+ywQ/21117b67TTTnttfb4uSioAAEA7duGFF257zz33fEiSXn755U6XXnpp7YgRI5YOHjx4hSRtu+2270rSpEmTetx8883PNfy92trad5t77WOPPXZRx46VuvjGG290OPHEE/vNnTu3i+1YuXKlJelPf/pTj9NPP31hp06dVP35TjjhhNevuuqqrb785S+/PnXq1G6333778+vzdVFSAQAA2qm77767+8SJE7tPnjx5Vvfu3VeNGDFi0LBhw5bNnj27S0tfw/Z7H//jH/9w9XPdunVb1fDxt771rR0PPvjgpffff/+zs2fP7vyJT3xi0Lpe94wzznj9U5/61K5dunSJI488clFDiW0pxqQCAAC0U2+++WaHnj17vtu9e/dVjz32WJcnnnhii+XLl9c88sgj3WfNmtVZkhou9x988MFLfvGLX2zT8HcbLvf36tVr5dSpU7u8++67uvPOO7dc2+dasmRJh969e6+QpHHjxm3dsP+QQw5ZMm7cuK0bJlc1fL6+ffuu3HbbbVdefPHF248ZM2a9LvVLnEkFAABoFSmWjDruuOMWX3nllbW77LLLbrvsssvyPffc8+1tttmm/tJLL517zDHH7Lpq1Sr16tVr5UMPPfTMT3/605dOO+20PgMGDNitpqYmvvOd77x46qmnvvmDH/xgwVFHHbXrVlttVb/nnnsue/vtt5s8ifmtb33r5S9+8Yv9Lrzwwh0OO+ywNxv2n3POOQuffvrpzQYPHrxbx44d49RTT134ne98Z6EkjRo16vUrrrii49577718fb82R6S5UcLw4cNj8uTJST43AADA+rA9JSKGV+974okn5u65557rfYawTE455ZQ+w4YNW3bOOec0+T498cQTW++55559m3qOM6kAAGyAvufe0+wxc7uctM7n9+jXp9nXePLUJ1ucCcjBbrvtNmTzzTdfNW7cuBc+yN+npAIA0A7MHDyk2WOGzJrZBkmAlpk+ffoG/YPc9EvqBT1bcMzijZ8DAAAALcbsfgAAAGSnRSXV9uG2Z9ueY/vcJp7vY/sB24/Znmb7n1s/KgAAAMqi2ZJqu4OkKyQdIalO0mjbdY0O+56kWyJimKRRkv5fawcFAABAebRkTOoISXMi4jlJsn2zpKMkzag6JiT1KD7uKenF1gwJAACQvQt67tO6r7e4zdddlaRJkyZ1vfbaa3tdf/31Tc7Knzt3bqfTTz99p9/97nfPNfV8a2lJSd1RUnXI+ZL2a3TMBZJ+b/ssSVtIOrSpF7I9RtIYSerTp/nlNgAAALBh6uvr1bFjy+fKf/SjH1320Y9+dNnanu/bt+/KjV1QpdabODVa0vUR0VvSP0v6pe01XjsiroyI4RExvLa2tpU+NQAAQDnNnj27c79+/XYbOXJkv1122WW3ww8/fJelS5fW7LjjjnucccYZO9bV1Q259tprt7z99tt77LXXXoPr6uqGHHHEEbssXry4RpImTpzYddiwYYMHDRpUt8ceewxZtGhRzd1339394x//+K6SdM8993QbPHhw3eDBg+uGDBlSt2jRoprZs2d3HjBgwG6StGzZMh9//PF9Bw4cWDdkyJC6u+66q7skXXrppb0++clP9v/IRz4yYOedd9799NNP772+X1tLSuoCSTtVbfcu9lX7gqRbJCki/iqpi6StBQAAgI1q7ty5Xc4888xXn3vuuendu3df9bOf/axWknr16lU/Y8aMmUceeeTSn/zkJ9tPmjTp6RkzZszce++9l/3whz/cdvny5f7sZz/b/z/+4z/mzZ49e8bEiRNnd+vWbVX1a1988cXbXXrppX+fNWvWjIcffnhW4+cvvPDCbWzr6aefnnHTTTc9N2bMmL7Lli2zJM2YMaPrHXfc8dzMmTOnT5gwYcs5c+Z0Wp+vqyXnfh+VNMB2P1XK6ShJjW+dMU/SIZKutz1ElZK6cH2CfFDN3eljbpfmX2OPG/Zo9phN7k4frB8LAMAmYbvttlvxyU9+8m1J+tznPvf6pZdeuo0knXLKKYsk6cEHH9zi2Wef7TJixIjBkrRy5Urvs88+b02bNq3LNttss/Lggw9eJklbbbXVqsavvf/++7/1jW98Y6cTTjjhjdGjRy/q37//asc89NBD3c4666xXJWnYsGHLd9hhhxVPPvlkF0k66KCDlvTq1etdSdp1112XP/vss5vtuuuuK1v6dTVbUiOi3vaZku6T1EHStREx3fZYSZMjYoKkr0u6yvY5qkyi+nxEREtDAAAA4IOx3eR29+7dV0lSROiggw5actdddz1ffdwjjzyyeXOv/ZOf/OTlo48+evGdd97Z8yMf+cjge+6555muXbuuUWab0rlz5/e6YIcOHWLlypVe1/GNtWhMakTcGxEDI6J/RPy42HdeUVAVETMi4sCI2DMi9oqI369PCAAAAHwwL730Uuc//OEPW0jS+PHjtzrggAPeqn7+Yx/72NuTJ0/u9tRTT20mSUuWLKmZNm3aZkOHDl3+6quvdpo4cWJXSVq0aFHNypWrn+icPn36ZiNGjPjHj3/845eHDh369lNPPbXaNeoDDzzwrV/96ldbSdK0adM2e+mllzoPHTp0eWt8XZv+bVFbSXP3TM7pfsnNDYGQWmcYxCY3BAIAgA2RaMmovn37Lr/sssu2GTNmTNcBAwYs/8Y3vrHw6quv3qbh+R122KF+3Lhxc0eNGrXLihUrLEnnn3/+gqFDh74zfvz4Z88+++w+y5cvr+nSpcuqSZMmPV392hdddNE2Dz30UA/bMWjQoH8cf/zxi+fNm/fe2NJvfvObr55yyik7Dxw4sK5Dhw4aN27c3M0337xVrqZTUgEAANqxjh076s4771ztUv6CBQtWO5M0cuTIpSNHjlzjjNrBBx+87IknnphVve/Tn/700k9/+tNLJemGG25YY63UQYMGrXjmmWemS1LXrl3jtttum9v4mLPPPvt1Sa83bD/wwANz1u+roqRiAzR3dlnK6wwzAABoP1prnVQAAAC0seqzmpsaSioAAACyw+V+oFpz68eydiwAtA7W60YzKKkojdZY9aCUN34AgA+Am+1gQ1FSgVa2yU0oK+nZjuZ/wDa+8d6a9ujXp9lj+AELbJhN7v9cvIeSCpQcZzvSak9rMANYtz1u2GOf1ny9J099Msm6q5deemmvyZMnb3HjjTfO+9rXvrZDt27d3h07duwrbZ2DkgqgTXC2AwA2rlWrViki1KFDh9RRWgWz+wEAANqp2bNnd+7bt+/uxxxzTN+BAwfu9s1vfnP73XfffcjAgQPrzjnnnB0ajrv88st7DRw4sG7QoEF1Rx99dD9Juummm3oOHTp08JAhQ+oOOOCAgS+88EJWJy+zCgMAAID1M2/evM2uueaa5xcvXvzGrbfeuuW0adNmRoQOPfTQXX/72992q62trf/5z3++/V//+tdZ22+/ff0rr7zSQZIOO+ywt0aNGjWrpqZGl1xyydZjx47d7qqrrpqf+utpQEkFALRIy1bI2PAJZbf8tL7Z12BoCPC+7bfffsUhhxzy9pgxY3pPmjSpR11dXZ0kLVu2rGbWrFldpk6dWnPkkUcu2n777esladttt31Xkp5//vnORx99dO+FCxd2WrFiRc1OO+30TsqvozEu9wMAALRjXbt2XSVJEaGvfvWrL82aNWvGrFmzZsybN++pc84557W1/b0zzzyzz7/+67+++vTTT8+4/PLL//7OO+9k1QuzCgMAAIAP5ogjjljyy1/+cuvFixfXSNLzzz/facGCBR3/6Z/+acldd9215csvv9xBkhou9y9durRDnz59VkrS9ddf3ytd8qZxuR8AAKAVpFoyqsGxxx67ZPr06V323XffwVLlDOv48eOfHz58+PKvf/3rL33kIx8ZXFNTE7vvvvuy//3f/5373e9+98XRo0f379mzZ/1BBx20dN68eZulzN8YJRUAAKCdGjRo0IpnnnlmesP297///Ve///3vv9r4uLPOOuv1s8466/XqfSeffPKbJ5988puNjz377LNfl/S6JF1yySUvboTYLcLlfgAAAGSHkgoAAIDsUFIBAACQHUoqAAAAskNJBQAAQHYoqQAAAMgOS1ABAAC0gpmDh+zTmq83ZNbMZtdd/dGPfrTNtddeWztgwIDlr7zySqcZM2Z0PffccxeMHTv2ldbMkgIlFQAAoJ265pprav/whz883aVLl5gzZ07n2267bcvUmVoLl/sBAADaoZNOOqnP/PnzNzviiCMGXH311VsdfPDByzp16hSpc7UWzqQCAAC0QzfddNO8iRMn9pw4ceLT22+/fX3qPK2NM6kAAADIDiUVAAAA2aGkAgAAIDuMSQUAAGgFLVkyamOZN29ex3333bfu7bff7mA7xo0bt+3MmTOf2mqrrValyrShKKkAAADt1IIFC55s+PiVV16ZljJLa+NyPwAAALJDSQUAAEB2KKkAAAAfzKpVq1Y5dYj2qnjv1jpmtkUl1fbhtmfbnmP73Cae/4Xtx4vH07bf3IDMAAAA7cFTCxcu7ElRXX+rVq3ywoULe0p6am3HNDtxynYHSVdIOkzSfEmP2p4QETMajomIc6qOP0vSsA0JDgAAkLv6+vovvvzyy1e//PLLu4ur0+trlaSn6uvrv7i2A1oyu3+EpDkR8Zwk2b5Z0lGSZqzl+NGSzl/PoAAAAO3KPvvs86qkkalzbKpa0vp3lPRC1fb8Yt8abO8sqZ+kP63l+TG2J9uevHDhwvXNCgAAgJJo7VPToyTdFhHvNvVkRFwZEcMjYnhtbW0rf2oAAABsKlpSUhdI2qlqu3exrymjJP3PhoYCAABAubWkpD4qaYDtfrY7q1JEJzQ+yPZgSVtK+mvrRgQAAEDZNFtSI6Je0pmS7pM0U9ItETHd9ljb1YOFR0m6OSJi40QFAABAWbRkdr8i4l5J9zbad16j7QtaLxYAAADKjDW9AAAAkB1KKgAAALJDSQUAAEB2KKkAAADIDiUVAAAA2aGkAgAAIDuUVAAAAGSHkgoAAIDsUFIBAACQHUoqAAAAskNJBQAAQHYoqQAAAMgOJRUAAADZoaQCAAAgO5RUAAAAZIeSCgAAgOxQUgEAAJAdSioAAACyQ0kFAABAdiipAAAAyA4lFQAAANmhpAIAACA7lFQAAABkh5IKAACA7FBSAQAAkB1KKgAAALJDSQUAAEB2KKkAAADIDiUVAAAA2aGkAgAAIDuUVAAAAGSHkgoAAIDsUFIBAACQHUoqAAAAskNJBQAAQHZaVFJtH257tu05ts9dyzEn2J5he7rtm1o3JgAAAMqkY3MH2O4g6QpJh0maL+lR2xMiYkbVMQMkfVvSgRGxyPY2GyswAAAANn0tOZM6QtKciHguIlZIulnSUY2O+ZKkKyJikSRFxKutGxMAAABl0pKSuqOkF6q25xf7qg2UNND2X2w/bPvw1goIAACA8mn2cv96vM4ASR+T1FvSJNt7RMSb1QfZHiNpjCT16dOnlT41AAAANjUtOZO6QNJOVdu9i33V5kuaEBErI+J5SU+rUlpXExFXRsTwiBheW1v7QTMDAABgE9eSkvqopAG2+9nuLGmUpAmNjrlDlbOosr21Kpf/n2vFnAAAACiRZktqRNRLOlPSfZJmSrolIqbbHmt7ZHHYfZJetz1D0gOS/i0iXt9YoQEAALBpa9GY1Ii4V9K9jfadV/VxSPpa8QAAAAA2CHecAgAAQHYoqQAAAMgOJRUAAADZoaQCAAAgO5RUAAAAZIeSCgAAgOxQUgEAAJAdSioAAACyQ0kFAABAdiipAAAAyA4lFQAAANmhpAIAACA7lFQAAABkh5IKAACA7FBSAQAAkB1KKgAAALJDSQUAAEB2KKkAAADIDiUVAAAA2aGkAgAAIDuUVAAAAGSHkgoAAIDsUFIBAACQHUoqAAAAskNJBQAAQHYoqQAAAMgOJRUAAADZoaQCAAAgO5RUAAAAZIeSCgAAgOxQUgEAAJAdSioAAACyQ0kFAABAdiipAAAAyA4lFQAAANmhpAIAACA7LSqptg+3Pdv2HNvnNvH8520vtP148fhi60cFAABAWXRs7gDbHSRdIekwSfMlPWp7QkTMaHToryPizI2QEQAAACXTkjOpIyTNiYjnImKFpJslHbVxYwEAAKDMWlJSd5T0QtX2/GJfY8fZnmb7Nts7NfVCtsfYnmx78sKFCz9AXAAAAJRBa02cuktS34gYKul+STc0dVBEXBkRwyNieG1tbSt9agAAAGxqWlJSF0iqPjPau9j3noh4PSLeKTavlrRP68QDAABAGbWkpD4qaYDtfrY7SxolaUL1Aba3r9ocKWlm60UEAABA2TQ7uz8i6m2fKek+SR0kXRsR022PlTQ5IiZIOtv2SEn1kt6Q9PmNmBkAAACbuGZLqiRFxL2S7m2077yqj78t6dutGw0AAABlxR2nAAAAkB1KKgAAALJDSQUAAEB2KKkAAADIDiUVAAAA2aGkAgAAIDuUVAAAAGSHkgoAAIDsUFIBAACQHUoqAAAAskNJBQAAQHYoqQAAAMgOJRUAAADZoaQCAAAgO5RUAAAAZIeSCgAAgOxQUgEAAJAdSioAAACyQ0kFAABAdiipAAAAyA4lFQAAANmhpAIAACA7lFQAAABkh5IKAACA7FBSAQAAkB1KKgAAALJDSQUAAEB2KKkAAADIDiUVAAAA2aGkAgAAIDuUVAAAAGSHkgoAAIDsUFIBAACQHUoqAAAAskNJBQAAQHZaVFJtH257tu05ts9dx3HH2Q7bw1svIgAAAMqm2ZJqu4OkKyQdIalO0mjbdU0c113SVyT9rbVDAgAAoFxaciZ1hKQ5EfFcRKyQdLOko5o47oeSLpS0vBXzAQAAoIRaUlJ3lPRC1fb8Yt97bO8taaeIuGddL2R7jO3JticvXLhwvcMCAACgHDZ44pTtGkmXSPp6c8dGxJURMTwihtfW1m7opwYAAMAmqiUldYGknaq2exf7GnSXtLukB23PlbS/pAlMngIAAMAH1ZKS+qikAbb72e4saZSkCQ1PRsTiiNg6IvpGRF9JD0saGRGTN0piAAAAbPKaLakRUS/pTEn3SZop6ZaImG57rO2RGzsgAAAAyqdjSw6KiHsl3dto33lrOfZjGx4LAAAAZcYdpwAAAJAdSioAAACyQ0kFAABAdiipAAAAyA4lFQAAANmhpAIAACA7lFQAAABkh5IKAACA7FBSAQAAkB1KKgAAALJDSQUAAEB2KKkAAADIDiUVAAAA2aGkAgAAIDuUVAAAAGSHkgoAAIDsUFIBAACQHUoqAAAAskNJBQAAQHYoqQAAAMgOJRUAAADZoaQCAAAgO5RUAAAAZIeSCgAAgOxQUgEAAJAdSioAAACyQ0kFAABAdiipAAAAyA4lFQAAANmhpAIAACA7lFQAAABkh5IKAACA7FBSAQAAkB1KKgAAALJDSQUAAEB2KKkAAADITotKqu3Dbc+2Pcf2uU08f7rtJ20/bvv/bNe1flQAAACURbMl1XYHSVdIOkJSnaTRTZTQmyJij4jYS9JFki5p9aQAAAAojZacSR0haU5EPBcRKyTdLOmo6gMiYknV5haSovUiAgAAoGw6tuCYHSW9ULU9X9J+jQ+y/WVJX5PUWdInmnoh22MkjZGkPn36rG9WAAAAlESrTZyKiCsior+kb0n63lqOuTIihkfE8Nra2tb61AAAANjEtKSkLpC0U9V272Lf2tws6egNCQUAAIBya0lJfVTSANv9bHeWNErShOoDbA+o2vyUpGdaLyIAAADKptkxqRFRb/tMSfdJ6iDp2oiYbnuspMkRMUHSmbYPlbRS0iJJp27M0AAAANi0tWTilCLiXkn3Ntp3XtXHX2nlXAAAACgx7jgFAACA7FBSAQAAkB1KKgAAALJDSQUAAEB2KKkAAADIDiUVAAAA2aGkAgAAIDuUVAAAAGSHkgoAAIDsUFIBAACQHUoqAAAAskNJBQAAQHYoqQAAAMgOJRUAAADZoaQCAAAgO5RUAAAAZIeSCgAAgOxQUgEAAJAdSioAAACyQ0kFAABAdiipAAAAyA4lFQAAANmhpAIAACA7lFQAAABkh5IKAACA7FBSAQAAkB1KKgAAALJDSQUAAEB2KKkAAADIDiUVAAAA2aGkAgAAIDuUVAAAAGSHkgoAAIDsUFIBAACQHUoqAAAAstOikmr7cNuzbc+xfW4Tz3/N9gzb02z/0fbOrR8VAAAAZdFsSbXdQdIVko6QVCdptO26Roc9Jml4RAyVdJuki1o7KAAAAMqjJWdSR0iaExHPRcQKSTdLOqr6gIh4ICKWFZsPS+rdujEBAABQJi0pqTtKeqFqe36xb22+IOm3TT1he4ztybYnL1y4sOUpAQAAUCqtOnHK9smShkv6WVPPR8SVETE8IobX1ta25qcGAADAJqRjC45ZIGmnqu3exb7V2D5U0nclHRwR77ROPAAAAJRRS86kPippgO1+tjtLGiVpQvUBtodJGidpZES82voxAQAAUCbNltSIqJd0pqT7JM2UdEtETLc91vbI4rCfSeom6Vbbj9uesJaXAwAAAJrVksv9ioh7Jd3baN95VR8f2sq5AAAAUGLccQoAAADZoaQCAAAgO5RUAAAAZIeSCgAAgOxQUgEAAJAdSioAAACyQ0kFAABAdiipAAAAyA4lFQAAANmhpAIAACA7lFQAAABkh5IKAACA7FBSAQAAkB1KKgAAALJDSQUAAEB2KKkAAADIDiUVAAAA2aGkAgAAIDuUVAAAAGSHkgoAAIDsUFIBAACQHUoqAAAAskNJBQAAQHYoqQAAAMgOJRUAAADZoaQCAAAgO5RUAAAAZIeSCgAAgOxQUgEAAJAdSioAAACyQ0kFAABAdiipAAAAyA4lFQAAANmhpAIAACA7lFQAAABkp0Ul1fbhtmfbnmP73Cae/6jtqbbrbR/f+jEBAABQJs2WVNsdJF0h6QhJdZJG265rdNg8SZ+XdFNrBwQAAED5dGzBMSMkzYmI5yTJ9s2SjpI0o+GAiJhbPLdqI2QEAABAybTkcv+Okl6o2p5f7AMAAAA2ijadOGV7jO3JticvXLiwLT81AAAA2pGWlNQFknaq2u5d7FtvEXFlRAyPiOG1tbUf5CUAAABQAi0pqY9KGmC7n+3OkkZJmrBxYwEAAKDMmi2pEVEv6UxJ90maKemWiJhue6ztkZJke1/b8yV9RtI429M3ZmgAAABs2loyu18Rca+kexvtO6/q40dVGQYAAAAAbDDuOAUAAIDsUFIBAACQHUoqAAAAskNJBQAAQHYoqQAAAMgOJRUAAADZoaQCAAAgO5RUAAAAZIeSCgAAgOxQUgEAAJAdSioAAACyQ0kFAABAdiipAAAAyA4lFQAAANmhpAIAACA7lFQAAABkh5IKAACA7FBSAQAAkB1KKgAAALJDSQUAAEB2KKkAAADIDiUVAAAA2aGkAgAAIDuUVAAAAGSHkgoAAIDsUFIBAACQHUoqAAAAskNJBQAAQHYoqQAAAMgOJRUAAADZoaQCAAAgO5RUAAAAZIeSCgAAgOxQUgEAAJAdSioAAACyQ0kFAABAdlpUUm0fbnu27Tm2z23i+c1s/7p4/m+2+7Z2UAAAAJRHsyXVdgdJV0g6QlKdpNG26xod9gVJiyJiV0m/kHRhawcFAABAebTkTOoISXMi4rmIWCHpZklHNTrmKEk3FB/fJukQ2269mAAAACgTR8S6D7CPl3R4RHyx2P6cpP0i4syqY54qjplfbD9bHPNao9caI2lMsTlI0uzW+kI20NaSXmv2qPLhfVkT70nTeF+axvvSNN6XNfGeNC2n92XniKhNHaJMOrblJ4uIKyVd2ZafsyVsT46I4alz5Ib3ZU28J03jfWka70vTeF/WxHvSNN6XcmvJ5f4Fknaq2u5d7GvyGNsdJfWU9HprBAQAAED5tKSkPippgO1+tjtLGiVpQqNjJizYvt0AABsGSURBVEg6tfj4eEl/iubGEQAAAABr0ezl/oiot32mpPskdZB0bURMtz1W0uSImCDpGkm/tD1H0huqFNn2JLshCJngfVkT70nTeF+axvvSNN6XNfGeNI33pcSanTgFAAAAtDXuOAUAAIDsUFIBAACQHUoqAAAAskNJBQAAQHbadDH/3Ng+SNKAiLjOdq2kbhHxfOpcKdnuKunrkvpExJdsD5A0KCLuThwtGdvDJX1X0s6qfM9YUkTE0KTBkBXbW63r+Yh4o62y5ML2ZZLWOjs3Is5uwzhZsd1B0h8i4uOps+Sm+LnzU0l1kro07I+IXZKFQhKlLam2z5c0XJXbs14nqZOkX0k6MGWuDFwnaYqkDxfbCyTdKqm0JVXSeEn/JulJSasSZ8mG7aV6v4B0VuV76O2I6JEuVVJTVHk/3MRzIamMP2AnF38eqErh+HWx/RlJM5IkykREvGt7le2eEbE4dZ7MXCfpfEm/kPRxSaeJK7+lVNqSKukYScMkTZWkiHjRdve0kbLQPyJOtD1akiJime2mfuiWycJiPWBUiYj3vl+KfyNHSdo/XaK0IqJf6gy5iYgbJMn2GZIOioj6Yvu/Jf05ZbZMvCXpSdv3S3q7YWeZzzAXNo+IP9p2RPxd0gW2p0g6L3UwtK0yl9QVERG2Q5Jsb5E6UCZW2N5cxRky2/0lvZM2UnLn275a0h9V9V5ExO3pIuWluMPcHcUVinNT50nN9paSBmj1S5WT0iVKbktJPVS52YskdSv2ld3txQOre8d2jaRnipsJLVDl3wxKpswl9Rbb4yR9yPaXJP2LpKsSZ8rB+ZJ+J2kn2+NVuUz3+aSJ0jtN0mBVLmc3XO4PlfyHi+1jqzZrVBk+szxRnGzY/qKkr0jqLelxVc4u/1XSJ1LmSuzfJT1m+wFVhkN8VNIFSRNlICJuKE4K9ImI2anzZOQrkrpKOlvSD1W55H9K0kRIotR3nLJ9mKRPqvKf5n0RcX/iSFmw3UuVH6yW9HBEvJY4UlK2Z0fEoNQ5cmP7uqrNeklzJV0VEa+mSZQH209K2leV7529bA+W9JOIOLaZv7pJs72dpP2Kzb9FxMsp8+TA9pGSfi6pc0T0s72XpLERMTJxtKRsfyYibm1uHzZ9pS6pWJPtAyU9HhFv2z5Z0t6S/rMYF1RKRRn7WUSUeqJHtWJm8tkR8YvUWXJj+9GI2Nf245L2i4h3bE+PiN1SZ8uJ7cERMSt1jpSKcZafkPRgRAwr9j0VEbunTZaW7akRsXdz+7DpK+3l/uJS5YWStlHljGHDskJlnZnc4L8k7Wl7T0lfk3SNpBslHZw0VVr7S3rc9vOqjEkt/RJUxczk0arMvsXq5tv+kKQ7JN1ve5Gk0v6Stw6/l9QndYjEVkbE4kZzU0u7gojtIyT9s6QdbV9a9VQPVa7WoGRKW1IlXSTpyIiYmTpIZuqLCWVHSboiIq6x/YXUoRI7PHWATP3F9uWqLCtUPTN5arpI6UXEMcWHFxRjMHuqMs67dBoVjdWekvShtsySqem2T5LUoVgb9GxJDyXOlNKLqixbNlKVJd0aLJV0TpJESKq0l/tt/yUiyr4m6hpsT1TlB+ppqkxueFXSExGxR9JgCdn+ZUR8rrl9ZVMUMOn9tVIbzjCXeYKQpPeGQ2yrqhMBETEvXaI0irV0v66mVwi5OCK2buNIWSlunvJdVc2NkPTDiCj1BETbnSJiZeocSK/MJfU/JW2nyiU5lhUqFJMbTpL0aET82XYfSR+LiBsTR0um8VioooA8GRF1CWMlZ/vrWn3x+pC0RNLkiHg8WbDEbJ+lyioZr6hqNYgyDg+x/SdJ34uINc4O2n6etWXRFO44hQZlLqnXNbE7IuJf2jwMsmT725K+I2lzScsadktaIenKiPh2qmw5sH2TKstOTVDlffm0pGmS+kq6NSIuSpcuHdtzVJkw9XrqLKkVt4pdHhHLmj24RGzfpXXfLrbss/v/T+/fcepIFXeciggW8y+Z0pZUNI0JZWuy/dOyF9Km2J4k6Z8j4q1iu5uke1QZwzulrGeai2EQhzXcXQnv/b9yT0SU/cYgkiTbDRNRj1Xlit6viu3Rkl6JiFKPv7Q9JSL2sf1kw1Czhn2ps6FtlW7ilO1vRsRFti9TE7/Jcjs6JpQ14W7bW7As1xq20epjDVdK2jYi/mG7zGXkOUkP2r5Hqw8luiRdpOSOlPSL4hebX0v6XZlLfERMlCTbF0fE8Kqn7rI9OVGsnHDHKUgqYUmV1FC++I+gaa9QUNdQvSzX1yVdLZblkqTxkv5m+85i+0hJNxW3GC7zmrLzikfn4lF6EXGa7U6SjlDlbOEVtu+PiC8mjpbaFrZ3iYjnJMl2P0nconvNO059QtKpSRMhCS73YzVMKFtTw8Qp2+dJWlAsy8XC0pJsD1fl1rmS9JeI4Je/QjH8QQ3DIVCZta3KcJDTJH2U2f0+XNKVqpx9t6SdJY2JiN8nDQZkonQllQHr68aEsjWxLBfWh+3dJf1S0lbFrtcknRIR09OlSqtYpP1ESR+T9KCkWyT9vsyX/BvY3kzS4GJzVpnH7fLzGY2VsaSu8xJtw1ghoAHLcmF92H5I0ncj4oFi+2OSfhIRByQNlpDt/1FlLOpvy1zCGivOLJ+hyi+/UqXAjyvrGqFMKENjpSup1WxvLqlPRMxOnSUXtgeqMgZz24jY3fZQSSMj4keJowHtgu0nImLP5vYBtq+W1EnSDcWuz0l6t+xjdW1PbjShrMl92PTVpA6Qiu0jJT2u4naFtveyPSFtqixcJenbqszUVkRMkzQqaaJEbC+1vaSJx1LbS1LnQ7aes/19232Lx/dUGXNYWraPtf2M7cV8D61m34g4NSL+VDxOk7Rv6lAZ2ML2ewv3M6GsvMo4u7/BBZJGqHJ5RRHxePGNUHZdI+IR29X7SjluLCK6p86AdulfJP1AUsNkwz8X+8qMpe2a9q7t/hHxrCQVxezdxJlycI4qy7itNqEsbSSkUOaSujIiFjcqY+Ud+/C+12z3V/Fe2D5e0ktpIwHtR0QsUmXpHLyPpe2a9m+SHmhUxk5LGym9iPhdcWvUJieU2T4sIu5Pkw5tqbRjUm1fI+mPks6VdJwqP1Q6RcTpSYMlVvwmf6WkAyQtkvS8pJMjYm7KXEDubP9HRHx1bTOUyzwzmaXt1q6Y3T+o2JzNxLLmsQRgeZS5pHaV9F1Jn1TlN9j7JP0wIpYnDZaJYkH2mohYmjoL0B7Y3icipqxtBZEyrxzC0nZNs/1lSeMj4s1ie0tJoyPi/6VNljfbj0XEsNQ5sPGVtqRWs91B0hYRUdqB/La/tq7nS35LR6DFbH8lIv6zuX2A7ccjYq9G+yhgzeBManmUeXb/TbZ7FGcMn5Q0w/a/pc6VUPfiMVyVdft2LB6nq3KvegAt09TtGz/f1iFyYru37d/YfrV4/K/t3qlzZaCDqyZGFCdMuJUuUCjzxKm6iFhi+7OSfqvK2NQpkn6WNlYaEfEDSbI9SdLeDZf5bV8g6Z6E0YB2wfZoVW760K/RcnbdJb2RJlU2rpN0k6TPFNsnF/sOS5YoD7+T9Gvb44rt/6/YV2q2N2s8NrfRvrltnwoplLmkdiru9nG0pMsjYqVtxj5I20paUbW9otgHYN0eUmUljK0lXVy1f6mkaUkS5aM2IqrHpV5v+6vJ0uTjW6oU0zOK7fslXZ0uTjb+qjWv4L23LyKObfNESKLMJXWcKr+NPSFpku2dJZV2TGqVGyU9Yvs3xfbRkq5PFwdoHyLi75L+XlydebFhEmZxZ7veKvfZn9dtnyzpf4rt0ZJeT5gnCxGxSpU7/P1X6iw5KG5BvaOkzW0PU2VSsyT1kNQ1WTAkw8SpKrY7RkQpF66vZntvSR8pNidFxGNVz21ZrAMJoAm2J0s6ICJWFNudJf0lIkp7J6HiJMBlkj6syvJcD0k6KyJeSBosMdsHqnJjmZ1VOWlkVVY92GVdf29TZftUVcZvD5c0ueqppZKuZ8my8il1SbX9KUm7SerSsC8ixqZLlD9mVQLrtpYZ209ExJ6pMqVm+wZJX234Bdf2VpJ+zhJUnqXK3ZWmqOpOUxFR6rPMto+LiP9NnQPplfZyv+3/VuXywcdVGQN0vKRHkoZqH9z8IUCpLbQ9MiImSJLtoyS9ljhTakOrr8BExBvF5dyyWxwRv00dIkN32z5JUl9V9RROIpVPaUuqKpfjhtqeFhE/sH2xKrP8sW7lPfUOtMzpksbbvkKV75f5kk5JGym5muqhQsWZ1DL//GnwgO2fSbpdq9+Ja2q6SFm4U9JiVc4wcweuEivzfxL/KP5cZnsHVQbxb58wD4BNQEQ8K2l/292K7bcSR8rBxZL+avvWYvszkn6cME8u9iv+HF61LyR9IkGWnPSOiMNTh0B6ZS6pd9v+kKSLVPltTWLpj5bgcj+wDra3lfQTSTtExBG26yR9OCKuSRwtmYi4sZhQ1lC+jo2IGSkz5SAiPp46Q6Yesr1HRDyZOgjSKu3EqWJZmDNUmcUekv4s6b8alo0pM9sHSRoQEdfZrpXULSKeL57bKiLKvjA5sFa2f6vKQvXfjYg9bXeU9FhE7JE4GjLDLzRNsz1D0q6Snlflcn/DqgdDkwZDmytzSb1FlWUtflXsOklSz4g4IV2q9Gyfr8qlp0ERMbAYCnFrRByYOBrQLth+NCL2rb4He1Mz/gF+oWlasWTZGoq1iFEiNakDJLR7RHwhIh4oHl+StHvqUBk4RtJISW9LUkS8qMptHQG0zNu2e6mYZGh7f1UmgQCNbR0Rt0haJUnFOt3vrvuvbPqKMrqTpE8UHy9TuftKaZV5TOpU2/tHxMOSZHs/rb54cFmtiIhouEWs7S1SBwLama9JmiCpv+2/SKpVZYk7oDF+oWlC9RU9Vc40d1LlqidX9EqmdCXV9pOq/IfQSZXB2fOK7Z0lzUqZLRO32B4n6UO2vyTpXyRdlTgT0C7Y7iDp4OIxSJWxdLMjYmXSYMgVv9A07RhJwyRNlSpX9GxzRa+ESjcmdW1jXRow5kWyfZikT6ryA/a+iLg/cSSg3bD9SESMSJ0D7UMxDrXJX2hsH1bG/38bvoca7nBYXNH7KxOnyqd0JRUANibbv1DlSs2vVYztlligHeuvrLehtv0NSQMkHSbpp6pc0bspIi5LGgxtjpIKSZLtpWr6blINS3/0aONIQLtk+4EmdkdElH2Bdqyn6hUiyoYrepAoqQAAZKnEZ1L7SXqpYd3yYl3zbSNibtJgaHOlmziF5tneW9JBqpxZ/b+IeCxxJCB7tk+OiF/Z/lpTz0fEJW2dCWinbpV0QNX2u8W+fdPEQSqsO4bV2D5P0g2SeknaWtL1tr+XNhXQLjQs19Z9LQ9gfc1NHSCRjhGxomGj+LhzwjxIhMv9WI3t2ZL2bHSZ5fGIGJQ2GQBsWmx3lfR1SX0i4ku2B6hyt7+7E0dLyvb9ki6LiAnF9lGSzo6IQ9ImQ1vjcj8ae1FSF0nLi+3NJC1IFwdoH2xfuq7nI+LstsqCduM6SVMkfbjYXqDKZe1Sl1RJp0sab/vyYnu+pM8lzINEKKlobLGk6cVvsqHKEiCPNPwA5gctsFZTij8PlFSnyhJUkvQZSTOSJELu+kfEibZHS1JELLPt1KFSKm6IcUZE7G+7myRFxFuJYyERSioa+03xaPBgohxAuxIRN0iS7TMkHVTch122/1vSn1NmQ7ZWFEOqGm6L2l/SO2kjpRUR79o+qPiYclpylFSspuEHLYAPbEtJPSS9UWx3K/YBjZ0v6XeSdrI9XpWz8J9PmigPj9meoMrQh+obYtyeLhJSoKRiNbY/LemHknZW5d8Hi/kD6+ffVfkh+4Aq3z8flXRB0kTIUkTcb3uqpP1V+bfylYh4LXGsHHSR9Lqk6htghCRKaskwux+rsT1H0rGSngz+cQAfiO3tJO1XbP4tIl5OmQd5sn2MpD9FxOJi+0OSPhYRd6RNBuSBdVLR2AuSnqKgAuvH9uDiz70l7aDK99ILknYo9gGNnd9QUCUpIt5UZQhAqdkeaPuPtp8qtoeyXnc5cSYVq7G9ryqX+yeqagA/d8sB1s32lRExprjMX/0fa8OQmU+s5a+ipGxPi4ihjfY9GRF7pMqUA9sTJf2bpHERMazY91RE7J42GdoaZ1LR2I8lLVNlTBB3ywFaKCLGFB/+s6R7VFnO7U1JE4p9QGOTbV9iu3/xuETvL2VWZl0j4pFG++qTJEFSTJxCYzvw2yqwQW6QtERSw+L+J0m6UdIJyRIhV2dJ+r7eX1P3fklfThcnG68Vy3E1LM11vKSX0kZCClzux2psXyTpDxHx+9RZgPbI9oyIqGtuH4Cm2d5F0pWSDpC0SNLzkj4bEX9PGgxtjpKK1dheKmkLVcajrhRLUAHrxfavJF0eEQ8X2/tJ+nJEnJI2GXJje6Ckb0jqq6orm4xfrrC9haSaiFiaOgvSoKQCQCuw/aQqlyc7SRokaV6xvbOkWZxJRWO2n5D036qMQ323YX9ElHpcqu1eqqxycJAq30P/J2lsRLyeNBjaHCUVkirL50TErLUtlRMRU9s6E9Ce2N55Xc9zqRKN2Z4SEfukzpEb2/dLmiTpV8Wuz6qyfuyh6VIhBUoqJK2xfE6D9/5xcPkJAFqX7QskvSrpN1p9yb831vZ3yqCp5aZYmqucKKlYje0TJP0uIpbY/r6kvSX9kDOpANC6bD/fxO6IiF3aPExGiqW4HpF0S7HreEkjIuIb6VIhBUoqVtOwuLTtg1RZ1P/nks6LiP2a+asAAGywqgm8DeN0O0h6u/iYibwlwmL+aKzhP4VPSboqIu6R1DlhHgDYJNnuavt7tq8stgfY/nTqXKlFRPeIqImITsWjptjXPSJ62N4tdUa0DUoqGltge5ykEyXda3sz8e8EADaG6yStUGU9UElaIOlH6eK0G79MHQBtg/KBxk6QdJ+kf4qINyVtpco9lAEArat/RFykyprUiohlqqxNjXXjPSoJbouK1RT/Sd5etf2SuB0dAGwMK2xvrvdv/9lfVbP8sVZMpikJSioAAGlcIOl3knayPV7SgZJOS5oIyAiz+wEASKS4u9L+qlzCfjgiXkscKXu2H46I/VPnwMZHSQUAIAHbf4yIQ5rbVya2e0o6XNKOxa4Fku4r5kigZJg4BQBAG7LdxfZWkra2vaXtrYpHX71fzkrH9imSpkr6mKSuxePjkqYUz6FkOJMKAEAbsv0VSV+VtIMqZwobZqsvUWV96stTZUvJ9mxJ+zU+a2p7S0l/i4iBaZIhFUoqAAAJ2D4rIi5LnSMXtp+WtG9ELG60v6ekyRExIE0ypMLsfgAAEoiIy2wfIKmvqn4eR8SNyUKl9WNJU23/XtILxb4+kg5T5TbdKBnOpAIAkIDtX0rqL+lxvX9L6oiIs9OlSqu4tP9PWnPi1KJ0qZAKJRUAgARsz5RUF/wgBprE7H4AANJ4StJ2qUO0B7afTJ0BbY8xqQAApLG1pBm2H1HV7VAjYmS6SOnYPnZtT4kyX0qUVAAA0rggdYDM/FrSeElNDX/o0sZZkAHGpAIAkIjtnSUNiIg/2O4qqUNELE2dKwXbUySdGhFPNfHcCxGxU4JYSIgxqQAAJGD7S5JukzSu2LWjpDvSJUruq6rc0KApx7RlEOSBkgoAQBpflnSgimIWEc9I2iZpooQi4s8RMW8tz01u+Nj2t9suFVKipAIAkMY7EbGiYcN2RzU9HhOr+0zqAGgblFQAANKYaPs7kja3fZikWyXdlThTe+DUAdA2mDgFAEACtmskfUHSJ1UpXvdJuprF/dfN9tSI2Dt1Dmx8lFQAABKzvZWk3hExLXWW3Nl+LCKGpc6BjY/L/QAAJGD7Qds9ioI6RdJVtn+ROlc7cGvqAGgblFQAANLoGRFLJB0r6caI2E/SIYkzJWd7F9t32X7N9qu277S9S8PzEfGTlPnQdiipAACk0dH29pJOkHR36jAZuUnSLarcCnUHVc6c/k/SREiCkgoAQBpjVZksNSciHi3OFj6TOFMOukbELyOivnj8StwWtZSYOAUAQIZsfzsifpo6R1spxuZK0rckLZJ0syrrxp4oacuIYBH/kqGkAgCQobIttWT7eVVKaVProEZE7NLEfmzCOqYOAAAAmlSqResjol/qDMgLJRUAgDyV8lKn7VOa2h8RN7Z1FqRFSQUAIE+lOpNaZd+qj7uosizXVEmU1JKhpAIAkKdSLlofEWdVb9v+kCqTqFAyLEEFAEACLFrfYm9LYrxqCXEmFQCANG6SdIWkY4rtUaosWr9fskQZsH2X3h+PWyOpTpXF/VEyLEEFAEACtqdFxNBG+56IiD1TZcqB7YOrNusl/T0i5qfKg3QoqQAAtCEWrQdahpIKAEAbYtH6dbN9rKQLJW2jyntkVd6XHkmDoc1RUgEAQDZsz5F0ZETMTJ0FaTFxCgCABFi0fq1eoaBC4kwqAABJ2L6savO9Resj4vhEkZIqLvNL0sGStpN0h6R3Gp6PiNtT5EI6lFQAADLQsGh9RByeOksKtq9bx9MREf/SZmGQBUoqAAAZsN1J0lMRMSh1lpzZ/nZE/DR1Dmx8jEkFACABFq3/wD4jiZJaApRUAADS+HnVxyxa33JNLd2FTRAlFQCABCJiYuoM7RTjFEuiJnUAAADKyPaxtp+xvdj2EttLbS9Jnasd4ExqSVBSAQBI4yJJIyOiZ0T0iIjuZb6rku0Liz8/08yht7ZBHGSA2f0AgP+/vbtHsSoIwgBaX+74A67AxGxAU3NxK2OuuAZX4BbcgRiYaeQovFmAO9DABZTBKFweg76ou/GeA53cTiosurq/ywRJPnb3k9l1rCLJVVWdV9Vldz+eXQ/zuZMKAANtQus/J3lbQuv/eFdVP6rq1tG1h9R1TupuT5n3ykkqAAwktP7vkrzv7qdH315398tZNTGHJhUAFrTX0PokX47H/UkO3X0+qybm8HAKANb0rwdE/5UkF7/vpT5Mctisb1V1Nbs+xnOSCgALSvK1ux/NrmOUJHeq6l5d/03q1WbrZ3d/n1MVM2lSAWBBN429YU+M+wFgTULr2TVNKgAMJLQeTmPcDwADCa2H0wjzB4CxhNbDCYz7AWCg7n7R3Xer6kN3396ss6p6M7s+WIUmFQDmuH/Dt2fDq4BFGfcDwEBJLqrqeVU9SHLYbJ1V1ac5VcF6PJwCgIGE1sNpNKkAACzHnVQAAJajSQUAYDmaVAAAlqNJBQBgOb8AUS1DrwH9Zk8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "U4Ydie66DH5Y",
        "outputId": "72315969-0914-44f2-c0e2-27b0ee393105"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAIRCAYAAABu0TiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfbxudV3n/9cbkBQFxThpci9z1CHDtCOY+CtLcdBGSFKDMm8yGf2FWpoTjoaEU6am/hplUqzMe0Sn7KgkkqKZtxwQQVDyDKiATR7UgHQS0c/vj7U2XOyzz9kbvnvvtfZer+fjcT3Otda1ztlvL9nXfu+1vuv7TVUhSZKk22eXoQNIkiStZZYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBrsN9YX32WefOuigg4b68pIkSUt2wQUXXFtVGxZ6bbAyddBBB7Fly5ahvrwkSdKSJfnqjl7zMp8kSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVIDy5QkSVKD3YYO0Oqgkz8wdAQAvvLHvzh0BEmSNADPTEmSJDVYUplKcnSSy5NsTXLyAq8fkOS8JJ9LcnGSxyx/VEmSpPFZtEwl2RU4HXg0cChwQpJD5x32YuCsqnogcDzwP5c7qCRJ0hgt5czU4cDWqrqiqm4EzgSOnXdMAXv1z+8KfH35IkqSJI3XUgag7wtcNbN9NXDEvGNOBT6U5NnAnYFHLks6SZKkkVuuAegnAH9VVfsBjwHemmS7fzvJiUm2JNmybdu2ZfrSkiRJw1lKmboG2H9me79+36ynA2cBVNWngDsC+8z/h6rqjKraVFWbNmzYcPsSS5IkjchSytT5wMYkByfZnW6A+eZ5x3wNeARAkv9IV6Y89SRJkta9RctUVd0EnAScA3yR7q69S5OcluSY/rDnA89I8nngncBTq6pWKrQkSdJYLGkG9Ko6Gzh73r5TZp5fBhy5vNEkSZLGzxnQJUmSGqz5tfm0vbGsVwiuWShJWv88MyVJktTAM1OaDM/YSZJWgmemJEmSGlimJEmSGlimJEmSGlimJEmSGjgAXZo4B+YvbCzvy5jeE0kLs0xJkpZkLAUTLJkaF8uUJEkNLJlyzJQkSVIDy5QkSVIDL/NJkqRlN6XLn56ZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJamCZkiRJarCkMpXk6CSXJ9ma5OQFXn9Nkov6xz8l+dfljypJkjQ+uy12QJJdgdOBo4CrgfOTbK6qy+aOqarfmTn+2cADVyCrJEnS6CzlzNThwNaquqKqbgTOBI7dyfEnAO9cjnCSJEljt5QytS9w1cz21f2+7SQ5EDgY+MgOXj8xyZYkW7Zt23Zbs0qSJI3Ocg9APx54T1X9YKEXq+qMqtpUVZs2bNiwzF9akiRp9S2lTF0D7D+zvV+/byHH4yU+SZI0IUspU+cDG5McnGR3usK0ef5BSe4H7A18ankjSpIkjdeiZaqqbgJOAs4BvgicVVWXJjktyTEzhx4PnFlVtTJRJUmSxmfRqREAqups4Ox5+06Zt33q8sWSJElaG5wBXZIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqcGSylSSo5NcnmRrkpN3cMwTk1yW5NIk71jemJIkSeO022IHJNkVOB04CrgaOD/J5qq6bOaYjcALgSOr6ttJfmylAkuSJI3JUs5MHQ5sraorqupG4Ezg2HnHPAM4vaq+DVBV31jemJIkSeO0lDK1L3DVzPbV/b5Z9wHuk+QTST6d5OiF/qEkJybZkmTLtm3bbl9iSZKkEVmuAei7ARuBhwMnAG9Mcrf5B1XVGVW1qao2bdiwYZm+tCRJ0nCWUqauAfaf2d6v3zframBzVX2/qq4E/omuXEmSJK1rSylT5wMbkxycZHfgeGDzvGPeS3dWiiT70F32u2IZc0qSJI3SomWqqm4CTgLOAb4InFVVlyY5Lckx/WHnAN9MchlwHvCCqvrmSoWWJEkai0WnRgCoqrOBs+ftO2XmeQHP6x+SJEmT4QzokiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDZZUppIcneTyJFuTnLzA609Nsi3JRf3jN5c/qiRJ0vjsttgBSXYFTgeOAq4Gzk+yuaoum3fou6rqpBXIKEmSNFpLOTN1OLC1qq6oqhuBM4FjVzaWJEnS2rCUMrUvcNXM9tX9vvl+OcnFSd6TZP+F/qEkJybZkmTLtm3bbkdcSZKkcVmuAejvAw6qqsOAc4E3L3RQVZ1RVZuqatOGDRuW6UtLkiQNZyll6hpg9kzTfv2+m1XVN6vqe/3mnwM/vTzxJEmSxm0pZep8YGOSg5PsDhwPbJ49IMmPz2weA3xx+SJKkiSN16J381XVTUlOAs4BdgX+sqouTXIasKWqNgPPSXIMcBPwLeCpK5hZkiRpNBYtUwBVdTZw9rx9p8w8fyHwwuWNJkmSNH7OgC5JktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktTAMiVJktRgSWUqydFJLk+yNcnJOznul5NUkk3LF1GSJGm8Fi1TSXYFTgceDRwKnJDk0AWO2xN4LvCZ5Q4pSZI0Vks5M3U4sLWqrqiqG4EzgWMXOO6lwMuBf1/GfJIkSaO2lDK1L3DVzPbV/b6bJXkQsH9VfWBn/1CSE5NsSbJl27ZttzmsJEnS2DQPQE+yC/Bq4PmLHVtVZ1TVpqratGHDhtYvLUmSNLillKlrgP1ntvfr983ZE7g/8NEkXwEeAmx2ELokSZqCpZSp84GNSQ5OsjtwPLB57sWquq6q9qmqg6rqIODTwDFVtWVFEkuSJI3IomWqqm4CTgLOAb4InFVVlyY5LckxKx1QkiRpzHZbykFVdTZw9rx9p+zg2Ie3x5IkSVobnAFdkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpgWVKkiSpwZLKVJKjk1yeZGuSkxd4/ZlJLklyUZJ/THLo8keVJEkan0XLVJJdgdOBRwOHAicsUJbeUVU/WVU/BbwCePWyJ5UkSRqhpZyZOhzYWlVXVNWNwJnAsbMHVNX1M5t3Bmr5IkqSJI3Xbks4Zl/gqpntq4Ej5h+U5LeA5wG7A7+w0D+U5ETgRIADDjjgtmaVJEkanWUbgF5Vp1fVIcDvAS/ewTFnVNWmqtq0YcOG5frSkiRJg1lKmboG2H9me79+346cCfxSSyhJkqS1Yill6nxgY5KDk+wOHA9snj0gycaZzV8Evrx8ESVJksZr0TFTVXVTkpOAc4Bdgb+sqkuTnAZsqarNwElJHgl8H/g28JSVDC1JkjQWSxmATlWdDZw9b98pM8+fu8y5JEmS1gRnQJckSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWpgmZIkSWqwpDKV5OgklyfZmuTkBV5/XpLLklyc5MNJDlz+qJIkSeOzaJlKsitwOvBo4FDghCSHzjvsc8CmqjoMeA/wiuUOKkmSNEZLOTN1OLC1qq6oqhuBM4FjZw+oqvOq6rv95qeB/ZY3piRJ0jgtpUztC1w1s311v29Hng783UIvJDkxyZYkW7Zt27b0lJIkSSO1rAPQkzwJ2AS8cqHXq+qMqtpUVZs2bNiwnF9akiRpELst4ZhrgP1ntvfr991KkkcCLwJ+rqq+tzzxJEmSxm0pZ6bOBzYmOTjJ7sDxwObZA5I8EHgDcExVfWP5Y0qSJI3TomWqqm4CTgLOAb4InFVVlyY5Lckx/WGvBO4CvDvJRUk27+CfkyRJWleWcpmPqjobOHvevlNmnj9ymXNJkiStCc6ALkmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1GBJZSrJ0UkuT7I1yckLvP6zSS5MclOSxy9/TEmSpHFatEwl2RU4HXg0cChwQpJD5x32NeCpwDuWO6AkSdKY7baEYw4HtlbVFQBJzgSOBS6bO6CqvtK/9sMVyChJkjRaS7nMty9w1cz21f2+2yzJiUm2JNmybdu22/NPSJIkjcqqDkCvqjOqalNVbdqwYcNqfmlJkqQVsZQydQ2w/8z2fv0+SZKkyVtKmTof2Jjk4CS7A8cDm1c2liRJ0tqwaJmqqpuAk4BzgC8CZ1XVpUlOS3IMQJIHJ7kaeALwhiSXrmRoSZKksVjK3XxU1dnA2fP2nTLz/Hy6y3+SJEmT4gzokiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDSxTkiRJDZZUppIcneTyJFuTnLzA6z+S5F39659JctByB5UkSRqjRctUkl2B04FHA4cCJyQ5dN5hTwe+XVX/AXgN8PLlDipJkjRGSzkzdTiwtaquqKobgTOBY+cdcyzw5v75e4BHJMnyxZQkSRqnVNXOD0geDxxdVb/Zb/86cERVnTRzzBf6Y67ut/93f8y18/6tE4ET+837Apcv1/+QRvsA1y561PT4vmzP92Rhvi8L831ZmO/L9nxPFjam9+XAqtqw0Au7rWaKqjoDOGM1v+ZSJNlSVZuGzjE2vi/b8z1ZmO/LwnxfFub7sj3fk4WtlfdlKZf5rgH2n9ner9+34DFJdgPuCnxzOQJKkiSN2VLK1PnAxiQHJ9kdOB7YPO+YzcBT+uePBz5Si10/lCRJWgcWvcxXVTclOQk4B9gV+MuqujTJacCWqtoM/AXw1iRbgW/RFa61ZHSXHkfC92V7vicL831ZmO/Lwnxftud7srA18b4sOgBdkiRJO+YM6JIkSQ0sU5IkSQ0sU5IkSQ0sU5IkSQ1WddLOsejXG/z7qvr5obOMUZKHARur6k1JNgB3qaorh841lCR7AM8HDqiqZyTZCNy3qt4/cLRBJdkEvAg4kO6zJEBV1WGDBhtY/9/Hy+jWMr3j3P6quvdgoQaU5O47e72qvrVaWTRuSV4L7PCuuKp6zirGuU0mWaaq6gdJfpjkrlV13dB5xiTJS4BNdMv9vAm4A/A24Mghcw3sTcAFwM/029cA7wYmXaaAtwMvAC4BfjhwljF5E/ASukXffx54GtO+CnAB3Q/IhdZrLWCSJRMgyQ3cUh52p/u8/U5V7TVcqkFt6f88ku6XkXf1208ALhsk0RJNskz1/g24JMm5wHfmdo65+a6SxwEPBC4EqKqvJ9lz2EiDO6SqfiXJCQBV9V0X8gZgWz/PnG7tTlX14SSpqq8Cpya5ADhl6GBDqKqDh84wVlV182dr/5lyLPCQ4RINq6reDJDkWcDDquqmfvv1wMeHzLaYKZepv+4furUbq6qSFECSOw8daARuTHIn+t8gkxwCfG/YSKPwkiR/DnyYmfejqqb+ffW9JLsAX+4nPL4GuMvAmUYhyd7ARm59+fMfhks0Hv2qIe/trw6cPHSege0N7EU3CTh03z97DxdncZMtU1X15v4H5AFVdfnQeUbkrCRvAO6W5BnAbwBvHDjT0F4CfBDYP8nb6U5BP3XQROPwNOB+dJcm5i7zFf6S8lxgD+A5wEvpLvU9edBEI5DkN+nem/2Ai+jOwHwK+IUhcw0pyXEzm7vQDbH494HijMkfA59Lch7d5eGfBU4dNNEiJjsDepLHAn8C7F5VByf5KeC0qjpm4GiDS3IU8Ci6/4jPqapzB440uCQ/SvfhH+DTVXXtwJEGl+Tyqrrv0DnGJskTqurdi+2bmiSXAA+m+/75qST3A/6oqo5b5K+uW0neNLN5E/AV4I1V9Y1hEo1HknsCR/Sbn6mq/zNknsVMuUxdQPcb0Uer6oH9vi9U1f2HTaaxSXIkcFFVfSfJk4AHAX/aj4eZrP4HwSuratQDQ1dbkgur6kGL7ZuaJOdX1YOTXAQcUVXfS3JpVf3E0NmG0N9V/pyqes3QWdaCJPerqi8NnWNHJnuZD/h+VV03bxzx5O9I6k87vxz4MbqzMHO3u0/17hKAPwMekOQBwPPoFvZ+C/Bzg6Ya3kOAi5JcSTdmatJTIyR5NPAYYN8k/2Pmpb3ozjpM3dVJ7ga8Fzg3ybeByf5C0t9VfgLdXZ9a3IeAA4YOsSNTLlOXJvlVYNd+XpjnAJ8cONMYvAJ4bFV9ceggI3JTPyj/WOD0qvqLJE8fOtQIHD10gJH5Ot2t3cfQTQcw5wbgdwZJNCJV9bj+6an9WJi70o1FnLJPJHkd3RQAs3eVXzhcpOHM+yXkVi8Bd1vNLLfVlC/z7UE34eDNY4OAl1bVpAf/JflEVU15TqntJPkY3Yf+0+gGQn4D+HxV/eSgwQaW5K1V9euL7ZuaJHeoqu8PnWOM+ktb92DmF/mq+tpwiYbVl0q4Za6pubO7kxyU38+79XwWvlv6VVW1zypHWrLJliktLMmfAvekOxXv7e7cPBDyV4Hzq+rjSQ4AHl5Vbxk42qDmjwPqf1BeUlWHDhhrcM6AvrAkz6a7M/ZfmLn7c6qXhQGSPJ9bT2hawPXAlqq6aLBgA0nyEeDFVbXdVaIkV455zrLJlakk72Pn09VP+m6+eXeXzKmq+o1VD6NRSvJC4L8BdwK+O7cbuBE4o6peOFS2MUjyj9wyA/pj6WdAr6pJTto5J8lWuoHn3xw6y1gkeQfddAib6b6H/jNwMXAQ8O6qesVw6VZfv/TQv1fVdxc9eGSmWKbmBg0fR3cG5m399gnAv1TV5Mc26NYclL+wJC+benFaSJILquqnk1wydyl4bt/Q2YbUX9I6am5Wa0GSfwAeU1X/1m/fBfgA3XjEC6Z6lrf/zP1AVa2ZyZEnNwC9qj4GkORVVbVp5qX3Jdmyg7+27iX5r1X1ih0tNDnxZXYclL+w9ye5s1NGbMcZ0Bd2BfDRJB/g1kMIXj1cpMH9GLceH/R94B5V9X+TrJkisQIeC7ymL5vvAj449hI+uTI1485J7l1VVwAkORiY8tIpc0VhsoVyJ/7FIrWg2Skjng/8OU4ZAdvPgP4LwFMGTTQOX+sfu/cPdYuFfybJ3/bbjwXe0S/jNdn526rqaUnuADya7qrR6UnOrarfHDjaDk3uMt+cJEcDZ9D9thTgQODEqvrQoME0Og7KX9jcAPQkpwDX9FNGTH5ySu1cfymLuUtbU5dkE90SVQCfqCp/oe31hepo+jupvZtvpJL8CN3aYgBfWkvXZ5ebA/N3zEH5C3PKiFvze2jnktwfeCtw937XtcCTq+rS4VJpjPoJcH8FeDjwUeAs4ENjvtQ32TLVN95n0f0QgO7/sDdMdX6YmYH5C5obaybNccqIW/Pmlp1L8kngRVV1Xr/9cLq1+R46aDCNTpJ30o2V+ru1cpJjymXqz+lWu39zv+vXgR+M+ZrsaklyJ+CAqrp86CxjkOQ+dOOD7lFV909yGHBMVf33gaNphJJsmXdzy4L7pibJ56vqAYvtk9aiXYYOMKAHV9VTquoj/eNpdCuaT1qSxwIX0S/zkOSnkmweNtXg3gi8kO5OG6rqYuD4QRMNKMkNSa5f4HFDkuuHzjcCd05y8wSd3txysyuS/H6Sg/rHi+nGrEq3kuS4JF9Oct1a+WyZ8t18P0hySFX9b4D+w+8HA2cag1OBw+kue1JVF/U/DKZsj6r67LxFsUd77X6lVdWeQ2cYud+hmwLgVje3DBtpFH4D+ANg7saNj/f7pPnW3HQ0Uy5TLwDOm/eB97RhI43C96vqunnFYZrXgm9xbZJD6N+HJI8H/nnYSBqrqvpgv6TMgje3JDmqqs4dJt1wqurbdNNFSItZc9PRTHbMFNx8N999+83L18pAt5WU5C+ADwMnA79M9+F3h6p65qDBBtSftTwDeCjwbeBK4ElV9ZUhc2ltmtr0EUn+v6r67R3d7Tj1uxy1vbU4Hc1ky1SS3wLeXlX/2m/vDZxQVf9z2GTDSrIH8CLgUXRn7M4BXlpV/z5osBHoJ9LbpapuGDqL1q4kn6uqBw6dY7Uk+emqumBHdwx7p7DmW4vT0Uy5TF1UVT81b9+kPuQWk2RX4M5VNeqBfyslyfN29vrEl8HQ7TS1M1Nzkjy3qv50sX3SWjTlu/l2zczAoL44TH6JgyTvSLJXfxbmEuCyJC8YOtdA9uwfm+jmJNu3fzyTbh06SUu30JI6T13tEBq/JPsl+Zsk3+gf/yvJfkPn2pkpD0D/IPCuJG/ot/9Lv2/qDq2q65P8GvB3dGOnLgBeOWys1VdVfwA3r+z+oLnLe0lOpVvZXdpOkh+ZP/5y3r6vrH6q4SQ5gW5y14PnTbOyJ/CtYVJp5N4EvAN4Qr/9pH7fUYMlWsSUy9Tv0RWoZ/Xb59It1Dp1d+hnh/8l4HVV9f0k07wWfIt7ADfObN/Y75MW8im2P3N5876qOm7VEw3rk3R3v+4DvGpm/w3AxYMk0thtqKrZcVN/leS3B0uzBJMtU1X1Q7pZrf9s6Cwj8wa635w/D/xDkgOBSY6ZmvEW4LNJ/qbf/iXgr4aLozHql9fZF7hTkgfS3cABsBewx2DBBlZVXwW+2p/t/vrczSz9Sgv7MbEzdVqSbyZ5EvDOfvsE4JsD5lnUlAegH0k3QeWBdKUydHcL3Htnf2+Kkuw25gUmV0OSBwH/T7/5D1X1uZnX9u7n0NGEJXkK3RigTcCWmZduAP5qzLd1r4YkW4CHVtWN/fbuwCeqavIrT+jW+l/iXwv8DN10Gp8Enl1VVw0abCemXKa+RDdT8QXMzHxeVaNuv6shyS8CPwHccW5fVZ02XKJxm+rdWVpYkl+uqv81dI6x2cEd1K7Np+0keTPw23O/pCa5O/AnY54aYbKX+YDrqurvhg4xNkleT3dJ4ufpxpA9HvjsoKHGL4sfogl5f5JfBQ5i5jPWX0jYluSYqtoMkORY4NqBM2mcDps9219V3+ovnY/WlMvUeUleSbdO1OwMqxcOF2kUHlpVhyW5uKr+IMmr6O7q045N8/SuduRvgevoznpPflWFGc8E3p7kdLrvmauBJw8bSSO1y+zwif7M1Kj7yqjDrbAj+j83zewr4BcGyDIm/7f/87tJ7kU36O/HB8wjrTX7VdXRQ4cYm35R+YckuUu//W8DR9J4vQr4VJJ399tPAP5wwDyLmmyZqqqfHzrDSL0/yd3oVu2+oN/nlBE752U+zfpkkp+sqkuGDjImSe4B/BFwr6p6dJJDgZ+pqr8YOJpGpqre0t+wMHdy47iqumzITIuZ8gB0v7EX0N+u/Cy6O9cK+DjwZ1Nfmy/Jw4CNVfWmJBuAu1TVlf1rd68qJx8UAEkuA/4D3YLY3+OWO4UPGzTYwJL8Hd3Eiy+qqgck2Q34XFX95MDRpGZTLlN+Yy8gyVl0t3K/rbHc09YAAA0xSURBVN/1q8Bdq+qJw6UaVpKX0F0Ovm9V3ae//Pnuqjpy4Ggaof627u308y1NVpLzq+rBs2ugLnSHn7QWTXltvn2q6izghwD9PEo/2PlfmYT7V9XTq+q8/vEM4P5DhxrY44BjgO8AVNXX6ZbCkLbTl6b9gV/on3+XaX/WzvlOkh+lv2EjyUPoBupLa95kx0zhN/aOXJjkIVX1aYAkR3DrCQin6MaqqrlldfpFoKUFzZ7JpDv7fQe6M71TP5P5PGAzcEiSTwAb6KZekda8KZcpv7FnJLmErljegW4A7df67QOBLw2ZbQTO6hfEvluSZwC/Abxx4Ewar8cBDwQuhO5MZpJJn8lMsivwc/3jvnTjyC6vqu8PGkxaJpMdMwXdMins4Bs7yVFVde5g4VbZjsZ5zHG8R44CHkX338o5U/pvQ7dNks9W1eFzM+P3ZzI/5QD07n0ZOoe0EiZdpnbGJUIk3R5JfhfYCBwFvIzuTOY7quq1gwYbWJLX0J35fhf9+ENwomStD5apHZi940TTlOQGFp7dfO5W971WOZLWCM9kbi/JeQvsrqqa+kTJWgcsUzvgmSlJt0eSg4F/npubrZ+77R5V9ZVBg0laMVMegC4tWZIHAQ+jO1P1j1X1uYEjabzeDTx0ZvsH/b4HDxNnWEmeVFVvS/K8hV6vqlevdiZpuTn3yY59ZegAGockpwBvBn4U2Af4qyQvHjaVRmy3qrpxbqN/vvuAeYY2N5XInjt4SGveZC/zJdkDeD5wQFU9I8lGuhmu3z9wNI1MksuBB8y7bHNRVd132GQaoyTnAq+tqs399rHAc6rqEcMmk7RSpnyZ7010C/n+TL99Dd2peMuU5vs6cEdgbn3CH6H770VayDOBtyd5Xb99NfDrA+YZVJL/sbPXq+o5q5VFWilTLlOHVNWvJDkBoKq+myRDh9IoXQdc2p9xKLpb3j8790PCHwaa009O+ayqekiSuwBU1b8NHGtoF/R/HgkcSjc1AsATgMsGSSQtsymXqRv7yzVzS4QcQrfCuzTf3/SPOR8dKIdGrqp+kORh/fOplygAqurNAEmeBTysXweVJK8HPj5kNmm5TLlMvQT4ILB/krfT/db01EETaZTmfhhIS/S5JJvphg3MTk7518NFGoW9gb2Ab/Xbd+n3SWveZMtUVZ2b5ELgIXQT6z23qq4dOJZGKMl/Bl5Kt07hbjhpp3bujsA3gdnJKAuYepn6Y7qieR7d99DPAqcOmkhaJlO+m+9xwEeq6rp++27Aw6vqvcMm09gk2QocB1xSU/2GkZZBknsCR/Sbn6mq/zNkHmm5THmeqZfMFSmAqvpXukt/0nxXAV+wSGkpktwnyYeTfKHfPmzK85IluV//54OAe9F9P10F3KvfJ615Uz4zdfH8VdyTXFJVPzlUJo1TkgfTXeb7GDM3KThzsxaS5GPAC4A3zK3vmeQLVXX/YZMNI8kZVXVif3lv9gfO3OVy1+bTmjflM1Nbkrw6ySH949XccguvNOsPge/SjYVx5mYtZo+q+uy8fTcNkmQEqurE/uljgA/QTTXyr8Dmfp+05k12ADrwbOD3uWXOk3OB3xoujkbsXlM9q6Db5dp+qpW5aVceD/zzsJFG4c3A9cDcJJ6/CrwFeOJgiaRlMtnLfNJSJXkF8PdV9aGhs2j8ktwbOINuseNvA1cCv1ZVXx002MCSXFZVhy62T1qLJlumktwH+F3gIGbO0Hn9XvMluYFusdbvAd/HqRG0BEnuDOxSVTcMnWUMkrwNeF1VfbrfPgL4rap68rDJpHZTLlOfB15PN07qB3P7q8pxU5JutyQ/Sndn8MPoLvX9I3BaVX1z0GADSXIJ3ftwB+C+wNf67QOBL3lmSuvBlMvUBVX100Pn0HgluV9VfWlHt29X1YWrnUnj16/h+A/A2/pdv0Y3h90jh0s1nCQH7uz1qV/+1Pow5TJ1KvANujXXZm93/9aO/o6mZd4t3XNu/obxkrAWstA0CE67Iq1vUy5TVy6wu6rq3qseRqOW5InAB6vq+iS/DzwIeKlnprSQfpqVzwJn9bseDxxeVb87XCpJK2myZUpaqrkJXpM8jG7yzj8BTqmqIxb5q5qgmRsW5sZi7sotCx5744K0Dk120s4keyR5cZIz+u2N/YK20nxzPxR/EXhjVX0A2H3APBqxqtqzqnapqjv0j136fXtW1V5JfmLojJKW12TLFPAm4Ea6uWAArgH++3BxNGLXJHkD8CvA2Ul+hGl/76jNW4cOIGl5TfkHwiFV9Qq6eYOoqu/SzR8kzfdE4BzgP/ULYt+dbu016fbwc0ZaZ6a8nMyNSe7ELUs+HMLMXX3SnL5o//XM9j/j8iC6/RyoKq0zUy5TpwIfBPZP8nbgSOBpgyaSJElrzqTv5utnKn4I3Wn3T1fVtQNHkrTOJfl0VT1k6BySls9ky1SSD1fVIxbbJ0lLleSuwNHAvv2ua4Bz+rF2ktapyQ1AT3LHJHcH9kmyd5K794+DuOUDUJJukyRPBi4EHg7s0T9+Hrigf03SOjW5M1NJngv8NnAvut8a5+6suZ5uDqHXDZVN0tqV5HLgiPlnoZLsDXymqu4zTDJJK21yZWpOkmdX1WuHziFpfUjyT8CDq+q6efvvCmypqo3DJJO00iZ7N19VvTbJQ4GDmHkfquotg4WStJb9IXBhkg8BV/X7DgCOoluGSNI6NeUzU28FDgEu4pblQqqqnjNcKklrWX9J7z+x/QD0bw+XStJKm3KZ+iJwaE31DZAkScticnfzzfgCcM+hQ0ha/5JcMnQGSStnsmOmgH2Ay5J8lpllZKrqmOEiSVqrkhy3o5fwFzdpXZtymTp16ACS1pV3AW9n4bX37rjKWSStosmOmQJIciCwsar+PskewK5VdcPQuSStPUkuAJ5SVV9Y4LWrqmr/AWJJWgWTHTOV5BnAe4A39Lv2Bd47XCJJa9xv003+u5DHrWYQSatrsmUK+C3gSPoPv6r6MvBjgyaStGZV1cer6ms7eG3L3PMkL1y9VJJWw5TL1Peq6sa5jSS7sfBYB0laTk8YOoCk5TXlMvWxJP8NuFOSo4B3A+8bOJOk9S+LHyJpLZnsAPQkuwBPBx5F9+F2DvDnTuIpaSUlubCqHjR0DknLZ7JlalaSuwP7VdXFQ2eRtL4l+VxVPXDoHJKWz2Qv8yX5aJK9+iJ1AfDGJK8ZOpekde/dQweQtLwmW6aAu1bV9cBxwFuq6gjgEQNnkrTGJbl3kvcluTbJN5L8bZJ7z71eVX80ZD5Jy2/KZWq3JD8OPBF4/9BhJK0b7wDOoltC5l50Z6LeOWgiSStqymXqNLpB51ur6vz+N8cvD5xJ0tq3R1W9tapu6h9vw+VkpHXNAeg7kOSFVfWyoXNIWhv68ZcAvwd8GziTbu66XwH2rion65TWKcvUDnj7sqTbIsmVdOVpoXmkqqruvcB+SevAbkMHGDEn1pO0ZFV18NAZJA3DMrVjnrKTdJslefJC+6vqLaudRdLqsEztmGemJN0eD555fke6KVcuBCxT0jplmdoxJ9aTdJtV1bNnt5PcjW4wuqR1arJTIzixnqRV8h3A8VTSOjblM1PvAE4HHtdvH083sd4RgyWStOYleR+3jLncBTiUbhJPSevUZKdGSHJxVR02b9/nq+oBQ2WStPYl+bmZzZuAr1bV1UPlkbTyJlemnFhPkiQtpymWKSfWk7RikhwHvBz4MbrPmdB9tuw1aDBJK2ZyZUqSVlKSrcBjq+qLQ2eRtDomOwDdifUkrZB/sUhJ0zLZM1NJXjuzefPEelX1+IEiSVrD+st7AD8H3BN4L/C9uder6q+HyCVp5U22TM03N7FeVR09dBZJa0+SN+3k5aqq31i1MJJWlWWql+QOwBeq6r5DZ5G0fiV5YVW9bOgckpbPlMdMObGepCE8AbBMSevIZMsU8Cczz51YT9JqcRF1aZ2ZbJmqqo8NnUHSJDm2QlpnprzQ8XFJvpzkuiTXJ7khyfVD55K07nlmSlpnJlumgFcAx1TVXatqr6ra0xmKJd1eSV7e//mERQ599yrEkbSKJns3X5JPVNWRQ+eQtD4kuQQ4DLigqh40dB5Jq2dyY6ZmJtbbkuRdOLGepOXxQbrF0+8yb8iAa/NJ69zkzkw5sZ6klZTkQ1X1qHn7XlFV/3WoTJJW1uTK1FI5sZ6k2yPJhfMv8yW5uKoOGyqTpJU15QHoi1lsEKkk3SzJs/pxU/dNcvHM40rgkqHzSVo5npnagSSfq6oHDp1D0tqQ5K7A3nSzm58889INVfWtYVJJWg2WqR1Y6FS9JEnSfF7m2zEn1pMkSYuaXJlyYj1JkrScJneZz4n1JEnScprcpJ04sZ4kSVpGk7vMV1UvqKq7AR/p1+Sbe+wJvH7ofJIkaW2ZXJmasc8C+45e9RSSJGlNm9xlviTPAv5f4N5JLp55aU/gk8OkkiRJa9UUB6A7sZ4kSVo2kytTkiRJy2nKY6YkSZKaWaYkSZIaWKYkSZIaWKYkSZIa/P9VLKY18RzZwAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORcgUn8YDSHo"
      },
      "source": [
        "## Combining our models (model ensembling/stacking)\n",
        "\n",
        "Many production systems use an **ensemble** (multiple different models combined) of models to make a prediction.\n",
        "\n",
        "The idea behind model stacking is that if several uncorrelated models agree on a prediction, then the prediction must be more robust than a prediction made by a singular model.\n",
        "\n",
        "The keyword in the sentence above is uncorrelated, which is another way of saying, different types of models. For example, in our case, we might combine our baseline, our bidirectional model and our `TensorFlow Hub USE model`.\n",
        "\n",
        "Think of it as trying to decide where to eat with your friends. If you all have similar tastes, you'll probably all pick the same restaurant. But if you've all got different tastes and still end up picking the same restaurant, the restaurant must be good.\n",
        "\n",
        "Since we're working with a classification problem, there are a few of ways we can combine our models:\n",
        "\n",
        "1. **Averaging** - *Take the output prediction probabilities of each model for each sample, combine them and then average them.*\n",
        "2. **Majority vote (mode)** - *Make class predictions with each of your models on all samples, the predicted class is the one in majority. For example, if three different models predict [1, 0, 1] respectively, the majority class is 1, therefore, that would be the predicted label.*\n",
        "3. **Model stacking** - *Take the outputs of each of your chosen models and use them as inputs to another model.*\n",
        "\n",
        "We're going to combine our baseline model (`model_0`), LSTM model (`model_2`) and our USE model trained on the full training data (`model_6`) by averaging the combined prediction probabilities of each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrSvdRhdGu6P",
        "outputId": "c8f301df-a6fa-466a-e7b8-51a36336cbbc"
      },
      "source": [
        "# Get mean pred probs for 3 models\n",
        "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n",
        "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
        "combined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\n",
        "combined_preds[:20]"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InhOw_3THLo1",
        "outputId": "749c4446-34f1-465a-f5f4-cf97f6dfc851"
      },
      "source": [
        "# Calculate results from averaging the prediction probabilities\n",
        "ensemble_results = calculate_results(val_labels, combined_preds)\n",
        "ensemble_results"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.52755905511812,\n",
              " 'f1': 0.7949420796084701,\n",
              " 'precision': 0.7950062580205643,\n",
              " 'recall': 0.7952755905511811}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzYAAPrgHXex"
      },
      "source": [
        "# Add our combined model's results to the results DataFrame\n",
        "all_model_results.loc[\"ensemble_results\"] = ensemble_results"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "32gZdYy3HbU1",
        "outputId": "58136a14-8c65-4726-f7c7-065609db1757"
      },
      "source": [
        "# Convert the accuracy to the same scale as the rest of the results\n",
        "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100\n",
        "\n",
        "all_model_results"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.793625</td>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.782222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.774516</td>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.770970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.770542</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.764985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.770361</td>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.767063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.759871</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.758578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>0.814961</td>\n",
              "      <td>0.816185</td>\n",
              "      <td>0.814961</td>\n",
              "      <td>0.813814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.774138</td>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.769181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble_results</th>\n",
              "      <td>0.795276</td>\n",
              "      <td>0.795006</td>\n",
              "      <td>0.795276</td>\n",
              "      <td>0.794942</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         accuracy  precision    recall        f1\n",
              "baseline                 0.792651   0.811139  0.792651  0.786219\n",
              "simple_dense             0.786089   0.793625  0.786089  0.782222\n",
              "lstm                     0.772966   0.774516  0.772966  0.770970\n",
              "gru                      0.767717   0.770542  0.767717  0.764985\n",
              "bidirectional            0.769029   0.770361  0.769029  0.767063\n",
              "conv1d                   0.759843   0.759871  0.759843  0.758578\n",
              "tf_hub_sentence_encoder  0.814961   0.816185  0.814961  0.813814\n",
              "tf_hub_10_percent_data   0.771654   0.774138  0.771654  0.769181\n",
              "ensemble_results         0.795276   0.795006  0.795276  0.794942"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu4mGxBkHe6V"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn_-OTH0HpmS"
      },
      "source": [
        "If you save a model as a HDF5, when loading it back in, you need to let TensorFlow know about any custom objects you've used (e.g. components which aren't built from pure TensorFlow, such as TensorFlow Hub components)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5dUvAbuHnBG"
      },
      "source": [
        "# Load model with custom Hub Layer (required with HDF5 format)\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\", \n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5cPmPNpHpCY",
        "outputId": "d1c2ef30-3c70-4d26-bd41-6f85b2385f84"
      },
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4265 - accuracy: 0.8150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4265137016773224, 0.8149606585502625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySoPb91AHuII",
        "outputId": "70f85dc6-ffd0-4bb0-b5d6-c263e39dbe5a"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKlDG0UrH0Oj"
      },
      "source": [
        "# Load TF Hub Sentence Encoder SavedModel\n",
        "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYtnrOFvH5BZ",
        "outputId": "e6e2f858-e057-4c22-9b26-f8c82a0cc56d"
      },
      "source": [
        "# Evaluate loaded SavedModel format\n",
        "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4265 - accuracy: 0.8150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4265137016773224, 0.8149606585502625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9bz7k3LH7Lm"
      },
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "One of the best ways to inspect your data is to sort your model's predictions and find the samples it got most wrong, meaning, what predictions had a high prediction probability but turned out to be wrong.\n",
        "\n",
        "To make things visual, let's take our best performing model's prediction probabilities and classes along with the validation samples (text and ground truth labels) and combine them in a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jM1bc90III3J",
        "outputId": "b964e5fe-5ba9-4185-cd0f-622e7ab23234"
      },
      "source": [
        "# Create dataframe with validation sentences and best performing model predictions\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
        "val_df.head()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.198806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.784013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.986501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.224572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.751279</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.198806\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.784013\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.986501\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.224572\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.751279"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-wxUVnmIQAR"
      },
      "source": [
        "Oh yeah! Now let's find our model's wrong predictions (where target != pred) and sort them by their prediction probability (the pred_prob column)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "-PaBhkHZIp1l",
        "outputId": "6041cab9-d229-4476-bd14-2a52ff24c712"
      },
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong[:10]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.925954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.895226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.870703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.858752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.858276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.848201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.846620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.842779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>A look at state actions a year after Ferguson'...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.829440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>The Sound of Arson</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.826037</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.925954\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.895226\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.870703\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.858752\n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.858276\n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   0.848201\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.846620\n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.842779\n",
              "695  A look at state actions a year after Ferguson'...       0   1.0   0.829440\n",
              "144                                 The Sound of Arson       0   1.0   0.826037"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywk1rXGeIsPg"
      },
      "source": [
        "Finally, we can write some code to visualize the sample text, truth label, prediction class and prediction probability. Because we've sorted our samples by prediction probability, viewing samples from the head of our most_wrong DataFrame will show us false positives.\n",
        "\n",
        "A reminder:\n",
        "\n",
        "* `0 = Not a real diaster Tweet`\n",
        "* `1 = Real diaster Tweet`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geFfvRrmI3F9",
        "outputId": "d2482da9-ecf5-48bf-a633-40184c46c164"
      },
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples(): # loop through the top 10 rows (change the index to view different rows)\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0, Pred: 1, Prob: 0.9259544014930725\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8952259421348572\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8707029223442078\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8587522506713867\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8582755923271179\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8482012748718262\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8466196656227112\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8427790403366089\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8294399976730347\n",
            "Text:\n",
            "A look at state actions a year after Ferguson's upheaval http://t.co/GZEkQWzijq\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8260366916656494\n",
            "Text:\n",
            "The Sound of Arson\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8-9JjgNI8C-",
        "outputId": "cf24a6df-d050-489f-9636-82ca817b879f"
      },
      "source": [
        "# Check the most wrong false negatives (model predicted 0 when should've predict 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 1, Pred: 0, Prob: 0.07047490030527115\n",
            "Text:\n",
            "@DavidVonderhaar At least you were sincere ??\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.06936823576688766\n",
            "Text:\n",
            "'The way you move is like a full on rainstorm and I'm a house of cards'\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.06683379411697388\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.05412893742322922\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.05357828363776207\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.04913429543375969\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.049077462404966354\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.047490961849689484\n",
            "Text:\n",
            "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.039752498269081116\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.03738321363925934\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id9iSf8YLYg0"
      },
      "source": [
        "### Making predictions on the test dataset\n",
        "\n",
        "Alright we've seen how our model's perform on the validation set.\n",
        "\n",
        "We don't have labels for the test dataset so we're going to have to make some predictions and inspect them for ourselves.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omZ--s2NLs3_",
        "outputId": "7c3e7ac9-c876-449a-8eaa-2cb99a1ba829"
      },
      "source": [
        "# Making predictions on the test dataset\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred: 0, Prob: 0.47517892718315125\n",
            "Text:\n",
            "The Dones felt grief bordering on devastation at losing connection with God through their church communities. Packard http://t.co/r2pQQPfqCt\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.054715074598789215\n",
            "Text:\n",
            "@iam_destruction Okay.. I'll put my tail in first.. -He moved to slip it in slowly.-\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.8383961319923401\n",
            "Text:\n",
            "Family mourns drowning of 'superhero' toddler with rare epilepsy: Bradley Diebold suffered hundreds of epilept... http://t.co/aSAn4yGd48\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.06576615571975708\n",
            "Text:\n",
            "@LadyShaxx That is freaking awesome!\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.11035394668579102\n",
            "Text:\n",
            "YE SBUJDJSJS YES YES I XUSKAK I SCREAMED PROTECT MY OTHER SON PROTECT UR BOYFRIEND YES  https://t.co/kDqtqGK5pI\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.21528947353363037\n",
            "Text:\n",
            "@bottleowhite i had to cover my eyes with the mudslide #toopainful\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.2894623577594757\n",
            "Text:\n",
            "#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/RaPaDCea1w #prebreak #best\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.35952720046043396\n",
            "Text:\n",
            "Is This Country Latin America's Next 'Argentina': One week ago we reported on the economic devastation in he o... http://t.co/J3rcOflDyA\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.9485481381416321\n",
            "Text:\n",
            "VIDEO: 'We're picking up bodies from water': Rescuers are searching for hundreds of migrants in the Mediterran... http://t.co/XfS3pJhFh9\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.076569102704525\n",
            "Text:\n",
            "fun fact: every rapid-fire weapon in the game is a hard counter to the slosher and the splattling\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ddnrfCULwG4"
      },
      "source": [
        "### Predicting on Tweets from the wild"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVmHo9bnM3no"
      },
      "source": [
        "# Turn Tweet into string\n",
        "prachurya_tweet = \"Life is like a wildfire. It burns slowly \""
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy68aVVINCYI"
      },
      "source": [
        "def predict_on_sentence(model, sentence):\n",
        "  \"\"\"\n",
        "  Uses model to make a prediction on sentence.\n",
        "\n",
        "  Returns the sentence, the predicted label and the prediction probability.\n",
        "  \"\"\"\n",
        "  pred_prob = model.predict([sentence])\n",
        "  pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
        "  print(f\"Pred: {pred_label}\", \"(real disaster)\" if pred_label > 0 else \"(not real disaster)\", f\"Prob: {pred_prob[0][0]}\")\n",
        "  print(f\"Text:\\n{sentence}\")"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhWOdtW4NFNk",
        "outputId": "926e0f0d-1caa-4968-c011-449021c95196"
      },
      "source": [
        "# Make a prediction on Tweet from the wild\n",
        "predict_on_sentence(model=model_6, # use the USE model\n",
        "                    sentence=prachurya_tweet)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.6579557657241821\n",
            "Text:\n",
            "Life is like a wildfire. It burns slowly \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nypl0AtZNJOc"
      },
      "source": [
        "# Source - https://twitter.com/BeirutCityGuide/status/1290696551376007168\n",
        "beirut_tweet_1 = \"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"\n",
        "\n",
        "# Source - https://twitter.com/BeirutCityGuide/status/1290773498743476224\n",
        "beirut_tweet_2 = \"#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\""
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7amvgHL1NeCu",
        "outputId": "5fe4b4f1-bb06-409b-e041-94955f0eed95"
      },
      "source": [
        "# Predict on diaster Tweet 1\n",
        "predict_on_sentence(model=model_6, \n",
        "                    sentence=beirut_tweet_1)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.9702665209770203\n",
            "Text:\n",
            "Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8m3eehqNgia",
        "outputId": "7fa538dc-2fef-44a5-9355-543a8e4030ed"
      },
      "source": [
        "# Predict on diaster Tweet 2\n",
        "predict_on_sentence(model=model_6, \n",
        "                    sentence=beirut_tweet_2)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.9808762669563293\n",
            "Text:\n",
            "#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HIJYl89Nkjq"
      },
      "source": [
        "## The speed/score tradeoff\n",
        "\n",
        "One of the final tests we're going to do is to find the speed/score tradeoffs between our best model and baseline model.\n",
        "\n",
        "Why is this important?\n",
        "\n",
        "Although it can be tempting to just choose the best performing model you find through experimentation, this model might not actually work in a production setting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9mq7MnzN3jr"
      },
      "source": [
        "# Calculate the time of predictions\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "  \n",
        "  Args:\n",
        "  ----\n",
        "  model = a trained model\n",
        "  sample = a list of samples\n",
        "\n",
        "  Returns:\n",
        "  ----\n",
        "  total_time = total elapsed time for model to make predictions on samples\n",
        "  time_per_pred = time in seconds per single sample\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples) # make predictions\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time-start_time # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(val_sentences) # find prediction time per sample\n",
        "  return total_time, time_per_pred"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P48-HY8dN6JP",
        "outputId": "ccef5622-ac1c-4fae-90be-ba44712ae098"
      },
      "source": [
        "# Calculate TF Hub Sentence Encoder prediction times\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2236374150006668, 0.0002934874212607176)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ5zPKHTN9I_",
        "outputId": "4996cc43-49b7-45b7-b18e-965f9c4114a4"
      },
      "source": [
        "# Calculate Naive Bayes prediction times\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.019145039999784785, 2.5124724409166386e-05)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Uy3b_QjN_V0"
      },
      "source": [
        "It seems with our current hardware (in my case, I'm using a Google Colab notebook) our best performing model takes over 10x the time to make predictions as our baseline model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "868gyEvtOCHv",
        "outputId": "f7d617ef-0e22-4c18-fcbf-dde640289604"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-Score\");"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqic_PPcOEsb"
      },
      "source": [
        "Of course, the ideal position for each of these dots is to be in the top left of the plot (low time per prediction, high F1-score).\n",
        "\n",
        "In our case, there's a clear tradeoff for time per prediction and performance. Our best performing model takes an order of magnitude longer per prediction but only results in a few F1-score point increase.\n",
        "\n"
      ]
    }
  ]
}